
4 CONCLUSION AND FUTURE WORK We conduct a statistical study on the iterative development process for ML applications in multiple domains. Our approach involves collecting carefully designed statistics from applied machine learning literature in order to reconstruct the iterative process that led to the results reported. We present our survey findings across domains and discuss desired ML system properties as suggested by the trends discovered from our survey data. The statistics and estimators described in our work can be further developed into a benchmark for systems specifically designed to address human-in-the-loop ML needs.   REFERENCES [1] 2017. Machine Learning: The New Proving Ground for Competitive Advantage. https://s3.amazonaws.com/files.technologyreview.com/whitepapers/  (2017). MITTR_GoogleforWork_Survey.pdf  [2] 2017. Machine learning: the power and promise of computers that learn by example. (2017). https://royalsociety.org/~/media/policy/projects/machine-learning/ publications/machine-learning-report.pdf  [3] 2017. The State of Data Science and Machine Learning. (2017). https://www.  kaggle.com/surveys/2017  [4] Ashraf Abdul, Jo Vermeulen, Danding Wang, Brian Y Lim, and Mohan Kankanhalli. 2018. Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, 582.  [5] Ivan Bruha and A Famili. 2000. Postprocessing in machine learning and data  mining. ACM SIGKDD Explorations Newsletter 2, 2, 110–114.  [6] Pedro Domingos. 2012. A few useful things to know about machine learning.  Commun. ACM 55, 10 (2012), 78–87.  [7] M. I. Jordan and T. M. Mitchell. 2015. Machine learning: Trends, perspectives, and prospects. Science 349 (2015), 255–260. http://science.sciencemag.org/content/ 349/6245/255  [8] Mary Beth Kery, Amber Horvath, and Brad Myers. 2017. Variolite: Supporting Exploratory Programming by Data Scientists. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 1265–1276.  [9] John King and Roger Magoulas. 2016. Data science salary survey: tools, trends,  what pays (and what doesn’t) for data professionals. (2016).  [10] Laura M Koesten, Emilia Kacprzak, Jenifer FA Tennison, and Elena Simperl. 2017. The Trials and Tribulations of Working with Structured Data:-a Study on Information Seeking Behaviour. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems. ACM, 1277–1289.  [11] Yong Liu, Jorge Goncalves, Denzil Ferreira, Bei Xiao, Simo Hosio, and Vassilis Kostakos. 2014. CHI 1994-2013: mapping two decades of intellectual progress through co-word analysis. In proceedings of the SIGCHI conference on human factors in computing systems. ACM, 3553–3562.  [12] M Arthur Munson. 2012. A study on the importance of and time spent on different modeling steps. ACM SIGKDD Explorations Newsletter 13, 2 (2012), 65–71. [13] Anton J Nederhof. 1985. Methods of coping with social desirability bias: A review.  European journal of social psychology 15, 3 (1985), 263–280.  [14] Junfei Qiu, Qihui Wu, Guoru Ding, Yuhua Xu, and Shuo Feng. 2016. A survey of machine learning for big data processing. EURASIP Journal on Advances in Signal Processing 2016, 1 (2016), 67.  [15] Carlton E. Sapp. 2017. Preparing and Architecting for Machine Learning. (2017). [16] Manasi Vartak, Pablo Ortiz, Kathryn Siegel, Harihar Subramanyam, Samuel Madden, and Matei Zaharia. 2015. Supporting fast iteration in model building. In NIPS Workshop LearningSys.  [17] Doris Xin et al. 2018. Helix: Holistic Optimization for Accelerating Iterative Machine Learning. Technical Report http://data-people.cs.illinois.edu/helix-tr.pdf (2018).  [18] Martin Zinkevich. 2017. Rules of Machine Learning: Best Practices for ML  Engineering. (2017).   
4. Conclusions  In this Perspective, we have given an overview of topics inside the ﬁelds of quantum In quantum machine learning, we have machine learning and quantum biomimetics. explored the topics of quantum reinforcement learning, on the one hand, and quantum autoencoders, on the other hand. In quantum biomimetics, we have described the results in quantum artiﬁcial life and quantum memristors.  Quantum reinforcement  interacting with an environment, obtaining information from it, as well as acting on it. The agent, typically a quantum system, can follow a policy to achieve a predetermined goal. Diﬀerent works in the literature show possible resource gains of quantum reinforcement learning with  learning considers an agent   Quantum machine learning and quantum biomimetics: A perspective  12  respect to its classical counterpart, as well as describe feasible experimental realizations in controllable quantum platforms.  Quantum autoencoders are a kind of quantum machine learning protocol in which the aim is to reduce the amount of quantum resources needed to encode a certain set of quantum states. Via a training process, with a certain parameterized quantum circuit, one may compress the quantum information from a certain Hilbert space onto a smaller space of states. A further variant of quantum autoencoders proposed in the literature is the one based on approximate quantum adders. These would allow for encoding a certain number of quantum states on a reduced number of quantum states via previouslyoptimized approximate quantum adders. Both kinds of quantum autoencoders have been realized experimentally. The ﬁrst one in quantum photonics, while the second one in superconducting circuits.  Quantum artiﬁcial life is a novel paradigm inside quantum biomimetics that may enable a quantum system to self-replicate and propagate its quantum information to further quantum systems. An open problem that remains to be addressed in these systems is whether one may be able to encode optimization problems by allowing the quantum individuals to compete, in some kind of quantum Darwinian evolution.  Quantum memristors are quantum devices with processing capabilities and memory, and constitute the basic building blocks for neuromorphic quantum computing. They may be employed in the future for distributed quantum computing, quantum neural networks, as well as quantum simulation of non-Markovian quantum systems.  Summarizing, quantum machine learning and quantum biomimetics are two emerging and promising ﬁelds inside quantum technologies, which may enable a wide variety of applications in the future.The connection between both ﬁelds is apparent in the sense that living systems, either natural or artiﬁcial, have often the ability to learn. With the advent of Noisy Intermediate-Scale Quantum (NISQ) computers [110], an enormous amount of computing power will be available, with desirable properties of speed and low energy consumption. Only the future can tell which progress may these technologies bring about.  Acknowledgements  I acknowledge collaborations and useful discussions on the topics presented in this article with Enrique Solano, Mikel Sanz, Unai Alvarez-Rodriguez, Jos´e Mart´ın-Guerrero, Pablo Escandell-Montero, Francisco Albarr´an-Arriagada, Juan Carlos Retamal, Francisco C´ardenas-L´opez, Yongcheng Ding, Xi Chen, Shang Yu, and Rei Li. Funding from Spanish PGC2018-095113-B-I00 (MCIU/AEI/FEDER, UE) is acknowledged.  Data Availability Statement  Data sharing does not apply to this article as no new data were created or analysed.   Quantum machine learning and quantum biomimetics: A perspective  13  References  [1] Mohseni M, Read P, Neven H, Boixo S, Denchev V, Babbush R, Fowler A, Smelyanskiy V and  Martinis J 2017 Commercialize early quantum technologies, Nature 543 171.  [2] New Strategic Research Agenda on Quantum technologies, European Commission, 2020. https://ec.europa.eu/digital-single-market/en/news/new-strategic-research-agenda-quantumtechnologies (last accessed: March 24, 2020).  [3] LeCun Y, Bengio Y, and Hinton G 2015 Deep learning. Nature 521 436. [4] Russell S and Norvig P 2009 Artiﬁcial Intelligence: A Modern Approach (Pearson). [5] Making a topic search at the Web of Science (Clarivate), http://apps.webofknowledge.com, with both the topics “machine learning” and “quantum”, retrieves a number of articles of about 10 per year in the period 2008-2013, and then a sustained growth, with a rapid rise in 2017 with 121 articles, 2018 with 249 articles, and 2019 with 354 articles.  [6] Wittek P 2014 Quantum Machine Learning (Academic Press). [7] Biamonte J, Wittek P, Pancotti N, Rebentrost P, Wiebe N and Lloyd S 2017 Quantum machine  learning Nature 549 074001  [8] Dunjko V and Briegel H J 2018 Machine learning & artiﬁcial intelligence in the quantum domain:  a review of recent progress Rep. Prog. Phys. 81 074001.  [9] Schuld M, Sinayskiy I, and Petruccione F 2015 An introduction to quantum machine learning  [10] Schuld M and Petruccione F 2018 Supervised Learning with Quantum Computers (Springer). [11] Schuld M, Sinayskiy I, and Petruccione F 2014 The quest for a Quantum Neural Network Quantum  [12] Dunjko V and Wittek P 2020 A non-review of Quantum Machine Learning:  trends and  [13] Harrow A W, Hassidim A, and Lloyd S 2009 Quantum Algorithm for Linear Systems of Equations  Contemp. Phys. 56 172.  Inf. Process. 13 2567.  explorations Quantum 4 32.  Phys. Rev. Lett. 103 150502.  [14] Rebentrost P, Mohseni M, and Lloyd S 2014 Quantum Support Vector Machine for Big Data  Classiﬁcation Phys. Rev. Lett. 113 130503.  [15] Lloyd S, Mohseni M, and Rebentrost P 2014 Quantum principal component analysis Nat. Phys.  10 631.  [16] Gily´en A, Arunachalam S, and Wiebe N 2019 Optimizing quantum optimization algorithms via faster quantum gradient computation Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete Algorithms.  [17] Sheng Y-B and Zhou L 2017 Distributed secure quantum machine learning Sci. Bull. 62 1025. [18] Dong D, Chen C, Li, H, and Tarn, T-J 2008 Quantum Reinforcement Learning IEEE Transactions  on Systems, Man, and Cybernetics, Part B (Cybernetics) 38 1207.  [19] Paparo G D, Dunjko V, Makmal A, Martin-Delgado M A, and Briegel H J 2014 Quantum Speedup  for Active Learning Agents Phys. Rev. X 4 031002.  [20] Dunjko V, Taylor J M, and Briegel H J 2016 Quantum-Enhanced Machine Learning Phys. Rev.  Lett. 117, 130501.  Sci. Rep. 7 1609.  [21] Lamata L 2017 Basic protocols in quantum reinforcement learning with superconducting circuits  [22] C´ardenas-L´opez F A, Lamata L, Retamal J C, and Solano E 2018 Multiqubit and multilevel quantum reinforcement learning with quantum technologies PLoS ONE 13 e0200455. [23] Albarr´an-Arriagada F, Retamal J C, Solano E, and Lamata L 2018 Measurement-based  adaptation protocol with quantum reinforcement learning Phys. Rev. A 98, 042315.  [24] Yu S, Albarr´an-Arriagada F, Retamal J C, Wang Y-T, Liu W, Ke Z-J, Meng Y, Li Z-P, Tang J-S, Solano E, Lamata L, Li C-F, and Guo G-C 2019 Reconstruction of a Photonic Qubit State with Reinforcement Learning Adv. Quantum Technol. 2, 1800074.  [25] Albarr´an-Arriagada F, Retamal J C, Solano E, and Lamata L 2020 Reinforcement learning for   Quantum machine learning and quantum biomimetics: A perspective  14  semi-autonomous approximate quantum eigensolver Mach. Learn.: Sci. Technol. 1, 015002.  [26] Romero J, Olson J P, and Aspuru-Guzik A 2017 Quantum autoencoders for eﬃcient compression  of quantum data Quantum Sci. Technol. 2 045001.  [27] Wan K H, Dahlsten O, Kristj´ansson H, Gardner R and Kim M S 2017 Quantum generalisation  of feedforward neural networks npj Quantum Information 3 36.  [28] Lamata L, Alvarez-Rodriguez U, Mart´ın-Guerrero J D, Sanz M, and Solano E 2018 Quantum  autoencoders via quantum adders with genetic algorithms Quantum Sci. Technol. 4 014007.  [29] Pepper A, Tischler N, and Pryde G J 2019 Experimental Realization of a Quantum Autoencoder:  The Compression of Qutrits via Machine Learning Phys. Rev. Lett. 122 060501.  [30] Ding Y, Lamata L, Sanz M, Chen X, and Solano E 2019 Experimental Implementation of a  Quantum Autoencoder via Quantum Adders Adv. Quantum Technol. 2 1800065.  [31] Khoshaman A, Vinci W, Denis B, Andriyash E, Sadeghi H, and Amin M H 2019 Quantum  variational autoencoder Quantum Sci. Technol. 4 014001.  [32] Tacchino F, Macchiavello C, Gerace D, and Bajoni D 2019 An artiﬁcial neuron implemented on  an actual quantum processor npj Quantum Inf. 5 26.  [33] Torrontegui E and Garca-Ripoll J J 2019 Unitary quantum perceptron as eﬃcient universal  approximator EPL 125 30004.  [34] Cao Y, Guerreschi G G, and Aspuru-Guzik A 2017 Quantum Neuron: an elementary building  block for machine learning on quantum computers arXiv:1711.11240  [35] Gonzalez-Raya T, Cheng X-H, Egusquiza I L, Chen X, Sanz M, and Solano E 2019 Quantized Single-Ion-Channel Hodgkin-Huxley Model for Quantum Neurons Phys. Rev. Appl. 12 014037. [36] Gonzalez-Raya T, Solano E, and Sanz M 2020 Quantized Three-Ion-Channel Neuron Model for  Neural Action Potentials Quantum 4 224.  [37] Alvarez-Rodriguez U, Lamata L, Escandell-Montero P, Mart´ın-Guerrero J D, and Solano E 2017  Supervised Quantum Learning without Measurements Sci. Rep. 7 13645.  [38] Johnson M W, Amin M H S, Gildert S, Lanting T, Hamze F, Dickson N, Harris R, Berkley A J, Johansson J, Bunyk P, Chapple E M, Enderud C, Hilton J P, Karimi K, Ladizinsky E, Ladizinsky N, Oh T, Perminov I, Rich C, Thom M C, Tolkacheva E, Truncik C J S, Uchaikin S, Wang J, Wilson B, and Rose G 2011 Quantum annealing with manufactured spins Nature 473 194.  [39] Venturelli D, Mandr`a S, Knysh S, O’Gorman B, Biswas R, and Smelyanskiy V 2015 Quantum  Optimization of Fully Connected Spin Glasses 2015 Phys. Rev. X 5 031040.  [40] Rieﬀel E G, Venturelli D, O’Gorman B, Do M B, Prystay E M, and Smelyanskiy V M 2015 A case study in programming a quantum annealer for hard operational planning problems Quantum Inf. Proc. 14 1.  [41] Amin M H, Andriyash E, Rolfe J, Kulchytskyy B, and Melko R 2018 Quantum Boltzmann  [42] Kieferov´a M and Wiebe N 2017 Tomography and generative training with quantum Boltzmann  Machine Phys. Rev. X 8 021050.  machines Phys. Rev. A 96, 062327.  [43] Benedetti M, Realpe-G´omez J, Biswas R, and Perdomo-Ortiz A 2017 Quantum-Assisted Learning  of Hardware-Embedded Probabilistic Graphical Models Phys. Rev. X 7 041052.  [44] Benedetti M, Realpe-G´omez J, and Perdomo-Ortiz A 2018 Quantum-assisted Helmholtz machines: A quantumclassical deep learning framework for industrial datasets in near-term devices Quantum Sci. Technol. 3 034007.  [45] Perdomo-Ortiz A, Benedetti M, Realpe-G´omez J and Biswas R 2018 Opportunities and challenges for quantum-assisted machine learning in near-term quantum computers Quantum Sci. Technol. 3 030502.  [46] Zahedinejad E, Ghosh J, and Sanders B C 2015 High-ﬁdelity single-shot Toﬀoli gate via quantum  control Phys. Rev. Lett. 114 200502.  [47] Zahedinejad E, Ghosh J, and Sanders B C 2016 Designing high-ﬁdelity single-shot three-qubit  gates: a machine-learning approach Phys. Rev. Applied 6 054005.   Quantum machine learning and quantum biomimetics: A perspective  15  [60] Sgroi P, Palma G M, and Paternostro M 2020 Reinforcement learning approach to non-equilibrium  [48] Las Heras U, Alvarez-Rodriguez U, Solano E, and Sanz M Genetic algorithms for digital quantum  simulations Phys. Rev. Lett. 116 230504.  [49] Li R, Alvarez-Rodriguez U, Lamata L, and Solano E 2017 Approximate Quantum Adders with  Genetic Algorithms: An IBM Quantum Experience Quantum Meas. Quantum Metrol. 4 1  [50] Carrasquilla J and Melko R G 2017 Machine learning phases of matter Nat. Phys. 13 431. [51] Mehta P, Bukov M, Wang C-H, Day A G R, Richardson C, Fisher C K, and Schwab D J 2019 A  high-bias, low-variance introduction to Machine Learning for physicists Phys. Rep. 810 1.  [52] Liu N and Rebentrost P 2018 Quantum machine learning for quantum anomaly detection Phys.  Rev. A 97 042315.  [53] Carleo G, Cirac I, Cranmer K, Daudet L, Schuld M, Tishby N, Vogt-Maranto L, and Zdeborov´a  L 2019 Machine learning and the physical sciences Rev. Mod. Phys. 91 045002.  [54] F¨osel T, Tighineanu P, Weiss T, and Marquardt F 2018 Reinforcement Learning with Neural  Networks for Quantum Feedback Phys. Rev. X 8, 031084.  [55] Bukov M, Day A G R, Sels D, Weinberg P, Polkovnikov A, and Mehta P 2018 Reinforcement  Learning in Diﬀerent Phases of Quantum Control Phys. Rev. X 8, 031086.  [56] Bukov M 2018 Reinforcement learning for autonomous preparation of Floquet-engineered states:  Inverting the quantum Kapitza oscillator Phys. Rev. B 98 224305.  [57] Melnikov A A, Nautrup H P, Krenn M, Dunjko V, Tiersch M, Zeilinger A, and Briegel H J 2018 Active learning machine learns to create new quantum experiments PNAS 115 1221. [58] Melnikov A A, Sekatski P, and Sangouard N 2020 Setting up experimental Bell test with  [59] Mackeprang J, Dasari D B R, and Wrachtrup J 2019 A Reinforcement Learning approach for  reinforcement learning arXiv:2005.01697.  Quantum State Engineering arXiv:1908.05981.  quantum thermodynamics arXiv:2004.07770.  quantum communication arXiv:1904.10797.  quantum control arXiv:2002.08376.  [61] Walln¨ofer, Melnikov A A, D¨ur W, and Briegel H J 2019 Machine learning for long-distance  [62] Sch¨afer F, Kloc M, Bruder C, and L¨orch N 2002 A diﬀerentiable programming method for  [63] Zhang X-M, Wei Z, Asad R, Yang X-C and Wang X 2019 When does reinforcement learning stand out in quantum control? A comparative study on state preparation npj Quantum Information 5 85.  [64] Xu H, Li J, Liu L, Wang Y, Yuan H, and Wang X 2019 Generalizable control for quantum parameter estimation through reinforcement learning npj Quantum Information 5 82. [65] Sweke R, Kesselring M S, van Nieuwenburg E P L, and Eisert J 2018 Reinforcement Learning  Decoders for Fault-Tolerant Quantum Computation arXiv:1810.07207.  [66] F¨osel T, Krastanov S, Marquardt F, and Jiang L 2020 Eﬃcient cavity control with SNAP gates  arXiv:2004.14256.  [67] Innocenti L, Banchi L, Ferraro A, Bose S, and Paternostro M Supervised learning of time-independent Hamiltonians for gate design New J. Phys. https://doi.org/10.1088/13672630/ab8aaf  [68] Youssry A, Chapman R J, Peruzzo A, Ferrie C, and Tomamichel M 2020 Modeling and control of a reconﬁgurable photonic circuit using deep learning Quantum Sci. Technol. 5 025001. [69] Shrapnel S, Costa F, and Milburn G 2018 Quantum Markovianity as a supervised learning task  Int. J. Quantum Info. 16 1840010.  [70] Luchnikov I A, Vintskevich S V, Grigoriev D A, and Filippov S N 2020 Machine Learning Non Markovian Quantum Dynamics Phys. Rev. Lett. 124 140502.  [71] Melnikov A A, Fedichkin L E, Lee R-K, and Alodjants A 2020 Machine Learning Transfer  Eﬃciencies for Noisy Quantum Walks Adv. Quantum Technol. 3 1900115.  [72] Melnikov A A, Fedichkin L E, and Alodjants A 2019 Predicting quantum advantage by quantum  walk with convolutional neural networks New J. Phys. 21 125002.   Quantum machine learning and quantum biomimetics: A perspective  16  [73] Kalantre S S, Zwolak J P, Ragole S, Wu X, Zimmerman N M, Stewart Jr. M D, and Taylor J M 2019 Machine learning techniques for state recognition and auto-tuning in quantum dots npj Quantum Information 5 6.  [74] Torlai G, Timar B, van Nieuwenburg E P L, Levine H, Omran A, Keesling A, Bernien H, Greiner M, Vuleti´c V, Lukin M D, Melko R G, and Endres M 2019 Integrating Neural Networks with a Quantum Simulator for State Reconstruction Phys. Rev. Lett. 123 230504.  [75] Torlai G, Mazzola G, Carrasquilla J, Troyer M, Melko R, and Carleo G 2018 Neural-network  quantum state tomography Nat. Phys. 14 447.  [76] Liu G, Chen M, Liu Y-X, Layden D, and Cappellaro P 2020 Repetitive readout enhanced by  machine learning Mach. Learn.: Sci. Technol. 1 015003.  [77] Agresti I, Viggianiello N, Flamini F, Spagnolo N, Crespi A, Osellame R, Wiebe N, and Sciarrino F 2019 Pattern Recognition Techniques for Boson Sampling Validation Phys. Rev. X 9 011013.  [78] Carrasquilla, J 2020 Machine Learning for Quantum Matter arXiv:2003.11040. [79] Tang E 2019 A quantum-inspired classical algorithm for recommendation systems. In Proceedings of the 51st Annual ACM SIGACT Symposium on Theory of Computing, STOC 217, New York, NY, USA.  [80] Arrazola J M, Delgado A, Bardhan B R, and Lloyd S 2019 Quantum-inspired algorithms in  practice arXiv:1905.10415.  [81] Langton C G 1997 Artiﬁcial Life: An overview (MIT Press, Cambridge USA). [82] Aguilar W, Santamar´ıa-Bonﬁl G, Froese T and Gershenson C 2014 The past, present, and future  [83] Gardner M, 1970 The fantastic combinations of John Conway’s new solitaire game “life”, Sci.  of artiﬁcial life Front. Robot. AI 1 8.  Am. 223 120.  Observables, Sci. Rep. 4 4910.  Technologies Sci. Rep. 6 20956.  Quantum Computer Sci. Rep. 8 14793.  [84] Alvarez-Rodriguez U, Sanz M, Lamata L, and Solano E 2014 Biomimetic Cloning of Quantum  [85] Alvarez-Rodriguez U, Sanz M, Lamata L, and Solano E 2016 Artiﬁcial Life in Quantum  [86] Alvarez-Rodriguez U, Sanz M, Lamata L, and Solano E 2018 Quantum Artiﬁcial Life in an IBM  [87] Wootters W K and Zurek W H 1982 A single quantum cannot be cloned Nature 299 802. [88] Eisert J, Wilkens M, and Lewenstein M 1999 Quantum games and quantum strategies Phys. Rev.  [89] Martin-Delgado M A, 2012 On Quantum Eﬀects in a Theory of Biological Evolution Sci. Rep. 2  [90] Abbott D, Davies P C W, and Pati A K 2008 Quantum Aspects of Life (Imperial College Press,  [91] Arrighi P and Grattage J 2010 A Quantum Game of Life. Paper presented at Journ´ees Automates  Cellulaires, Turku, Finland.  [92] Bleh D, Calarco T, and Montangero S 2012 Quantum Game of Life. EPL 97 20012. [93] Pfeiﬀer P, Egusquiza I L, Di Ventra M, Sanz M, and Solano E 2016 Quantum Memristors Sci.  Lett. 83 3077.  302.  London).  Rep. 6 29507.  [94] Salmilehto J, Deppe F, Di Ventra M, Sanz M, and Solano E, 2017 Quantum Memristors with  Superconducting Circuits, Sci. Rep. 7 42044.  [95] Sanz M, Lamata L, and Solano E, 2018 Invited article: Quantum memristors in quantum  [96] Shevchenko S N, Pershin Y V, and Nori F 2016 Qubit-based memcapacitors and meminductors  photonics APL Phot. 3 080801.  Phys. Rev. Applied 6, 014006.  [97] Di Ventra M, Pershin Y V, and Chua L O 2009 Circuit elements with memory: memristors,  memcapacitors, and meminductors Proc. IEEE 97 1717  [98] https://www.qutisgroup.com [99] Lamata L, Sanz M, and Solano E 2019 Quantum Machine Learning and Bioinspired Quantum   Quantum machine learning and quantum biomimetics: A perspective  17  Technologies Adv. Quantum Technol. 2 1900075.  [100] Sutton R S and Barto A G 2018 Reinforcement Learning: An Introduction (MIT Press). [101] Silver D, Huang A, Maddison C J, Guez A, Sifre L, van den Driessche G, Schrittwieser J, Antonoglou I, Panneershelvam V, Lanctot M, Dieleman S, Grewe D, Nham J, Kalchbrenner N, Sutskever I, Lillicrap T, Leach M, Kavukcuoglu K, Graepel T, and Hassabis D 2016 Mastering the game of Go with deep neural networks and tree search Nature 529 484.  [102] Silver D, Schrittwieser J, Simonyan K, Antonoglou I, Huang A, Guez A, Hubert T, Baker L, Lai M, Bolton A, Chen Y, Lillicrap T, Hui F, Sifre L, van den Driessche G, Graepel T, and Hassabis D 2017 Mastering the game of Go without human knowledge Nature 550 354. [103] Grover L K 1997 Quantum Mechanics Helps in Searching for a Needle in a Haystack Phys. Rev.  [104] Alvarez-Rodriguez U, Sanz M, Lamata L, and Solano E 2015 The Forbidden Quantum Adder  Lett. 79, 325.  Sci. Rep. 5 11983.  [105] Oszmaniec M, Grudka A, Horodecki M, and W´ojcik A 2016 Creating a Superposition of Unknown  [106] Werfel J, Petersen K, and Nagpal R 2014 Designing collective behavior in a termite-inspired robot  Quantum States Phys. Rev. Lett. 116 110403.  construction team Science 343 754.  [107] Dittrich P, Ziegler J, and Banzhaf W 2001 Artiﬁcial chemistries – a review Artif. Life 7 225. [108] Baeck T, Fogel D, and Michalewicz Z. 1997. Handbook of Evolutionary Computation (Taylor &  Francis, London, UK).  [109] Benner S A and Sismour A M 2005 Synthetic biology Nat. Rev. Genet. 6, 533. [110] Preskill J 2018 Quantum Computing in the NISQ era and beyond Quantum 2 79.   
VII. CONCLUSION  In this study, we present a series of classiﬁcation experiments to ﬁnd requirements-relevant information in English app reviews as well as in English and Italian tweets. We applied supervised machine learning and compared traditional machine learning and deep learning approaches. We rely our results on a) 10,000 English and 15,000 Italian annotated tweets from telecommunication Twitter support accounts, and b) on 6,000 annotations of English app reviews. Our results show that, within our setting, traditional machine learning can achieve comparable results to deep learning, although we collected thousands of annotations for each channel.  ACKNOWLEDGEMENT  The work presented in this paper was conducted within the scope of the Horizon 2020 project OpenReq, which is supported by the European Union under the Grant Nr. 732463. The work was also supported by the “Forum4.0” project as part of the ahoi.digital funding line. We thank Davide Fucci for helping collect and analyze the Italian tweets.  REFERENCES  [1] J. Bergstra and Y. Bengio. Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13(Feb):281–305, 2012.  [2] J. S. Bergstra, R. Bardenet, Y. Bengio, and B. K´egl. Algorithms In Advances in neural information  for hyper-parameter optimization. processing systems, pages 2546–2554, 2011.  [3] N. Chen, J. Lin, S. C. Hoi, X. Xiao, and B. Zhang. Ar-miner: mining informative reviews for developers from mobile app marketplace. In Proceedings of the 36th International Conference on Software Engineering, pages 767–778. ACM, 2014.  [4] F. Chollet. Deep learning with Python. Manning Publications, 2018. [5] F. Chollet et al. Keras. https://keras.io, 2015. [6] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12(Aug):2493–2537, 2011.  [7] J. Davis and M. Goadrich. The relationship between precision-recall and roc curves. In Proceedings of the 23rd International Conference on Machine Learning, ICML ’06, pages 233–240, New York, NY, USA, 2006. ACM.  [8] V. T. Dhinakaran, R. Pulle, N. Ajmeri, and P. K. Murukannaiah. App review analysis via active learning: Reducing supervision effort without compromising classiﬁcation accuracy. 2018 IEEE 26th International Requirements Engineering Conference (RE), pages 170–181, 2018. [9] S. Fakhoury, V. Arnaoudova, C. Noiseux, F. Khomh, and G. Antoniol. Keep it simple: Is deep learning good for linguistic smell detection? In 2018 IEEE 25th International Conference on Software Analysis, Evolution and Reengineering (SANER), pages 602–611. IEEE, 2018.  [10] W. Fu and T. Menzies. Easy over hard: A case study on deep learning. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering, pages 49–60. ACM, 2017.  [11] I. Goodfellow, Y. Bengio, A. Courville, and Y. Bengio. Deep learning,  volume 1. MIT press Cambridge, 2016.  [12] E. Guzman, R. Alkadhi, and N. Seyff. A needle in a haystack: What In Requirements Engineering do twitter users say about software? Conference (RE), 2016 IEEE 24th International, pages 96–105. IEEE, 2016.  [13] E. Guzman, M. El-Haliby, and B. Bruegge. Ensemble Methods for App Review Classiﬁcation: An Approach for Software Evolution (N). In 2015 30th IEEE/ACM International Conference on Automated Software Engineering (ASE), pages 771–776, Nov. 2015.  [14] E. Guzman, M. Ibrahim, and M. Glinz. A little bird told me: mining In 2017 IEEE 25th tweets for requirements and software evolution. International Requirements Engineering Conference (RE), pages 11–20. IEEE, 2017.  [15] E. Guzman, M. Ibrahim, and M. Glinz. Prioritizing user feedback In 2017 IEEE/ACM 4th International from twitter: A survey report. Workshop on CrowdSourcing in Software Engineering (CSI-SE), pages 21–24. IEEE, 2017.  [16] E. Guzman and W. Maalej. How do users like this feature? a ﬁne grained sentiment analysis of app reviews. In Requirements Engineering Conference (RE), 2014 IEEE 22nd International, pages 153–162. IEEE, 2014.  [17] M. Harman, Y. Jia, and Y. Zhang. App store mining and analysis: Msr for app stores. In Proceedings of the 9th IEEE Working Conference on Mining Software Repositories, pages 108–111. IEEE Press, 2012. [18] M. H¨aring, W. Loosen, and W. Maalej. Who is Addressed in This Comment?: Automatically Classifying Meta-Comments in News Comments. Proc. ACM Hum.-Comput. Interact., 2(CSCW):67:1–67:20, Nov. 2018. [19] C. Iacob and R. Harrison. Retrieving and analyzing mobile apps feature In Proceedings of the 10th Working requests from online reviews. Conference on Mining Software Repositories, pages 41–44. IEEE Press, 2013.  [20] T. Johann, C. Stanik, A. M. A. B., and W. Maalej. Safe: A simple approach for feature extraction from app descriptions and app reviews. In 2017 IEEE 25th International Requirements Engineering Conference (RE), pages 21–30, Sep. 2017.  [21] A. Joulin, E. Grave, P. Bojanowski, M. Douze, H. J´egou, and T. Mikolov. arXiv preprint  Fasttext.zip: Compressing text classiﬁcation models. arXiv:1612.03651, 2016.  [22] Y. Kim. Convolutional neural networks for sentence classiﬁcation. arXiv  preprint arXiv:1408.5882, 2014.  [23] Z. Kurtanovi´c and W. Maalej. Automatically classifying functional and non-functional requirements using supervised machine learning. In 2017 IEEE 25th International Requirements Engineering Conference (RE), pages 490–495. IEEE, 2017.  [24] Z. Kurtanovi´c and W. Maalej. Mining user rationale from software In 2017 IEEE 25th International Requirements Engineering  reviews. Conference (RE), pages 61–70. IEEE, 2017.  [25] Z. Kurtanovi´c and W. Maalej. On user rationale in software engineering.  Requirements Engineering, 23(3):357–379, 2018.  [26] M. M. Lopez and J. Kalita.  Deep Learning applied to NLP.  arXiv:1703.03091 [cs], Mar. 2017. arXiv: 1703.03091.  [27] W. Maalej, Z. Kurtanovi´c, H. Nabil, and C. Stanik. On the automatic classiﬁcation of app reviews. Requirements Engineering, 21(3):311–331, Sep 2016.  [28] W. Maalej, M. Nayebi, T. Johann, and G. Ruhe. Toward data-driven  requirements engineering. IEEE Software, 33(1):48–54, 2016.  [29] T. Mikolov, K. Chen, G. Corrado, and J. Dean. Efﬁcient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.  [30] M. Nayebi, H. Cho, H. Farrahi, and G. Ruhe. App store mining is not enough. In 2017 IEEE/ACM 39th International Conference on Software Engineering Companion (ICSE-C), pages 152–154, May 2017.  [31] D. Pagano and W. Maalej. User feedback in the appstore: An empirical study. In Requirements Engineering Conference (RE), 2013 21st IEEE International, pages 125–134. IEEE, 2013.  [32] F. Palomba, M. Linares-Vasquez, G. Bavota, R. Oliveto, M. Di Penta, D. Poshyvanyk, and A. De Lucia. User reviews matter! tracking crowdsourced reviews to support evolution of successful apps. In 2015 IEEE international conference on software maintenance and evolution (ICSME), pages 291–300. IEEE, 2015.  [33] W. Song and J. Cai. End-to-end deep neural network for automatic  speech recognition. Standford CS224D Reports, 2015.  [34] K. Sparck Jones. A statistical interpretation of term speciﬁcity and its application in retrieval. Journal of documentation, 28(1):11–21, 1972. [35] M. Thelwall, K. Buckley, G. Paltoglou, D. Cai, and A. Kappas. Sentiment strength detection in short informal text. Journal of the Association for Information Science and Technology, 61(12):2544–2558, 2010. [36] L. Villarroel, G. Bavota, B. Russo, R. Oliveto, and M. Di Penta. Release planning of mobile apps based on user reviews. In 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). IEEE, 2016. [37] G. Williams and A. Mahmoud. Mining twitter feeds for software In 2017 IEEE 25th International Requirements  user requirements. Engineering Conference (RE), pages 1–10. IEEE, 2017.  [38] T. Young, D. Hazarika, S. Poria, and E. Cambria. Recent Trends in Deep Learning Based Natural Language Processing. arXiv:1708.02709 [cs], Aug. 2017. arXiv: 1708.02709.   
10 | DISCUSSION AND FUTURE WORK  From this analysis, we conclude that the interpretable models can indeed perform approximately as well as the black-box  models in various recidivism prediction problems, and much can be gained in interpretability for small sacriﬁces in  accuracy. On the Broward data set, we found that RiskSLIM, EBM, and Additive Stumps perform as well or better than  the best black-box models. On the Kentucky data set, we observed that EBM and Additive Stumps have extremely close  performance to the best black-box models—Random Forest and XGBoost— with average AUC differences around 1%,  which is less than the uncertainty gap.  We observed that machine learning models for six-month outcomes generally outperform those for two-year  outcomes (conditioning on the recidivism type). This may be because treatment/rehabilitation programs have a greater  chance of taking effect over a two-year time span (as compared to the six-month time span), altering the probability of  recidivism. Future work could investigate this hypothesis, or pose other hypotheses to explain this observation.  We also observed that machine learning models do not generalize well across states, perhaps due to differences  in the feature distributions between regions—in particular, we observed that the age distributions for Kentucky and  Broward County are considerably different. One might easily imagine regional feature distributions shifting over time  as well, which is supported by several studies [17, 81, 82, 83]. Even though these studies focused on disparate crime  types, they consistently observed a drop in the rate of offending among younger people since the 1990s. Studies have  explicitly shown that the distributions of age versus arrest rate has changed over time as well. For instance, Kim et al.  [17] has reported that in the state of New York, the mean age of the total arrested population increased by two years   WANG & HAN ET AL.  29  between 1990 and 2010. They hypothesized that a decrease in arrests in younger people and an increase in arrests in  older people together contributed to the increase in mean age.  There are many reasons why data would change over time and over jurisdictions. Changing policies (e.g., the NYC  stop and frisk program) could potentially alter who would be arrested and for what types of crime. New cultural phe nomena (e.g., in video games and media) could also inﬂuence people’s behavior at a large scale. The above observations  lead us to conclude that different recidivism prediction models could be constructed for different locations and should  be periodically updated. Machine learning models are well-suited for efﬁcient creation and updating of these kinds of  models. A possible future line of work is to separate the Kentucky data at the jurisdiction level, and perform a causal  analysis of the effects of different judicial and policing practices on the recidivism distribution.  Simple, transparent models have been used for criminal justice applications for almost a century [65, 84]. They  have the advantage that one can easily quantify the contributions of each feature to the predicted score. Judicial  actors without much statistics background can understand these scores, and use them to help solve societal issues.  Interpretable models are extremely valuable for current decision-making processes in criminal justice: they allow  error-checking, help ensure due process, and allow judges to incorporate information outside the database into their  decision-making process in a calibrated manner.  However, our work on interpretable risk prediction is only one step closer to what we view as the ultimate goal—  placing recidivism prediction into the framework of formal decision analysis. Decision-making in the context of decision  analysis involves the minimization of costs rather than risks. Towards this end, Lakkaraju and Rudin [85] considered  several costs related to pretrial release decisions; these include the societal cost of releasing an individual who might  commit a crime before their trial, the cost of assigning an ofﬁcer to an individual, and the cost to taxpayers of keeping an  individual incarcerated. The importance of risk predictions vary between decision-making problems (release, parole,  sentencing, etc.). In some cases, they play a minor role, yet in others, predictions may comprise the sole deciding factor.  Because of this, it would be useful to have a cost-beneﬁt analysis per decision that would help determine exactly when  and where risk scores should participate.  Hence, an important and necessary direction for the future work would be to incorporate the framework of  classical decision analysis into decision-making in the criminal justice system. Decision analysis tools would ideally  allow practitioners to strike a balance between relevant considerations (e.g., future risks to society, costs of treatment  programs to society, costs to families involved in the criminal justice system, costs to the individual, as well as more  traditional modelling objectives such as fairness, interpretability, transparency, and predictive performance). While  the full data measuring costs and risks to all stakeholders in the criminal justice process may never be available, it is  important to move in this direction, as this would bring us closer to more consistent and informed decision making.  A C K N O W L E D G E M E N T S  We acknowledge partial funding from Arnold Ventures, the Duke Computer Science Undergraduate Research Fellows  Program, the Lord Foundation of North Carolina and the Duke Department of Electrical and Computer Engineering.  This report represents the ﬁndings of the authors and does not represent the views of any of the funding agencies. We  thank the Broward County Sheriff’s ofﬁce and the Kentucky Department of Shared Services, Research and Statistics for  their assistance and provision of data. We would also like to thank Daniel Sturtevant from the Kentucky Department of  Shared Services, Research and Statistics for providing signiﬁcant insight into the Kentucky data set, and Berk Ustun for  his advice on training RiskSLIM. Finally, we thank Brandon Garrett from Duke, Stuart Buck and Kristin Bechtel from  Arnold Ventures, and Kathy Schiﬂett, Christy May, and Tara Blair from Kentucky Pretrial Services for their thoughtful  comments on the article.   30  C O D E  R E F E R E N C E S  Our code is here: https://github.com/BeanHam/interpretable-machine-learning  WANG & HAN ET AL.  [1] Berk R. An Impact Assessment of Machine Learning Risk Forecasts on Parole Board Decisions and Recidivism. Experi mental Criminology 2017 April;13:193–216.  [2] Larson J, Mattu S, Kirchner L, Angwin J. How We Analyzed the COMPAS Recidivism Algorithm. ProPublica; 2016.  [3] Freeman K. Algorithmic Injustice: How the Wisconsin Supreme Court Failed to Protect Due Process Rights in State V. Loomis. North Carolina Journal of Law & Technology 2016 December;18. http://ncjolt.org/wp-content/uploads/ 2016/12/Freeman_Final.pdf.  [4] Rudin C, Wang C, Coker B. The age of secrecy and unfairness in recidivism prediction. arXiv:181100731 2019 Novem ber;Accepted to Harvard Data Science Review.  [5] Flores AW, Lowenkamp CT, Bechtel K. False Positives, False Negatives, and False Analyses: A Rejoinder to “Machine Bias: There’s Software Used Across the Country to Predict Future Criminals". Federal probation 2016 September;80(2).  [6] Dieterich W, Mendoza C, Brennan T. COMPAS Risk Scales: Demonstrating Accuracy Equity and Predictive Parity: Per formance of the COMPAS Risk Scales in Broward County; 2016.  [7] Barabas C, Dinakar K, Doyle C. The Problems With Risk Assessment Tools. The New York Times 2019 July;https:  //www.nytimes.com/2019/07/17/opinion/pretrial-ai.html.  [8] O’Neil C. Weapons of Math Destruction. Crown Books; 2016.  [9] Wexler R. When a Computer Program Keeps You in Jail: How Computers are Harming Criminal Justice. New York  Times 2017 June;p. 27. Section A.  [10] Zeng J, Ustun B, Rudin C. Interpretable classiﬁcation models for recidivism prediction. Journal of the Royal Statistical  Society: Series A (Statistics in Society) 2017;180(3):689–722.  [11] Angelino E, Larus-Stone N, Alabi D, Seltzer M, Rudin C. Certiﬁably optimal rule lists for categorical data. Journal of  Machine Learning Research 2018;19:1–79.  [12] Lou Y, Caruana R, Gehrke J, Hooker G. Accurate intelligible models with pairwise interactions.  In: 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD); 2013. p. 623–631. DOI: 10.1145/2487575.2487579.  [13] Soares E, Angelov PP. Fair-by-design explainable models for prediction of recidivism. ArXiv 2019;abs/1910.02043.  [14] MHS Assessments. Level of Service/Case Management Inventory: An Offender Management System. MHS Public  Safety 2017;https://issuu.com/mhs-assessments/docs/ls-cmi.lsi-r.brochure_insequence.  [15] Northpointe. Practitioner’s Guide to COMPAS Core; 2013, http://www.northpointeinc.com/downloads/compas/  Practitioners-Guide-COMPAS-Core-_031915.pdf.  [16] Gelb A, Velazquez T, Trust PC, of America US. The Changing State of Recidivism: Fewer People Going Back to Prison.  The Pew Charitable Trusts 2018;.  [17] Kim J, Bushway S, Tsao H. Identifying Classes of Explanation for Crime Drop: Period and Cohort Effects for New York  State. Journal of Quantitative Criminology 2016;32:357–375.   WANG & HAN ET AL.  31  [18] Bureau of Justice Assistance; Bureau of Justice Assistance. History of Risk Assessment. Bureau of Justice Assistance  2020;https://psrac.bja.ojp.gov/basics/history.  [19] Kehl D, Guo P, Kessler S. Algorithms in the Criminal Justice System: Assessing the Use of Risk Assessments in Sentenc ing. 2017 July;https://cyber.harvard.edu/publications/2017/07/Algorithms.  [20] Public Safety Assessment. Risk Factors and Formulas. Laura and John Arnold Foundation 2019 9;(https://www.  psapretrial.org/about/).  [21] Latessa E, Smith P, Lemke R, Makarios M, Lowenkamp C. Creation and Validation of the Ohio Risk Assessment System.  University of Cincinnati School of Criminal Justice Center for Criminal Justice Research; 2009.  [22] Electronic Privacy Information Center. Algorithms in the Criminal Justice System. Electronic Privacy Information  Center 2016 6;https://epic.org/algorithmic-transparency/crim-justice/.  [23] Hanson R, Thornton D. Notes on the development of Static-2002. Ottawa, Ontario: Department of the Solicitor Gen eral of Canada 2003;.  [24] Tollenaar N, van der Heijden PGM. Which method predicts recidivism best?: a comparison of statistical, machine learning and data mining predictive models. Journal of the Royal Statistical Society: Series A (Statistics in Society) 2013;176(2):565–584.  [25] Howard P, Francis B, Soothill K, Humphreys L. OGRS 3: The revised offender group reconviction scale. Ministry of  Justice; 2009.  [26] Dawes RM, Faust D, Meehl PE. Clinical versus actuarial judgment. Science 1989;243(4899):1668–1674.  [27] Grove WM, Meehl PE. Comparative efﬁciency of informal (subjective, impressionistic) and formal (mechanical, algorithmic) prediction procedures: The clinical–statistical controversy. Psychology, Public Policy, and Law 1996;2(2):293.  [28] Wolfgang ME. Delinquency in a birth cohort. University of Chicago Press; 1987.  [29] Sherman LW. The power few: experimental criminology and the reduction of harm. Journal of Experimental Criminol ogy 2007;3(4):299–321.  [30] Milgram A, Milgram A, editor, Why smart statistics are the key to ﬁghting crime. Ted Talk; 2014.  [31] James N. Risk and Needs Assessment in the Federal Prison System. Congressional Research Service; 2018.  [32] Zweig J.  Extraordinary Conditions Of Release Under The Bail Reform Act. Harvard Journal On Legislation  2010;47:555–585.  [33] Desmarais S, Garrett B, Rudin C. Risk Assessment Tools Are Not A Failed ’Minority Report’.  Law360 2019 July;https://www.law360.com/access-to-justice/articles/1180373/risk-assessment-tools-are-not-a-failedminority-report-.  [34] The Leadership Conference on Civil and Human Rights. The Use of Pretrial "Risk Assessment" Instrument: A Shared Statement of Civil Rights Concerns. 2018 August;http://civilrightsdocs.info/pdf/criminal-justice/PretrialRisk-Assessment-Full.pdf.  [35] Pretrial Justice Institute. Updated Position on Pretrial Risk Assessment Tools. Pretrial Justice Institute 2020;https:  //www.pretrial.org/wp-content/uploads/Risk-Statement-PJI-2020.pdf.  [36] Angwin J, Larson J, Mattu S, Kirchner L. Machine Bias. ProPublica; 2016.  [37] Stevenson M. Assessing Risk Assessment in Action. Minnesota Law Review 2018;http://www.minnesotalawreview.  org/wp-content/uploads/2019/01/13Stevenson_MLR.pdf.   32  WANG & HAN ET AL.  [38] Skeem J, Lin Z, Jung J, Goel S. The limits of human predictions of recidivism. Science Advances 2020;6.  [39] Garrett B, Stevenson M. Open Risk Assessments. Behavioral Science & Law 2020;https://sites.law.duke.edu/ justsciencelab/2019/09/15/comment-on-pattern-by-brandon-l-garrett-megan-t-stevenson/, forthcoming.  [40] Roberts J, von Hirsch A. Previous Convictions at Sentening - Theoretical and Applied Perspective. Bloomsbury Publish ing; 2010.  [41] Frase RS, Roberts J, Hester R, Mitchell KL, of Criminal Law RI, Justice C, editors, Robina Institute of Criminal Law and Criminal Justice, Criminal History Enhancements Sourcebook. Robina Institute of Criminal Law and Criminal Justice; 2015. https://robinainstitute.umn.edu/publications/criminal-history-enhancements-sourcebook.  [42] Starr SB. The Risk Assessment Era: An Overdue Debate. Federal Sentencing Reporter 2015 April;27:205–206.  [43] American Law Institute, Model Penal Code; 2017. https://www.ali.org/projects/show/sentencing/.  [44] Neuilly MA, Zgoba KM, Tita GE, Lee SS. Predicting recidivism in homicide offenders using classiﬁcation tree analysis.  Homicide studies 2011;15(2):154–176.  [45] Friedman JH. Stochastic gradient boosting. Computational Statistics &amp; Data Analysis 2002;38(4):367–378.  [46] Palocsay SW, PingWang, Brookshire RG. Predicting criminal recidivism using neural networks. Socio-Economic Plan ning Sciences 2000 December;34:271–284.  [47] Berk RA, He Y, Sorenson SB. Developing a practical forecasting screener for domestic violence incidents. Evaluation  Review 2005;29(4):358–383.  [48] Goel S, Rao JM, Shroff R. Precinct or Prejudice? Understanding Racial Disparities in New York City’s Stop-And-Frisk  Policy. Institute of Mathematical Statistics 2016;10(1):365–394.  [49] Rudin C. Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models  Instead. Nature Machine Intelligence 2019 May;1:206–215.  [50] Hardt M, Price E, Srebro N. Equality of opportunity in supervised learning. In: Advances in neural information process ing systems; 2016. p. 3315–3323.  arXiv:180302453 2018;.  arXiv:160905807 2016 November;.  January;81:1–11.  2018. p. 1–7.  [51] Agarwal A, Beygelzimer A, Dudík M, Langford J, Wallach H. A reductions approach to fair classiﬁcation. arXiv preprint  [52] Kleinberg J, Mullainathan S, Raghavan M.  Inherent Trade-Offs in the Fair Determination of Risk Scores.  [53] Pleiss G, Raghavan M, Wu F, Kleinberg J, Weinberger K. On fairness and calibration. In: Advances in Neural Information  Processing Systems; 2017. p. 5680–5689.  [54] Binns R. Fairness in Machine Learning: Lessons from Political Philosophy. Journal of Machine Learning Research 2018  [55] Verma S, Rubin J. Fairness Deﬁnitions Explained. In: ACM/IEEE International Workshop on Software Fairness ACM;  [56] Berk R, Heidari H, Jabbari S, Kearns M, Roth A. Fairness in Criminal Justice Risk Assessments: The State of the Art.  Sociological Methods & Research 2017 03;.  [57] Berk R. Accuracy and Fairness for Juvenile Justice Risk Assessments.  Journal of Empirical Legal Studies 2019  March;16(1):174–194.   WANG & HAN ET AL.  33  [58] Corbett-Davies S, Pierson E, Feller A, Goel S, Huq A. Algorithmic decision making and the cost of fairness. In: In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; 2017. p. 797–806.  [59] Barocas S, Selbst AD. Big Data’s Disparate Impact. California Law Review 2016;104:671–732.  [60] Corbett-Davies S, Goel S. The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning.  arXiv:180800023v2 2018 August;.  [61] Vapnik V, Chervonenkis A. A note on one class of perceptrons. Automation and Remote Control 1964;25.  [62] Breiman L, Friedman J, Stone CJ, Olshen RA. Classiﬁcation and regression trees. CRC press; 1984.  [63] Freund Y, Schapire RE. A decision-theoretic generalization of on-line learning and an application to boosting. Journal  of computer and system sciences 1997;55(1):119–139.  [64] Chen T, Guestrin C. Xgboost: A scalable tree boosting system. In: Proceedings of the 22nd acm sigkdd international  conference on knowledge discovery and data mining; 2016. p. 785–794.  [65] Burgess EW, on Indeterminate-Sentence Law IC, Parole Springﬁeld I, editors, Factors determining success or failure on  parole. Illinois Committee on Indeterminate-Sentence Law and Parole Springﬁeld, IL; 1928.  [66] Ustun B, Rudin C. Optimized Risk Scores.  In: Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining KDD ’17, New York, NY, USA: ACM; 2017. p. 1125–1134. http://doi.acm. org/10.1145/3097983.3098161.  [67] Stevenson MT, Slobogin C. Algorithmic Risk Assessments and the Double-Edged Sword of Youth. Washington University Law Review 2018;96(Vanderbilt Law Research Paper No. 18-36). http://dx.doi.org/10.2139/ssrn.3225350.  [68] Bindler A, Hjalmarsson R. How punishment severity affects jury verdicts: Evidence from two natural experiments.  American Economic Journal: Economic Policy 2018;10.  [69] Bushway SD, Piehl AM. The inextricable link between age and criminal history in sentencing. Crime & Delinquency  2007;53(1):156–183.  table/KY,US/PST045219.  [70] United States Census Bureau. QuickFacts: Kentucy; United States. 2019;https://www.census.gov/quickfacts/fact/  [71] United States Census Bureau. Hispanic or Latino Origin By Race 2011-2015 American Community Survey 5-Year Estimates. 2015;https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_15_ 5YR_B03002&prodType=table.  [72] Mishra A. Climate and Crime. Global Journal of Science Frontier Research: H, Environment & Earth Science 2014;14.  [73] Ranson M. Crime, weather, and climate change. Journal of Environmental Economics and Management 2014;67.  [74] Defronzo J. Climate and Crime: Tests of an FBI Assumption. Environment and Behavior 1984;16.  [75] Kleiman M, Ostrom BJ, Cheesman FL. Using risk assessment to inform sentencing decisions for nonviolent offenders  in Virginia. Crime & Delinquency 2007;53(1):106–132.  [76] Dwork C, Hardt M, Pitassi T, Reingold O, Zemel R. Fairness Through Awareness. In: Proceedings of the 3rd Innovations in Theoretical Computer Science Conference ITCS ’12, New York, NY, USA: ACM; 2012. p. 214–226. http://doi.acm. org/10.1145/2090236.2090255.  [77] Chouldechova A. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data  2017;5(2):153–163.   34  WANG & HAN ET AL.  [78] Zemel R, Wu Y, Swersky K, Pitassi T, Dwork C. Learning fair representations. In: International Conference on Machine  Learning; 2013. p. 325–333.  preprint arXiv:170602409 2017;.  arXiv:190512843 2019;.  37.  [79] Berk R, Heidari H, Jabbari S, Joseph M, Kearns M, Morgenstern J, et al. A convex framework for fair regression. arXiv  [80] Agarwal A, Dudík M, Wu ZS. Fair Regression: Quantitative Deﬁnitions and Reduction-based Algorithms. arXiv preprint  [81] Cook P, Laub J. After the Epidemic Recent Trends in Youth Violence in the United States. Crime and Justice 2002;29:1–  [82] Alfred B. The Crime Drop in America: An Explanation of Some Recent Crime Trends. Journal of Scandinavian Studies  in Criminology and Crime Prevention 2006;7:17–35.  [83] Matthews B, Minton J. Rethinking one of the criminology’s ’brute facts’: The age-crime curve and the crime drop in  Scotland. European Journal of Criminology 2017;15(3):296–320.  [84] Hart H. Predicting Parole Success. Journal of Criminal Law and Criminology 1924;14.  [85] Lakkaraju H, Rudin C. Learning Cost-Effective and Interpretable Treatment Regimes. In: Singh A, Zhu J, editors. Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics, vol. 54 of Proceedings of Machine Learning Research Fort Lauderdale, FL, USA: PMLR; 2017. p. 166–175. http://proceedings.mlr.press/v54/ lakkaraju17a.html.  [86] Brennan T, Dieterich W, Ehret B. Evaluating the Predictive Validity of the COMPAS Risk and Needs Assessment System.  Criminal Justice and Behavior 2009 January;36(1):21–40.  [87] Northpointe Inc . Measurement & Treatment Implications of COMPAS Core Scales; 2009.  [88] Carollo J, Hedlund J, Hines M. Expanded Validation of a Decision Aid for Pretrial Conditional Release; 2007.  [89] The Colorado Pretrial Assessment Tool (CPAT): Administration, Scoring, and Reporting Manual. Colorado Association of Pretrial Services; 2015, https://university.pretrial.org/HigherLogic/System/DownloadDocumentFile. ashx?DocumentFileKey=47e978bb-3945-9591-7a4f-77755959c5f5.  [90] Turner S, Hess J, Jannetta J. Development of the California Static Risk Assessment Instrument (CSRA). CEBC Working  Papers 2009;.  2011;75(2).  [91] Cadigan TP, Lowenkamp CT. Implementing Risk Assessment in the Federal Pretrial Services System. Federal Probation  [92] Hoffman PB, Adelberg S. The Salient Factor Score: A Nontechnical Overview. Fed Probation 1980;44:44.  [93] Nafekh M, Motiuk LL. The Statistical Information on Recidivism, Revised 1 (SIR-R1) Scale: A Psychometric Examination.  Correctional Service of Canada. Research Branch; 2002.  [94] Orbis, Orbis, editor, Service Planning Instrument: An Innovative Assessment and Case Planning Tool. Orbis; 2014.  https://orbispartners.com/wp-content/uploads/2014/07/SPIn-Brochure.pdf.  [95] Lazarsfeld PF. An Evaluation of the Pretrial Services Agency of the Vera Institute of Justice. New York: Vera Institute  1974;.  [96] Harris GT, Rice ME. Violence Risk Appraisal Guide (VRAG). In: Cutler BL, editor. Encyclopedia of Psychology and Law SAGE Publications, Inc.; 2008. p. 848. https://sk.sagepub.com/reference/download/psychologylaw/n345.pdf.   WANG & HAN ET AL.  35  [97] Virginia Pretrial Risk Assessment Instrument - (VPRAI). Virginia Department of Criminal Justice Services; 2018,  https://www.dcjs.virginia.gov/sites/dcjs.virginia.gov/files/publications/corrections/virginia-pretrialrisk-assessment-instrument-vprai_0.pdf.  [98] Fan RE, Chang KW, Hsieh CJ, Wang XR, Lin CJ. LIBLINEAR: A Library for Large Linear Classiﬁcation. J Mach Learn Res  2008 Jun;9:1871–1874.  [99] Smith B. Auditing Deep Neural Networks to Understand Recidivism Predictions. PhD thesis, Haverford College; 2016.  [100] Ustun B, Rudin C. Supersparse linear integer models for optimized medical scoring systems. Machine Learning 2015;p.  1–43. http://dx.doi.org/10.1007/s10994-015-5528-6.  11 | APPENDIX  11.1 | Broward Data Processing  The Broward County data set consists of publicly available criminal history, court data and COMPAS scores from  Broward County, Florida. The criminal history and demographic information were computed from raw data released by  ProPublica [36]. The probational history was computed from public criminal records released by the Broward Clerk’s  Ofﬁce.  The screening date is the date on which the COMPAS score was calculated. The features and labels were computed  for an individual with respect to a particular screening date. For individuals who have multiple screening dates, we  compute the features for each screening date, such that the set of events for calculating features for earlier screening  dates is included in the set of events for later screening dates. On occasion, an individual will have multiple COMPAS  scores calculated on the same date. There appears to be no information distinguishing these scores other than their  identiﬁcation number, so we take the scores with the larger identiﬁcation number.  The recidivism labels were computed for the timescales of six months and two years. Some individuals were  sentenced to prison as a result of their offense(s). We used only observations for which we have six months/two years  of data subsequent to the individual’s release date.  Below, we describe details of the feature and label generation process.  •  •  •  • Degree “(0)” charges seem to be very minor offenses, so we exclude these charges. We infer whether a charge is a  felony, misdemeanor, or trafﬁc charge based off the charge degree.  Some of our features rely on classifying the type of each offense (e.g., whether or not it is a violent offense). We  infer this from the statute number, most of which correspond to statute numbers from the Florida state crime code.  The raw Propublica data includes arrest data as well as charge data. Because the arrest data does not include the  statute, which is necessary for us to determine offense type, we use the charge data to compute features that  require the offense type. We use both charge and arrest data to predict recidivism.  For each person on each COMPAS screening date, we identify the offense—which we call the current offense—that  most likely triggered the COMPAS screening. The current offense date is the date of the most recent charge that  occurred on or before the COMPAS screening date. Any charge that occurred on the current offense date is part  of the current offense. In some cases, there is no prior charge that occurred near the COMPAS screening date,  suggesting charges may be missing from the data set. For this reason we consider charges that occurred within  30 days of the screening date for computing the current offense. If there are no charges in this range, we say the  current offense is missing. We exclude observations with missing current offenses. We used some of the COMPAS   36  •  •  •  •  •  WANG & HAN ET AL.  subscale items as features for our machine learning models. All such components of the COMPAS subscales that  we compute are based on data that occurred prior to (not including) the current offense date.  The events/documents data includes a number of events (e.g., “File Afﬁdavit Of Defense” or “File Order Dismissing  Appeal”) related to each case, and thus to each person. To determine how many prior offenses occurred while on  probation, or if the current offense occurred while on probation, we deﬁne a list of event descriptions indicating  that an individual was taken on or off probation. Unfortunately, there appear to be missing events, as individuals  often have consecutive “On” or consecutive “Off” events (e.g., two “On” events in a row, without an “Off” in between). In these cases, or if the ﬁrst event is an “Off” event or the last event is an “On” event, we deﬁne two thresholds, t on and t of f . If an offense occurred within t on days after an “On” event or t of f days before an “Off” event, we count the offense as occurring while on probation. We set t on to 365 and t of f to 30. On the other hand, the “number of times on probation” feature is just the count of “On” events and the “number of times the probation was revoked” feature  is just the count of “File order of Revocation of Probation” event descriptions (i.e., we do not infer missing probation  events for these two features).  • Current age is deﬁned as the age in years, rounded down to the nearest integer, on the COMPAS screening date. • A juvenile charge is deﬁned as an offense that occurred prior to the defendant’s 18th birthday.  Labels and features were computed using charge data.  The ﬁnal data set contains 1,954 records and 41 features.  11.2 | Kentucky Data Processing  The Kentucky pretrial and criminal court data was provided by the Department of Shared Services, Research and  Statistics in Kentucky. The Pretrial Services Information Management System (PRIM) data contains records regarding  defendants, interviews, PRIM cases, bonds etc., that are connected with the pretrial services’ interviews conducted  between July 1, 2009 and June 30, 2018. The cases were restricted to have misdemeanor, felony, and other level charges.  The data from another system, CourtNet, provided further information about cases, charges, sentences, dispositions  etc. for CourtNet cases matched in the PRIM system. The Kentucky data can be accessed through a special data request  to the Kentucky Department of Shared Services, Research and Statistics.  CourtNet and PRIM data were processed separately and then combined together. We describe the details below:  For the CourtNet data, we ﬁltered out cases with ﬁling date prior to Jan. 1st, 1996, which were claimed to be less  reliable records by the Kentucky Department of Shared Services, Research and Statistics (which provided the  data). To investigate what types of crimes the individuals were involved in for each charge, such as drug, property,  trafﬁc-related crime, we used the Kentucky Uniform Crime Reporting Code (UOR Code), as well as detecting  keywords in the UOR description.  From the PRIM system data, we extracted the probation, failure to appear, case pending, and violent charge  information at the PRIM case level, as well as the Arnold PSA risk scores computed at the time of each pretrial  services’ interview. Since Kentucky did not use Arnold PSA until July 1st, 2013, we ﬁltered out records before the  this date. We omitted records without risk scores since we want to compare the performance of the PSA with other  models. Only 33 records are missing PSA scores; therefore we do not worry about missing records impacting the  results. Additionally, some cases in the PRIM system have “indictment” for the arrest type, along with an “original”  arrest case ID, indicating that those cases were not new arrests. We matched these cases with the records that  correspond to the original arrests to avoid overcounting the number of prior arrests. Then we inner-joined the data  from the two systems using person-id and prim-case-id.   WANG & HAN ET AL.  37  •  •  •  For each individual, we used the date that is two years before the latest charge date in the Kentucky data, as a  cutoff date. The data before the cutoff are used as criminal history information to compute features. The data  after the cutoff are used to compute labels and check recidivism. In the data before the cutoff, the latest charge is  treated as the current charge (i.e., the charge that would trigger a risk-assessment) for each individual. We compute  features and construct labels using only convicted charges. However, the current charge can be either convicted or  non-convicted. This ensures that our analysis includes all individuals that would receive a risk assessment, even  if they were later found innocent of the current charge that triggered the risk assessment. It also ensures that  criminal history features use only convicted charges, so that our risk assessments are not inﬂuenced by charges for  crimes that the person may not have committed.  In order to compute the labels, we must ensure that there are at least two years of data following an individual’s  current charge date. For individuals who are sentenced to prison due to their current charge, we consider their  release date instead of the current charge date. We omitted individuals for whom there were less than two years of  data between their current charge date or release date, and the last date recorded in the data set.  To get the age at current charge information, we ﬁrst calculated the date of birth (DOB) for each individual, using  CourtNet case ﬁling date and age at the CourtNet case ﬁling date. Then we calculated “age at current charge” using  the DOB and charge date (the charge date sometimes differs from the case ﬁling date). Notice that there are many  errors in age records in the data. For instance, some people have age recorded over 150, which is certainly wrong  but there is no way to correct it. To ensure the quality of our data, we limited the ﬁnal current age feature to be  inclusively between 18 and 70. This is also consistent with the range from Broward analysis. If the person was  not sentenced to prison, we deﬁne current age as the age at current charge date. If the person was sentenced to  prison, we compute current age by adding the sentence time to the age at the current charge date. Note that this  differs from the way risk scores are computed in practice—usually risk scores are computed prior to the sentencing  decision. This helps to handle distributional shift between the individuals with no prison sentence (for whom a  2-year evaluation can be handled directly) and the full population (some of whom may have been sentenced to  prison and cannot commit a crime during their sentence).  • We computed features using the data before the current charge date. The CourtNet data is organized by CourtNet cases, and each CourtNet case has charge level data. The PRIM data is organized by PRIM cases. Each CourtNet case can connect to multiple PRIM cases.14 Therefore, to compute the criminal history information, we ﬁrst grouped  on PRIM case level to summarize the charge information. Next, we grouped on CourtNet case level to summarize  PRIM case level information. Last, we grouped on the individual level to summarize the criminal histories.  • On computing the ADE feature: The ADE feature means number of times the individual was assigned to alcohol and drug education classes. Note that by Kentucky state law, any individual convicted for a DUI is assigned to ADE  classes. This does not indicate whether the individual successfully completed ADE classes.  • We compute labels using the two years of data after the current charge date/release date. We constructed the general recidivism labels by checking whether a “convicted charge” occurred within two years or six months from the current charge (or release date). Then, using the charge types of the convicted charge, other recidivism  prediction labels were generated, such as drug or property-related recidivism. The ﬁnal data set contains 250,778  Note: there are degrees of experimenter freedom in some of these data processing choices; exploring all the possible choices  records and 40 features.  here is left for future studies.  The Arnold PSA features that were included in the Kentucky data set (e.g., prior convictions, prior felony convictions  14This occurs because a new PRIM case is logged when an update occurs in the defendant’s CourtNet case (for example, if the defendant fails to appear in court).   38  WANG & HAN ET AL.  etc.) were computed by pretrial ofﬁcers who had access to criminal history data from both inside and outside of Kentucky.  However, the Kentucky data set we received contained criminal history information from within Kentucky only. Thus,  the Arnold PSA features for Kentucky (which are included in our models as well) use both in-state and out-of-state  information, but the remaining features (which we compute directly from the Kentucky criminal history data) are limited  to in-state criminal history.  Additionally, we were informed by Kentucky Pretrial Services team that the data set ’s sentencing information  may not be reliable due to unmeasured confounding, including shock probation and early releases that would allow  a prisoner to be released much earlier than the end date of the sentence. Because the sentence could be anywhere  from zero days to the full length, we conducted a sensitivity analysis by excluding the sentence information in the data  processing, which is equivalent to the assumption that no prison sentence was served. For that analysis, the current age  of each individual was calculated to be the age at the current charge, and the prediction labels were generated from  new charges within six months (or two years) from the current charge. The sensitivity analysis yielded predictive results  that were almost exactly the same as the results in the main text, when the sentence information was used to determine  age and prediction interval.  11.3 | Why We Compare Only Against COMPAS and the PSA  The variables included in risk assessments are often categorized into static and dynamic factors. Static factors are deﬁned  as factors that cannot be reduced over time (e.g. criminal history, gender, and age-at-ﬁrst-arrest). Dynamic factors  are deﬁned as variables that can change over time to decrease the risk of recidivism; they allow insight into whether a  high-risk individual can lower their risk through rehabilitation, and sometimes improve prediction accuracy. Examples  of dynamic factors include current age, treatment for substance abuse, and mental health status [19]. Dynamic factors  are often included in risk-and-needs-assessments (RNAs), which in addition to identifying risk of recidivism, recommend  interventions to practitioners (e.g., treatment programs, social services, diversion of individuals from jail).  With the exception of current age, our features all fall under the “static” classiﬁcation. This renders us unable to  compare against the risk assessment tools that use dynamic factors, whose formulas are public. The risk assessments  that we examined are listed in Table 4. Since we have only criminal history and age variables, the only model we could  compute from our data was the Arnold PSA.  However, as we demonstrated in the main body of the paper, the fact that we do not possess dynamic factors is  not necessarily harmful to the predictive performance of our models. The goal behind including dynamic factors in  models is to improve prediction accuracy as well as be able to recommend interventions that reduce the probability of  recidivism. While an admirable goal, the inclusion of dynamic factors does not come at zero cost and may not actually  produce performance gains for recidivism prediction. In Sections 6 and 7, we show that standard machine learning  techniques (using only the static factors) and interpretable machine learning models (using only static factors) are  able to outperform a criminal justice model that utilizes both static and dynamic factors (COMPAS). Furthermore, the  inclusion of additional, unnecessary factors increases the risk of data entry errors, or exposes models to additional  feature bias [60]. As Rudin et al. [4] reveals, data entry errors appear to be common in COMPAS score calculations and  could lead to scores that are either too high or too low.  Although the COMPAS suite is a proprietary (and thus black-box) risk-and-needs assessment, we were still able  to compare against its risk assessments thanks to the Florida’s strong open-records laws. Created by Northpointe (a  subsidiary company of Equivant), COMPAS is a recidivism prediction suite which is used in criminal justice systems  throughout the United States. It is comprised of three scores: Risk of General Recidivism, Risk of Violent Recidivism,  and Risk of Failure to Appear. In this work, we examine the two risk scores relating to violent recidivism and general   WANG & HAN ET AL.  39  recidivism. Each risk score is an integer from one to ten [86].  As COMPAS scores are proprietary instruments, the precise forms of its models are not publicly available. How ever, it is known that the COMPAS scores are computed from a subset of 137 input variables that include voca tional/educational status, substance abuse, and probational history, in addition to the standard criminal history vari ables [86]. As such, we cannot directly compute these risk scores, and instead utilize the COMPAS scores released by  ProPublica in the Broward County recidivism data set. We do not compare against COMPAS on the Kentucky data set,  as our data set does not include COMPAS scores.  The PSA was created by Arnold Ventures, and is a publicly available risk assessment tool. Similar to the COMPAS  suite, it is comprised of three risk scores: Failure to Appear, New Criminal Activity, and New Violent Criminal Activity.  Again, we compare against latter two scores. Both are additive integer models which take nine factors as input, relating  to age, current charge, and criminal history. The New Criminal Activity model outputs a score from 1 to 6, while the New  Violent Criminal Activity model outputs a binary score [20]. The PSA is an interpretable model.  TA B L E 4 Variable comparison for currently-utilized actuarial risk assessments. We only have criminal history and age variables, but most models include many other variables. Abbreviations are: Correctional Offender Management Proﬁling for Alternative Sanctions (COMPAS); Connecticut Risk Assessment for Pretrial Decision Making (Connecticut); Colorado Pretrial Risk Assessment Tool (CPAT); California Static Risk Assessment (CSRA); Ohio Risk Assessment System (ORAS); Level-of-Service Case Management Inventory (LSI-CMR); Public Service Assessment(PSA); (Federal) Pretrial Risk Assessment (PTRA); Statistical Information on Recidivism Score (SIRS); Service Planning Instruments (SPIn); Vera Point Scale (VERA); Violence Risk Appraisal Guide (VRAG); Virginia Pretrial Risk Assessment Instrument (VPRAI).  Models  Criminal History Age  Finance Residential Info  Edu/Emp  Peer/Family Mental Health Alc/Subs Abuse Other  COMPAS [87]  Connecticut [88]  CPAT [89]  CSRA [90]  ORAS [21]  LSI-CMI [14]  PSA [20]  PTRA [91]  SIRS [93]  SPIn [94]  VERA [95]  VRAG [96]  VPRAI [97]  Salient Factor [92]  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X  X   40  WANG & HAN ET AL.  11.4 | Hyperparameters  | Baseline Models, CART, EBM  We applied nested cross validation to tune the hyperparameters. Please refer to Table 5 for parameter details.  TA B L E 5 Hyperparameters for (cid:96)1 and (cid:96)2 Penalized Logistic Regression, Linear SVM, CART, Random Forest, XGBoost, and EBM. RiskSLIM and Additive Stumps are discussed separately.  Models  Kentucky  Broward  (cid:96)2 Logistic Regression class_weight: balanced  class_weight: balanced  solver: liblinear[98]  solver: liblinear  penalty: (cid:96)2 C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]  penalty: (cid:96)2 C ∈ 100 values in [1e-5, 1e-2]  (cid:96)1 Logistic Regression class_weight: balanced  solver: liblinear  class_weight: balanced  solver: liblinear  penalty: (cid:96)1 C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]  penalty: (cid:96)1 C ∈ 100 values in [1e-5, 1e-2]  LinearSVM  C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]  C ∈ 100 values in [1e-5, 1e-2]  CART  max_depth ∈ [5,6,7,8,9,10]  Random Forest  n_estimator ∈ [100,150,200] max_depth ∈ [7,8,9]  max_depth ∈ [1,2,3,4,5] min_impurity_decrease ∈ [1e-3, 2e-3, . . . 5e-3]  n_estimator ∈ [50,100,200,400,600] max_depth ∈ [1,2,3] min_impurity_decrease ∈ [1e-3, 2e-3, . . . , 1e-2]  XGBoost  learning_rate ∈ [0.1] n_estimator ∈ [100,150] max_depth ∈ [4,5,6]  EBM 15  n_estimator ∈ [60] max_tree_splits ∈ [2] learning_rate ∈ [0.1]  learning_rate ∈ [0.05] n_estimator ∈ [50,100,200,400,600] max_depth ∈ [1,2,3] gamma ∈ [6,8,10,12] min_child_weight ∈ [6,8,10,12] subsample ∈ [0.5]  n_estimator ∈ [40,60,80,100] max_tree_splits ∈ [1,2,3] learning_rate ∈ [0.01] holdout_split ∈ [0.7, 0.9]  | Additive Stumps  Stumps were created for each feature as detailed in Section 7.1. An additive model was created from the stumps  using (cid:96)1-penalized logistic regression, and no more than 15 original features were involved in the additive models. But multiple stumps corresponding to each feature could be used in the models. We chose to limit the size of the model to  15 original features because then at most 15 plots would be generated to visualize the full model, which is a reasonable  number of visualizations for users to digest.  We started with the smallest regularization parameter on (cid:96)1 penalty that provides at most 15 original features from the model. This will be our lower bound for nested cross validation. From there, we perform nested cross validation over  a grid of regularization parameters, all of which are greater than or equal to the minimum value of the regularization  parameter found above. Please refer to Table 6 for more details.  15The training procedure is slow for EBM, due to the size of Kentucky data, the nested cross validation we applied, and the cross-validation within the algorithm  to choose number of pairwise interactions. Therefore, we tested only one set of parameters, which gave reliable results.   WANG & HAN ET AL.  41  TA B L E 6 Hyperparameters for Additive Stumps  Models  Two Year  Six Month  Two Year  Six Month  Kentucky  Broward  General  C ∈ [1e-3, 2e-3]  C ∈ [1e-3, 1.5e-3]  C ∈ [1e-2, 2e-2. . . 1e-1]  C ∈ [1e-2, 2e-2. . . 1e-1]  Violent  C ∈ [6e-4, 8e-4, 1e-3]  C ∈ [5e-4, 7e-4]  C ∈ [1e-2, 2e-2 . . . 7e-2]  C ∈ [1e-2, 2e-2 . . . 7e-2]  Drug  C ∈ [1e-3, 2e-3, 2.5e-3]  C ∈ [1e-3, 2e-3]  C ∈ [1e-2, 2e-2 . . . 9e-2]  C ∈ [1e-2, 2e-2 . . . 6e-2]  Property  C ∈ [1e-3, 1.5e-3]  C ∈ [1e-3, 1.5e-3]  C ∈ [1e-2, 2e-2 . . . 8e-2]  C ∈ [1e-2, 2e-2 . . . 6e-2]  Felony  C ∈ [1e-3, 1.5e-3]  Misdemeanor C ∈ [1e-3, 1.5e-3]  C ∈ [5e-4, 8e-4]  C ∈ [5e-4, 1e-3]  C ∈ [1e-2, 2e-2 . . . 8e-2]  C ∈ [1e-2, 2e-2 . . . 8e-2]  C ∈ [1e-2, 2e-2 . . . 7e-2]  C ∈ [1e-2, 2e-2 . . . 7e-2]  All the models use "balanced" for the class_weight, "liblinear" for the solver, and (cid:96)1 for the penalty.  | RiskSLIM  RiskSLIM is challenging to train, because it uses the CPLEX optimization software, which can be difﬁcult to install and  requires a license. Moreover, since RiskSLIM solves a very difﬁcult mixed-integer nonlinear optimization problem, it  can be slow to prove optimality, which makes it difﬁcult to perform nested cross validation as nested cross validation  requires many solutions of the optimization problem. A previous study [99] also noted similar problems with algorithms  that use CPLEX (this study trained on SLIM [100], which is similar to the training process of RiskSLIM in that they both  require CPLEX). Here we provide details of how we trained RiskSLIM to help others use the algorithm more efﬁciently.  • We ran (cid:96)1-penalized logistic regression on the stumps training data with a relatively large regularization parameter to obtain a small subset of features (that is, we used (cid:96)1-penalized logistic regression for feature selection). Then we trained RiskSLIM using nested cross validation with this small subset of features. The maximum run-time, maximum  offset, and penalty value were set to 1,000 seconds, 100, and 1e-6 respectively. The coefﬁcient range was set to [-5,  5], which would give us small coefﬁcients that are easy to add/subtract.  •  If the model converged to optimality (optimality gap less than 5%) within 1,000 seconds, we then ran (cid:96)1-penalized logistic regression again with a smaller regularization parameter to obtain a slightly larger subset of features to work  with. We then trained RiskSLIM with nested cross validation again on this larger subset of features. If RiskSLIM  also generated an optimality gap less than 5% within 1,000 seconds and had better validation performance, we  • Once either RiskSLIM could not converge to a 5% optimality gap within 1,000 seconds, or the validation performance did not improve by adding more stumps, we stopped there, using the previously obtained RiskSLIM model as  repeated this procedure.  the ﬁnal model.  •  This procedure generally stopped with between 12 and 20 stumps from (cid:96)1-penalized logistic regression. Beyond this number of stumps, we did not observe improvements in performance in validation.   42  11.5 | Tables  WANG & HAN ET AL.  TA B L E 7 Broward baseline models. Results are the average value of test AUCs from ﬁve-fold nested cross validation, with standard deviation listed in parentheses.  Labels  Logistic ((cid:96)2)  Logistic((cid:96)1)  Linear SVM  RF  XGBoost  Performance Range  Baseline Models  Two Year  0.670 (0.021)  0.650 (0.021)  0.670 (0.020)  0.658 (0.027)  0.655 (0.022)  0.675 (0.037)  0.663 (0.039)  0.659 (0.032)  0.671 (0.036)  0.676 (0.048)  0.711 (0.048)  0.733 (0.035)  0.695 (0.037)  0.703 (0.040)  0.722 (0.039)  0.717 (0.052)  0.730 (0.057)  0.683 (0.048)  0.712 (0.027)  0.733 (0.034)  0.646 (0.041)  0.648 (0.050)  0.621 (0.036)  0.647 (0.046)  0.644 (0.037)  Misdemeanor  0.630 (0.019)  0.597 (0.013)  0.628 (0.018)  0.629 (0.027)  0.627 (0.024)  Six Month  0.625 (0.022)  0.608 (0.022)  0.618 (0.028)  0.615 (0.026)  0.623 (0.014)  0.685 (0.024)  0.651 (0.038)  0.619 (0.036)  0.668 (0.045)  0.685 (0.033)  0.673 (0.084)  0.696 (0.022)  0.640 (0.081)  0.675 (0.055)  0.698 (0.038)  0.727 (0.047)  0.725 (0.053)  0.659 (0.069)  0.687 (0.047)  0.725 (0.048)  0.611 (0.050)  0.613 (0.054)  0.580 (0.086)  0.591 (0.061)  0.585 (0.066)  Misdemeanor  0.612 (0.038)  0.586 (0.040)  0.586 (0.016)  0.593 (0.039)  0.608 (0.031)  TA B L E 8 Kentucky baseline models. Results are the average value of test AUCs from ﬁve-fold nested cross validation, with standard deviation listed in parentheses.  Labels  Logistic ((cid:96)2)  Logistic((cid:96)1)  Linear SVM  RF  XGBoost  Performance Range  Baseline Models  Two Year  0.745 (0.004)  0.745 (0.004)  0.746 (0.004)  0.753 (0.003)  0.759 (0.003)  0.768 (0.002)  0.769 (0.003)  0.769 (0.003)  0.777 (0.005)  0.784 (0.004)  0.730 (0.003)  0.730 (0.003)  0.733 (0.003)  0.743 (0.002)  0.749 (0.002)  0.785 (0.005)  0.785 (0.005)  0.787 (0.005)  0.801 (0.004)  0.806 (0.004)  0.765 (0.001)  0.765 (0.001)  0.768 (0.002)  0.779 (0.002)  0.784 (0.001)  Misdemeanor  0.729 (0.005)  0.729 (0.005)  0.730 (0.006)  0.738 (0.005)  0.744 (0.005)  Six Month  0.761 (0.004)  0.761 (0.004)  0.764 (0.005)  0.779 (0.003)  0.785 (0.004)  0.833 (0.007)  0.834 (0.006)  0.833 (0.007)  0.843 (0.006)  0.847 (0.005)  0.782 (0.003)  0.782 (0.003)  0.785 (0.003)  0.803 (0.003)  0.811 (0.002)  0.834 (0.012)  0.834 (0.013)  0.831 (0.014)  0.857 (0.011)  0.860 (0.011)  0.799 (0.002)  0.800 (0.002)  0.804 (0.003)  0.824 (0.003)  0.831 (0.002)  Misdemeanor  0.746 (0.007)  0.746 (0.007)  0.748 (0.007)  0.765 (0.006)  0.774 (0.006)  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  0.020  0.017  0.038  0.051  0.027  0.033  0.017  0.066  0.058  0.068  0.034  0.027  0.014  0.016  0.019  0.021  0.019  0.016  0.024  0.014  0.029  0.029  0.032  0.028   WANG & HAN ET AL.  43  TA B L E 9 AUCs of intepretable models on Broward data. For the violence problem, we use the Arnold New Violent Criminal Activity score. For the general problem, we use the Arnold New Criminal Activity score.  Labels  CART  EBM  Additive Stumps  RiskSLIM  Performance Range  Arnold PSA  COMPAS  Interpretable Models  Existing Risk Models  0.613 (0.025) 0.664 (0.027)  0.651 (0.020)  0.624 (0.022)  0.605 (0.022) 0.631 (0.019)  0.613 (0.045) 0.673 (0.045)  0.665 (0.034)  0.655 (0.055)  0.649 (0.028)  0.666 (0.026) 0.685 (0.043)  0.716 (0.037)  0.697 (0.027)  0.686 (0.059) 0.736 (0.034)  0.736 (0.033)  0.717 (0.020)  0.596 (0.033) 0.655 (0.050)  0.631 (0.028)  0.590 (0.036)  Misdemeanor 0.577 (0.036) 0.636 (0.029)  0.609 (0.020)  0.579 (0.015)  Two Year  Six Month  0.569 (0.074) 0.672 (0.043)  0.656 (0.068)  0.650 (0.068)  0.637 (0.052) 0.725 (0.031)  0.725 (0.036)  0.703 (0.023)  0.513 (0.014) 0.606 (0.049)  0.574 (0.036)  0.561 (0.045)  Misdemeanor 0.535 (0.021) 0.608 (0.042)  0.582 (0.036)  0.576 (0.024)  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  0.051  0.059  0.049  0.052  0.065  0.059  0.074  0.049  0.102  0.089  0.093  0.073                    0.549 (0.021) 0.622 (0.022)  0.620 (0.019)  0.585 (0.021)  0.577 (0.018) 0.609 (0.019)  0.631 (0.050) 0.680 (0.040)  0.676 (0.029)  0.671 (0.039)  0.675 (0.038)  TA B L E 1 0 AUCs of interpretable models on Kentucky data. For the violence problem, we use the Arnold New Violent Criminal Activity score. For the general problem, we use the Arnold New Criminal Activity score.  Labels  CART  EBM  Additive Stumps  RiskSLIM  Performance Range  Arnold PSA  Interpretable Models  Existing Risk Models  0.746 (0.003)  0.751 (0.004)  0.748 (0.004)  0.708 (0.003)  0.763 (0.007)  0.777 (0.004)  0.770 (0.005)  0.744 (0.008)  0.736 (0.002)  0.740 (0.001)  0.738 (0.002)  0.708 (0.005)  0.790 (0.003)  0.798 (0.006)  0.796 (0.005)  0.761 (0.003)  0.771 (0.002)  0.776 (0.001)  0.773 (0.002)  0.757 (0.007)  Misdemeanor  0.730 (0.005)  0.735 (0.005)  0.729 (0.006)  0.701 (0.002)  Two Year  Six Month  0.772 (0.005)  0.773 (0.004)  0.771 (0.004)  0.737 (0.002)  0.822 (0.011)  0.843 (0.006)  0.836 (0.004)  0.810 (0.009)  0.794 (0.003)  0.793 (0.004)  0.796 (0.004)  0.763 (0.004)  0.839 (0.014)  0.850 (0.012)  0.851 (0.010)  0.832 (0.010)  0.811 (0.003)  0.820 (0.003)  0.813 (0.003)  0.790 (0.006)  Misdemeanor  0.760 (0.006)  0.757 (0.006)  0.751 (0.006)  0.705 (0.005)  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  0.042  0.032  0.032  0.037  0.019  0.033  0.037  0.033  0.033  0.019  0.030  0.055  0.711 (0.004)  0.743 (0.003)  0.718 (0.004)  0.794 (0.011)           44  WANG & HAN ET AL.  TA B L E 1 1 Additive Stumps on two-year general recidivism. The model consists of twenty-eight stumps with an intercept. These binary features represent ﬁfteen original features; coefﬁcients were rounded for display purposes only.  1. age at current charge ≤ 20  2. age at current charge ≤ 21  3. age at current charge ≤ 24  4. age at current charge ≤ 27  5. age at current charge ≤ 35  6. age at current charge ≤ 39  7. age at current charge ≤ 43  8. age at current charge ≤ 47  9. prior arrest ≥ 2  10. prior arrest ≥ 3  11. prior arrest ≥ 4  12. prior arrest ≥ 5  13. prior charges ≥ 2  14. prior charges ≥ 2 3  15. prior violence ≥ 1  16. prior felony ≥ 1  17. prior misdemeanor ≥ 2  18. prior misdemeanor ≥ 3  19. prior misdemeanor ≥ 4  20. prior trafﬁc ≥ 1  21. ADE ≥ 1  22. prior fta two year ≥ 1  23. prior fta two year ≥ 2  24. prior pending charge ≥ 1  25. prior probation ≥ 1  26. prior incarceration ≥ 1  27. six month ≥ 1  28. three year ≥ 1  29. Intercept  0.0082  0.0053  0.0322  0.0270  0.0108  0.1223  0.0311  0.0686  0.6762  0.3489  0.2339  0.1226  0.0124  0.0065  0.0474  0.1721  0.0162  0.0764  0.0733  0.0394  0.1583  0.3398  0.0617  0.3874  0.2265  0.3577  0.0148  0.0005  -1.1500  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  -...  +...  +...  +...  +...  +...  -...  +...  +...  ADD POINTS FROM ROWS 1 TO 29  SCORE  = .....  Probability: Pr(Y = 1) = exp(score) / (1 + exp(score))   WANG & HAN ET AL.  45  TA B L E 1 2 Training baseline models and interpretable models on the Kentucky data set using ﬁve-fold nested cross validation and testing the best-performing model on the Broward data set.  Labels  Logistic ((cid:96)2)  Logistic ((cid:96)1)  Linear SVM Random Forest  XGBoost  CART  EBM  Additive Stumps  RiskSLIM  Baseline Models  Interpretable Models  0.615 (0.001) 0.614 (0.001) 0.610 (0.000) 0.619 (0.001) 0.617 (0.003) 0.595 (0.009)  0.612 (0.002)  0.608 (0.001)  0.568 (0.000)  0.655 (0.001) 0.653 (0.002) 0.630 (0.000) 0.652 (0.000) 0.652 (0.004) 0.622 (0.030) 0.640 (0.0100)  0.652 (0.002)  0.629 (0.018)  0.629 (0.001) 0.629 (0.001) 0.618 (0.000) 0.614 (0.002) 0.637 (0.002) 0.621 (0.010)  0.629 (0.003)  0.631 (0.001)  0.625 (0.000)  0.664 (0.001) 0.672 (0.001) 0.649 (0.000) 0.668 (0.002) 0.674 (0.008) 0.649 (0.017)  0.665 (0.011)  0.659 (0.001)  0.639 (0.021)  0.630 (0.001) 0.630 (0.001) 0.624 (0.000) 0.631 (0.001) 0.627 (0.005) 0.611 (0.003)  0.623 (0.005)  0.624 (0.000)  0.614 (0.000)  Misdemeanor 0.558 (0.000) 0.558 (0.000) 0.551 (0.000) 0.561 (0.001) 0.576 (0.002) 0.555 (0.004)  0.571 (0.003)  0.557 (0.000)  0.539 (0.002)  0.577 (0.002) 0.576 (0.001) 0.569 (0.000) 0.577 (0.001) 0.581 (0.002) 0.562 (0.007)  0.571 (0.004)  0.562 (0.001)  0.553 (0.000)  0.641 (0.002) 0.644 (0.001) 0.614 (0.000) 0.643 (0.001) 0.626 (0.004) 0.611 (0.013)  0.622 (0.009)  0.650 (0.001)  0.637 (0.002)  0.607 (0.004) 0.604 (0.003) 0.589 (0.000) 0.567 (0.005) 0.593 (0.007) 0.580 (0.018)  0.618 (0.006)  0.576 (0.001)  0.566 (0.020)  0.662 (0.001) 0.665 (0.002) 0.635 (0.000) 0.652 (0.002) 0.656 (0.013) 0.634 (0.016)  0.657 (0.008)  0.640 (0.004)  0.619 (0.000)  0.586 (0.001) 0.584 (0.002) 0.575 (0.000) 0.589 (0.002) 0.58 (0.002)  0.563 (0.003)  0.571 (0.005)  0.574 (0.001)  0.550 (0.001)  Misdemeanor 0.558 (0.002) 0.558 (0.000) 0.550 (0.000) 0.552 (0.002) 0.563 (0.004) 0.554 (0.012)  0.559 (0.002)  0.542 (0.001)  0.526 (0.003)  TA B L E 1 3 Training baseline models and interpretable models on the Broward County data set using ﬁve-fold nested cross validation and testing the resulting best-performing model on a held out portion of the Broward data set.  Labels  Logistic ((cid:96)2)  Logistic ((cid:96)1)  Linear SVM Random Forest  XGBoost  CART  EBM  Additive Stumps  RiskSLIM  Baseline Models  Interpretable Models  0.669 (0.020) 0.649 (0.021) 0.670 (0.020) 0.657 (0.034) 0.659 (0.019) 0.629 (0.028) 0.663 (0.031)  0.644 (0.027)  0.622 (0.021)  0.679 (0.038) 0.662 (0.035) 0.662 (0.034) 0.675 (0.037) 0.677 (0.05)  0.600 (0.037) 0.675 (0.049)  0.673 (0.035)  0.670 (0.032)  0.716 (0.047) 0.734 (0.034) 0.702 (0.043) 0.688 (0.044) 0.720 (0.034) 0.672 (0.041) 0.690 (0.054)  0.709 (0.044)  0.706 (0.027)  0.721 (0.057) 0.731 (0.057) 0.687 (0.052) 0.725 (0.039) 0.729 (0.04)  0.685 (0.058) 0.738 (0.031)  0.733 (0.039)  0.703 (0.036)  0.651 (0.040) 0.652 (0.053) 0.622 (0.036) 0.649 (0.045) 0.647 (0.039) 0.598 (0.034) 0.656 (0.050) 0.6400 (0.031) 0.603 (0.042)  Misdemeanor 0.634 (0.017) 0.602 (0.012) 0.632 (0.017) 0.629 (0.022) 0.624 (0.020) 0.585 (0.041) 0.633 (0.025)  0.603 (0.016)  0.558 (0.026)  0.624 (0.024) 0.607 (0.019) 0.619 (0.026) 0.620 (0.025) 0.621 (0.019) 0.553 (0.014) 0.620 (0.027)  0.617 (0.035)  0.600 (0.021)  0.680 (0.027) 0.650 (0.038) 0.614 (0.039) 0.670 (0.039) 0.689 (0.031) 0.623 (0.043) 0.683 (0.040)  0.683 (0.032)  0.691 (0.032)  0.672 (0.082) 0.696 (0.025) 0.649 (0.080) 0.687 (0.065) 0.686 (0.044) 0.569 (0.074) 0.655 (0.035)  0.704 (0.054)  0.719 (0.039)  0.726 (0.049) 0.725 (0.053) 0.648 (0.058) 0.698 (0.046) 0.720 (0.052) 0.637 (0.052) 0.723 (0.030)  0.699 (0.038)  0.663 (0.048)  0.620 (0.058) 0.613 (0.054) 0.587 (0.086) 0.611 (0.076) 0.601 (0.047) 0.524 (0.015) 0.605 (0.052)  0.584 (0.034)  0.557 (0.043)  Misdemeanor 0.616 (0.030) 0.583 (0.039) 0.590 (0.022) 0.601 (0.049) 0.620 (0.044) 0.543 (0.033) 0.612 (0.050)  0.576 (0.037)  0.556 (0.040)  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  Two Year  Six Month  Two Year  Six Month   46  WANG & HAN ET AL.  TA B L E 1 4 Training baseline and interpretable models on the Broward County data set using ﬁve-fold nested cross validation and testing the resulting best-performing model on the Kentucky data set.  Labels  Logistic ((cid:96)2)  Logistic ((cid:96)1)  Linear SVM Random Forest  XGBoost  CART  EBM  Additive Stumps  RiskSLIM  Baseline Models  Interpretable Models  0.664 (0.007) 0.653 (0.001) 0.658 (0.007) 0.701 (0.005) 0.689 (0.006) 0.626 (0.025) 0.704 (0.003)  0.653 (0.009)  0.649 (0.037)  0.674 (0.005) 0.650 (0.007) 0.611 (0.013) 0.729 (0.005) 0.724 (0.005) 0.589 (0.053) 0.720 (0.005)  0.657 (0.018)  0.663 (0.025)  0.649 (0.008) 0.632 (0.003) 0.554 (0.005) 0.655 (0.022) 0.650 (0.006) 0.613 (0.013) 0.656 (0.008)  0.626 (0.009)  0.634 (0.012)  0.628 (0.022) 0.663 (0.014) 0.556 (0.017) 0.695 (0.018) 0.669 (0.023) 0.548 (0.018) 0.687 (0.011)  0.590 (0.014)  0.593 (0.052)  0.671 (0.006) 0.661 (0.002) 0.592 (0.014) 0.724 (0.003) 0.706 (0.014) 0.592 (0.042) 0.725 (0.006)  0.676 (0.023)  0.631 (0.059)  Misdemeanor 0.638 (0.007) 0.619 (0.026) 0.579 (0.01)  0.665 (0.011) 0.645 (0.014) 0.574 (0.053) 0.669 (0.007)  0.621 (0.017)  0.631 (0.025)  0.676 (0.006) 0.665 (0.004) 0.601 (0.011) 0.698 (0.009) 0.685 (0.010) 0.613 (0.018) 0.709 (0.005)  0.663 (0.012)  0.602 (0.046)  0.653 (0.015) 0.662 (0.021) 0.533 (0.011) 0.762 (0.047) 0.773 (0.007) 0.625 (0.059) 0.757 (0.004)  0.728 (0.026)  0.723 (0.004)  0.663 (0.031) 0.678 (0.008) 0.521 (0.006) 0.682 (0.009) 0.658 (0.027) 0.600 (0.082) 0.609 (0.037)  0.619 (0.025)  0.635 (0.017)  0.681 (0.012) 0.708 (0.009) 0.529 (0.012) 0.719 (0.053) 0.718 (0.010) 0.555 (0.007) 0.715 (0.018)  0.643 (0.022)  0.696 (0.053)  0.685 (0.008) 0.679 (0.008) 0.556 (0.011) 0.719 (0.018) 0.683 (0.025) 0.552 (0.049) 0.724 (0.010)  0.652 (0.039)  0.621 (0.036)  Misdemeanor 0.664 (0.003) 0.658 (0.008) 0.558 (0.016) 0.670 (0.004) 0.662 (0.006) 0.604 (0.019) 0.676 (0.006)  0.615 (0.019)  0.583 (0.070)  TA B L E 1 5 Training baseline models and interpretable models on the Kentucky data set using ﬁve-fold nested cross validation and testing the resulting best-performing model on a held out portion of the Kentucky data set.  Labels  Logistic ((cid:96)2)  Logistic ((cid:96)1)  Linear SVM Random Forest  XGBoost  CART  EBM  Additive Stumps  RiskSLIM  Baseline Models  Interpretable Models  0.739 (0.003) 0.739 (0.003) 0.740 (0.004) 0.752 (0.004) 0.757 (0.003) 0.746 (0.003) 0.750 (0.004)  0.747 (0.004)  0.704 (0.004)  0.765 (0.001) 0.766 (0.002) 0.767 (0.002) 0.776 (0.004) 0.783 (0.004) 0.763 (0.007) 0.776 (0.004)  0.771 (0.005)  0.741 (0.010)  0.723 (0.002) 0.723 (0.002) 0.727 (0.002) 0.739 (0.002) 0.745 (0.002) 0.733 (0.002) 0.737 (0.002)  0.734 (0.003)  0.708 (0.002)  0.78 (0.004)  0.779 (0.004) 0.784 (0.004) 0.801 (0.004) 0.805 (0.004) 0.79 (0.004)  0.797 (0.005)  0.796 (0.005)  0.764 (0.009)  0.758 (0.002) 0.758 (0.002) 0.763 (0.002) 0.778 (0.002) 0.783 (0.001) 0.771 (0.002) 0.775 (0.001)  0.773 (0.001)  0.765 (0.001)  Misdemeanor 0.722 (0.005) 0.722 (0.005) 0.724 (0.006) 0.736 (0.006) 0.742 (0.005) 0.729 (0.005) 0.733 (0.006)  0.729 (0.006)  0.693 (0.010)  0.752 (0.004) 0.752 (0.004) 0.757 (0.004) 0.775 (0.003) 0.780 (0.003) 0.769 (0.005) 0.770 (0.004)  0.768 (0.004)  0.736 (0.004)  0.828 (0.006) 0.830 (0.005) 0.834 (0.005) 0.843 (0.005) 0.846 (0.005) 0.821 (0.011) 0.842 (0.005)  0.837 (0.004)  0.809 (0.005)  0.770 (0.003) 0.771 (0.003) 0.777 (0.004) 0.794 (0.004) 0.799 (0.002) 0.783 (0.005) 0.785 (0.004)  0.786 (0.004)  0.752 (0.006)  0.830 (0.010) 0.829 (0.011) 0.830 (0.013) 0.856 (0.009) 0.860 (0.011) 0.839 (0.014) 0.849 (0.011)  0.851 (0.010)  0.835 (0.009)  0.790 (0.002) 0.791 (0.002) 0.798 (0.003) 0.823 (0.003) 0.829 (0.003) 0.811 (0.005) 0.818 (0.004)  0.812 (0.004)  0.790 (0.005)  Misdemeanor 0.735 (0.006) 0.735 (0.006) 0.740 (0.007) 0.760 (0.005) 0.766 (0.005) 0.754 (0.005) 0.753 (0.006)  0.750 (0.006)  0.705 (0.005)  Two Year  Six Month  Two Year  Six Month  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony  General  Violent  Drug  Property  Felony   WANG & HAN ET AL.  47  TA B L E 1 6 Arnold Public Safety Assessment (PSA): New Criminal Activity (NCA)  New Criminal Activity (NCA)  Risk Factor  Value  Points  Age at Current Arrest  23 or older  Total NCA Points NCA Scaled Score  Point Scaling  Pending Charge at Time of Offense  22 or younger  0  2  0  3  0  1  0  1  0  1  1  2  0  1  2  0  2  No  Yes  No  Yes  No  Yes  0  1  2  0  1  No  Yes  3 or more  2 or more  Prior Misdemeanor Conviction  Prior Felony Conviction  Prior Violent Conviction  Prior FTA in Past 2 Years  Prior Sentence to Incarceration  0  1  2  3  4  5  6  7  8  9  10  11  12  13  1  2  2  3  3  4  4  5  5  6  6  6  6  6  TA B L E 1 7 Arnold Public Safety Assessment (PSA): New Violent Criminal Activity (NVCA)  New Violent Criminal Activity (NVCA)  Risk Factor  Value  Points  Current Violent Offense  Point Scaling  Total NVCA Points NVCA Scaled Score  Current Violent Offense and 20 Years or Younger  Pending Charge at Time of Offense  Prior Conviction (Misdemeanor or Felony)  Prior Violent Conviction  No  Yes  No  Yes  No  Yes  No  Yes  0  1  2  3 or more  0  2  0  1  0  1  0  1  0  1  1  2  0  1  2  3  4  5  6  7  No  No  No  No  Yes  Yes  Yes  Yes   48  WANG & HAN ET AL.  TA B L E 1 8 AUCs of the Arnold NVCA Raw, EBM and RiskSLIM on Kentucky for two-year violent recidivism, conditioned on sensitive attributes. AUC ranges are also given for each sensitive attribute class  Kentucky  Race  Sex  Model  Label  Afr-Am.  Cauc.  Other Race  race_range  Female  Male  sex_range  Arnold NVCA Raw  violent_two_year  0.728  0.740  0.767  0.039  0.728  0.734  0.006  EBM  violent_two_year  0.775  0.770  0.766  0.009  0.744  0.766  0.022  RiskSLIM  violent_two_year  0.744  0.736  0.680  0.063  0.706  0.730  0.024  TA B L E 1 9 Race and gender distributions for Kentucky. Due to the low percentage of the Asians and Indians in Kentucky, we included them in the "Other" category in the fairness analysis.  Kentucky  Attribute  Attribute Value  num_inds % total  African-American  42197  16.83  race  race  race  race  race  sex  sex  Asian  843  0.34  Caucasian  202341  80.69  Indian  Other  195  5202  0.08  2.07  female  79207  31.58  male  171571  68.42   WANG & HAN ET AL.  11.6 | Figures  49  F I G U R E 1 0 Base rates of all twelve types of recidivism on Kentucky data, conditioned (separately) on race and gender.  F I G U R E 1 1 Probabilities of two-year and six-month violent recidivism, given the age at current charge.  drug_six_monthdrug_two_yearfelony_six_monthfelony_two_yeargeneral_six_monthgeneral_two_yearmisdemeanor_six_monthmisdemeanor_two_yearproperty_six_monthproperty_two_yearviolent_six_monthviolent_two_yearPrediction Problem0.000.050.100.150.200.250.30P(Y = 1 | Attr = attr)Cond. prob. of recidivism for all prediction problems on KentuckyAfrican-AmericanCaucasianOtherfemalemale                      S U R E D E L O L W \ O R F D W L R Q     . < W Z R B \ H D U V L [ B P R Q W K                                                                                               D J H B D W B F X U U H Q W B F K D U J H                      S U R E D E L O L W \ O R F D W L R Q     ) / 9 L R O H Q W  5 H F L G L Y L V P 50  WANG & HAN ET AL.  F I G U R E 1 2 Calibration of the Arnold NVCA Raw, EBM and RiskSLIM for two-year violent recidivism on Kentucky.  (a) For the Arnold NVCA raw score, the curves satisfy mono tonic calibration until the score value of 7, where the prob abilities drop to 0. This may be because there are few  individuals with an Arnold NVCA raw score equal to 7 in  the data. The curves for African-Americans/Caucasians and  males/females are close enough to satisfy group calibration  (but we note that the African-American (respectively, male)  curve is consistently higher than the Caucasian (respectively,  female) curve), especially for larger raw NVCA scores.  (b) For EBM, the calibration curves for both gender and race  (c) For RiskSLIM, the curves are monotonically increasing and  groups are irregular, demonstrating that EBM satisﬁed nei roughly overlap with each other. The calibration curve for  ther group calibration nor monotonic calibration, on race and  African-Americans is slightly higher than for the Caucasian  gender groups.  and the “Other” race groups. For the two gender groups, the  curves are close to each other. We conclude that both race  and gender approximately satisfy group calibration.  0246Arnold NVCA Raw Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of Arnold NVCA Raw on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale0.0-0.10.1-0.20.2-0.30.3-0.40.4-0.50.5-0.60.6-0.70.7-0.80.8-0.90.9-1.0EBM Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of EBM on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale0.0-0.10.1-0.20.2-0.30.3-0.40.4-0.50.5-0.60.6-0.70.7-0.80.8-0.90.9-1.0RiskSLIM Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of RiskSLIM on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale WANG & HAN ET AL.  51  F I G U R E 1 3 Balance for Positive and Negative Class for the Arnold NVCA Raw, EBM and RiskSLIM on the two-year violent prediction problem in Kentucky. Red line indicates the maximum value output by models.  (a) Differences in expected scores for African-Americans  and Caucasians are greater than the threshold (0.2):  0.29 (race, negative class), 0.29 (race, positive class).  Differences in expected scores for gender are also  greater than the threshold: 0.38 (gender, negative  class) and 0.50 (gender, positive class).  (b) Differences in expected scores for African-Americans  (c) Differences in expected scores for African-Americans  and Caucasians are less than 0.03: 0.01 (race, negative  and Caucasians are less than 0.03: 0.01 (race, negative  class), 0.01 (race, positive class). Differences in expected  class), 0.02 (race, positive class). Differences in expected  scores for gender also satisfy the threshold: 0.00 (gender,  scores for gender satisfy the threshold for the negative  negative class) and 0.02 (gender, positive class).  class, but not for the positive class: 0.03 (gender, negative  class) and 0.06 (gender, positive class).  violent_bncviolent_bpc02468E(Arnold | Attr = attr, Y = i)1.863.131.572.841.152.551.352.491.732.99BPC/BNC for Arnold on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMaleviolent_bncviolent_bpc0.00.20.40.60.81.0E(EBM | Attr = attr, Y = i)0.010.030.00.020.00.010.00.010.00.03BPC/BNC for EBM on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMaleviolent_bncviolent_bpc0.00.20.40.60.81.0E(RiskSLIM | Attr = attr, Y = i)0.040.080.030.060.010.030.010.020.040.08BPC/BNC for RiskSLIM on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMale 52  WANG & HAN ET AL.  11.7 | Nested Cross Validation Procedure  We applied ﬁve-fold nested cross validation to tune parameters. We split the entire data set into ﬁve equally-sized folds  for the outer cross validation step. One fold was used as the holdout test set and the other four folds were used as the training set (call it “outer training set”). The inner loop deals only with the outer training set ( 45 ths of the data). On this outer training set, we conducted ﬁve-fold cross validation and grid-searched hyperparameter values. After this point,  each hyperparameter value had ﬁve validation results. We selected the parameter values with the highest average  validation results and then trained the model with this best set of parameters on the entire outer training set and tested  We repeated the process above until each one of the original ﬁve folds was used as the holdout test set. Ultimately,  we had ﬁve holdout test results, with which we were able to calculate the average and standard deviation of the  it on the holdout test set.  performance.  We applied a variant of the nested cross validation procedure described above to perform the analysis discussed  in Section 8—where we trained models on one region and tested on the other region. For instance, when we trained  models on Broward and tested them on Kentucky, the Kentucky data was treated as the holdout test set. We split  the Broward data into ﬁve folds and used four folds to do cross validation and constructed the ﬁnal model using the  best parameters. We then tested the ﬁnal model on the entire Kentucky data set, as well as the holdout test set from  Broward. We rotated the four folds and repeated the above process ﬁve times.   WANG & HAN ET AL.  11.8 | RiskSLIM Tables  53  TA B L E 2 0 Two Year Prediction Problems—Kentucky. Here, counts of prior arrests indicate the counts of arrests with at least one convicted charge. All charges mentioned are convicted charges. ADE indicates assignment to alcohol and drug education classes.  Two Year General Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-6 + score)))  Two Year Violent Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))  sex = Male  number of prior arrests≥2  number of prior arrests≥3  number of prior arrests≥5  1 points  1 points  1 points  +...  +...  +...  age at current charge ≤ 27  number of prior arrests≥2  number of prior violent charges≥1  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....  sentenced to incarceration before = Yes  1 points  1 points  1 points  1 points  1 points  +...  +...  +...  +...  +...  ADD POINTS FROM ROWS 1 TO 5  SCORE  = .....  Two Year Drug Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))  number of prior arrests≥2  number of prior drug related  charges≥1  1 points  1 points  +...  +...  charges≥1  number of times charged with  1 points  +...  a new offense when there is a pending case≥1  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....  Two Year Property Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))  number of prior property related  1 points  +...  number of prior arrests≥3  number of times charged with  1 points  1 points  +...  +...  a new offense when there is a pending case≥1  number of prior ADE ≥1  -1 points  +...  ADD POINTS FROM ROWS 1 TO 4  SCORE  = .....  Two Year Felony Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))  Two Year Misdemeanor Recidivism  age at current charge ≤ 43  number of prior arrests≥2  number of prior felony level charges≥1  number of times charged with  a new offense when there is a pending case≥1  1 points  1 points  1 points  1 points  +...  +...  +...  +...  Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))  number of prior arrests≥2  number of times charged with  a new offense when there is a pending case≥1  1 points  1 points  +...  +...  sentenced to incarceration before = Yes  1 points  +...  sentenced to incarceration before = Yes  1 points  +...  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....  ADD POINTS FROM ROWS 1 TO 5  SCORE  = .....   54  WANG & HAN ET AL.  TA B L E 2 1 Six Month Prediction Problems—Kentucky. Here, counts of prior arrests indicate the counts of arrests with at least one convicted charge. All charges mentioned are convicted charges. ADE means assignment to alcohol and drug education classes.  Six Month General Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-7 + score)))  Six Month Violent Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))  number of prior arrests≥2  number of prior arrests≥4  number of times charged with  a new offense when there is a pending case≥1  1 points  1 points  1 points  +...  +...  +...  number of prior violent charges≥1  number of prior arrests≥3  number of prior felony level charges≥1  current violent charge = Yes  number of times charged with  1 points  1 points  1 points  1 points  1 points  +...  +...  +...  +...  +...  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....  a new offense when there is a pending case≥1  ADD POINTS FROM ROWS 1 TO 5  SCORE  = .....  Six Month Drug Recidivism  Six Month Property Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))  Pr(Y = +1) = 1 / (1 + exp(-(-7 + score)))  number of prior drug related charges≥1  number of prior property related charges≥1  number of prior drug related charges≥3  number of prior felony level charges≥1  1 points  1 points  1 points  +...  +...  +...  number of times charged with  a new offense when there is a pending case≥1  number of prior FTA within last two years ≥1  1 points  number of times charged with  1 points  number of prior ADE≥1  -1 points  +...  a new offense when there is a pending case≥1  2 points  1 points  +...  +...  +...  +...  ADD POINTS FROM ROWS 1 TO 4  SCORE  = .....  ADD POINTS FROM ROWS 1 TO 4  SCORE  = .....  Six Month Felony Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))  number of prior arrests≥3  number of prior felony level charges≥1  number of times charged with  a new offense when there is a pending case≥1  Six Month Misdemeanor Recidivism  1 points  1 points  1 points  +...  +...  +...  Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))  number of prior arrests≥2  number of prior arrests≥4  1 points  1 points  +...  +...  ADD POINTS FROM ROWS 1 TO 2  SCORE  = .....  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....   WANG & HAN ET AL.  55  TA B L E 2 2 Two Year Prediction Problems—Broward. Here, counts of prior arrests indicate the counts of arrests with at least one non-convicted or convicted charge. All charges mentioned are non-convicted charges.  Two Year Violent Recidivism  Two Year General Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))  Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))  age at current charge≤30  age at current charge ≤31  1 points  number of prior violent charges≥4  number of prior misdemeanor level charges ≥4  1 points  number of prior arrests≥7  had charge(s) within last three years = Yes  1 points  current violent charge=Yes  +...  +...  +...  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....  had charge(s) within last three year = Yes  ADD POINTS FROM ROWS 1 TO 5  SCORE  = .....  1 points  1 points  1 points  1 points  1 points  1 points  1 points  1 points  1 points  1 points  +...  +...  +...  +...  +...  +...  +...  +...  +...  +...  Two Year Property Recidivism  Two Year Drug Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))  Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))  age at current charge≤33  age at current charge ≤18  age at current charge ≤23  number of prior drug related charges≥1  number of prior property related charges≥1  number of prior drug related charges≥4  number of prior property related charges≥5  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....  number of prior violent charges≥4  1 points  1 points  1 points  +...  +...  +...  ADD POINTS FROM ROWS 1 TO 5  SCORE  = .....  Two Year Felony Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))  age at current charge ≤33  number of prior misdemeanor  level charges≥4  1 points  1 points  +...  +...  Two Year Misdemeanor Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))  age at ﬁrst charge≤30  number of FTA within last two years≥1  1 points  1 points  +...  +...  number of prior property related charges≥4  1 points  +...  ADD POINTS FROM ROWS 1 TO 2  SCORE  = .....  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....   56  WANG & HAN ET AL.  TA B L E 2 3 Six Month Prediction Problems—Broward. Here, counts of prior arrests indicate the counts of arrests with at least one non-convicted or convicted charge. All charges mentioned are non-convicted charges.  Six Month General Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))  age at ﬁrst charge≤28  had charge(s) within last three years = Yes  1 points  1 points  +...  +...  ADD POINTS FROM ROWS 1 TO 2  SCORE  = .....  Six Month Violent Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))  current violent charge = Yes  number of prior violent charges ≥4  had charge(s) within last three years = Yes  1 points  1 points  1 points  +...  +...  +...  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....  Six Month Drug Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))  age at ﬁrst charge≤21  number of prior drug charges≥2  had charge(s) within last year = Yes  1 points  1 points  1 points  +...  +...  +...  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....  Six Month Property Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))  age at current charge≤29  1 points  + ...  number of prior misdemeanor level charges≥5  1 points  number of prior property related charges≥1  number of prior property related charges≥4  +...  +...  +...  1 points  1 points  ADD POINTS FROM ROWS 1 TO 4  SCORE  = .....  Six Month Felony Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))  age at current charge≤29  number of prior property related charges≥4  1 points  1 points  +...  +...  ADD POINTS FROM ROWS 1 TO 2  SCORE  = .....  Six Month Misdemeanor Recidivism  Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))  age at current charge≤19  number of prior weapon related charges≥1  had charge(s) within last three years = Yes  1 points  1 points  1 points  +...  +...  +...  ADD POINTS FROM ROWS 1 TO 3  SCORE  = .....   WANG & HAN ET AL.  11.9 | Features  57  TA B L E 2 4 Features from Broward data set. Recall that charges can be convicted or non-convicted.  person_id  unique personal identiﬁer  sex  race  biological sex of the person  race of the person  screening_date  date that triggered the COMPAS screening  age_at_current_charge age at the person’s current charge  age_at_ﬁrst_charge  age at the person’s ﬁrst charge  p_arrest  count of prior arrests  p_charges  count of prior charges  p_violence  count of prior violent charges  p_felony  count of prior felony-level charges  p_misdemeanor  count of prior misdemeanor-level charges  p_juv_fel_count  count of prior felony-level and juvenile charges  p_property  count of prior property-related charges  p_murder  count of prior murder charges  p_famviol  count of prior family violence charges  p_sex_offenses  count of prior sex offense charges  p_weapon  count of prior weapon-related charges  p_felprop_viol  count of prior felony-level, property-related, and violent charges  p_felassault  count of prior felony-level assault charges  p_misdeassault  count of prior misdemeanor-level assault charges  p_trafﬁc  count of prior trafﬁc-related charges  p_drug  p_dui  count of prior drug-related charges  count of prior DUI charges  p_stalking  count of prior stalking charges  p_voyeurism  count of prior voyeurism charges  p_fraud  count of prior fraud charges  p_stealing  count of prior stealing/theft charges  p_domestic  count of prior domestic violence charges  p_trespass  count of prior trespass charges  p_fta_two_year  count of prior failures to appear in court within last two years (≤ 2 years)  p_fta_two_year_plus  count of prior failures to appear in court beyond last two years (> 2 years)  p_pending_charge  count of times charged with a new offense when there was a pending case  p_probation  count of times charged with a new offense when the person was on probation  p_incarceration  whether or not the person was formerly sentenced to incarceration  six_month  whether or not the person had charges within last six months (≤ 6 months)  one_year  whether or not the person had charges within last year (≤ 1 year)  three_year  whether or not the person had charges within last three years (≤ 3 years)  ﬁve_year  whether or not the person had charges within last ﬁve years (≤ 5 years)  current_violence  whether or not the current charge is violent  current_violence20 whether or not the current charge is violent and the person is ≤ 20 years old  total_convictions  total count of convictions   58  WANG & HAN ET AL.  TA B L E 2 5 Features from Kentucky data set. The charges are convicted. ADE means assignment to alcohol and drug education classes.  current_date  current charge date or the release date if there was a sentence on the current charge.  age_at_current_charge  age at the person’s current charge, or the age at current charge plus the sentence time if there was  person_id  unique personal identiﬁer  sex  race  biological sex of the person  race of the person  a sentence on the current charge  p_arrest  count of prior arrests with convicted charges  p_charges  count of prior convicted charges  p_violence  count of prior violent charges  p_felony  count of prior felony-level charges  p_misdemeanor  count of prior misdemeanor-level charges  p_property  count of prior property-related charges  p_murder  count of prior murder charges  p_assault  count of prior assault charges  p_sex_offenses  count of prior sex offense charges  p_weapon  count of prior weapon-related charges  p_felprop_viol  count of prior felony-level, property-related, and violent charges  p_felassault  count of prior felony-level assault charges  p_misdeassault  count of prior misdemeanor-level assault charges  p_trafﬁc  count of prior trafﬁc-related charges  p_drug  p_dui  count of prior drug-related charges  count of prior DUI charges  p_stalking  count of prior stalking charges  p_voyeurism  count of prior voyeurism charges  p_fraud  count of prior fraud charges  p_stealing  count of prior stealing/theft charges  p_trespass  count of prior trespass charges  ADE  count of times the person was assigned to alcohol/drug education classes  treatment  count of times the person received treatment along with the sentence  p_fta_two_year  count of prior failures to appear in court within last two years (≤ 2 years)  p_fta_two_year_plus  count of prior failures to appear in court beyond last two years (> 2 years)  p_pending_charge  count of times charged with a new offense when there was a pending case  p_probation  count of times charged with a new offense when the person was on probation  p_incarceration  whether or not the person was formerly sentenced to incarceration  six_month  whether or not the person had charges within last six months (≤ 6 months)  one_year  whether or not the person had charges within last year (≤ 1 year)  three_year  whether or not the person had charges within last three years (≤ 3 years)  ﬁve_year  whether or not the person had charges within last ﬁve years (≤ 5 years)  current_violence  whether or not the current charge was violent  current_violence20  whether or not the current charge was violent and the person was ≤ 20 years old  current_pending_charge whether or not the person had a pending case during the current charge   
4 Conclusion  We presented a framework to derive Rademacher bounds for a wide class of vector-valued functions combined with Lipschitz losses. We studied in parallel the case of multi-task and multi-category learning. To our knowledge our framework allows to derive bounds for more general classes of vector-valued function and loss functions than currently possible, while still improving over existing bounds [15, 17] in special cases. In particular, we illustrate how bounds can be derived for neural networks with one hidden layer and rather general nonlinear activation functions.  In the future, it would be valuable to study more examples of the loss functions included in the setting. In addition to one-vs-one classiﬁcation, which we brieﬂy mentioned in the paper, these could include multi-label classiﬁcation or hybrid multi-task learning, in which each task is itself a multi-category or multi-label problem. Another interesting direction of research is to extend our analysis to neural networks with more than one hidden layer. Although the proof technique presented in Section 3.3 could naturally be extended to derive such bounds, it seems important to study improvement in the large constants appearing in Theorem 3.4 (see [18]) in order to avoid explosion of the constants in bounds for deep networks.  11   A Appendix  A.1 Mixed Norms  Theorem A.1 We have that:  (i) For p ∈ [2, ∞]  T  B √2N  For the convenience of the reader we restate in greater generality the results contained in the main body of the paper. The ǫi or ǫti are throughout independent Rademacher variables.  In this section we prove a more general result implying Theorem 3.1.  Xt=1 q|It| tr( ˆCt) ≤ RI (W2,∞, x) ≤ RI (W2,p, x) ≤  B√T  T  N vuut  Xt=1 |It| tr( ˆCt).  (ii) For p ∈ [1, 2] and 1/p + 1/q = 1 if  P RI (W2,2, x) ≤ RI (W2,p, x) ≤  2  i∈It kxik T 1/pB√q N  ≥ q−1 then Xt q|It|tr( ˆCt)   2  1/q  q  ,  !  where 1/p + 1/q = 1.  (iii) For 1-vs-all multi-category learning the condition  bound in (ii) can be simpliﬁed to  2  i∈It kxik  ≥ q−1 can be omitted and the  P  RI mc (W2,p, x) ≤ Bs  qT tr( ˆC) n  .  Proof. (i) We have  B  √2 Xt q|It| tr( ˆCt) = B  2 = B  E  √2 Xt vuut  (cid:13)(cid:13)(cid:13)(cid:13)(cid:13) Xi∈It E sup w,kwk≤B *w,  2  ǫixi(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  √2 Xt sXi∈It kxik ǫixi(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  Xt  Xi∈It  (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  E  ≤ B Xi∈It = N RI (W2,∞) ≤ N RI (W2,p) ≤ N RI (W2,2)  Xt  =  ǫixi+  = E sup  W ∈W2,2  ≤ B√T  wt,  Xt * sXt Xi∈It kxik  ǫixi+  Xi∈It 2 = B√T  = B√T EvuutXt (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  |It| tr( ˆCt)  Xi∈It  sXt  2  ǫixi(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  12   where we used Szarek’s inequality (Theorem 5.20 [6]) in the ﬁrst inequality. The next inequalities follow from W2,∞ ⊆ W2,p ⊆ W2,2. For the last inequality we use Jensen’s. (ii) The ﬁrst inequality is W2,2 ⊆ W2,p. Then let Xt = i∈It kxik  , so that EXt ≤ (cid:13)(cid:13)  i∈It ǫixi  2. By the bounded difference inequality (see [6]) for s ≥ 0 (cid:13)(cid:13)P −s2 i∈It kxik  Pr {Xt > EXt + s} ≤ exp    2 ! ,  2  qP  so with integration by parts  P  ∞  0  Z  ∞  0  Z  E [X q  t ] ≤ EXt + q  sq−1 Pr {X > EX + s} dsq  ≤ EXt + q  sq−1 exp  = EXt +  Xi∈It kxik ≤  Xi∈It kxik  1/2  !  2  2     q/2  2  !  ∞  P q  (cid:18)  0  Z  −s2 i∈It kxik  ds  2 !  −s2 2 (cid:19)  (cid:18)  ds  (cid:19)  sq−1 exp  q/2  +  q  Xi∈It kxik  2  !  ≤ 2  q  Xi∈It kxik  2  !  q/2  ,  where the third inequality follows from a comparison of the integral with the moments of the standard normal distribution, and the last follows from  2  RI (W2,p) = 1 N E  sup  kW k2,p≤T 1/pB Xt Xi∈It hwt, xii = T 1/pB N E  ≤  T 1/pB N  Xt = 21/qT 1/pB√q N  1/q  T 1/pB√q N  ≤  EX q  t !   Xt (cid:16)|It| tr( ˆCt)  (cid:17)  q/2  !  .  i∈It kxik  ≥ q−1. Thus  P  2      1/q  1/q  X q  t !   Xt Xt  Xi∈It kxik  2  !  q/2  1/q      (iii) The case of 1-vs-all multi-category learning is simpler because It = {1, . . . , N } and we can interchange summation over t and i. Then we can essentially proceed as in[15] and use the 1/q-strong convexity of 1 2,p w.r.t. kW k2,p. In Corollary 4 of [11] let λ > 0 and u = W and 2 = fmax (u) to obtain vi = λ (ǫ1ixi, . . . , ǫT ixi) and use 1 2 kW k  2 kW k  2 2,p ≤  T 1/pB  1 2  2  N  Xi=1 hW, λ (ǫ1ixi, ..., ǫT ixi)i2 ≤  N  (cid:0)  (cid:1)  Xi=1 h∇f (v1:i−1) , vii + 1 2 (cid:16)  T 1/pB  N  2 + qλ2 2 (cid:17)  Xi=1 k(ǫ1ixi, ..., ǫT ixi)k  2 2q ,  13   where h·, ·i2 is the Hilbert-Schmidt inner product. Take the supremum in W and then the expectation. The ﬁrst term on the r.h.s. above vanishes. Dividing by λ and optimizing in λ gives  n  E sup W  Xi=1 hW, ǫ1ixi, . . . , ǫT ixii ≤ (cid:16)  T 1/pB  E k(ǫ1ixi, . . . , ǫT ixi)k  2 2q.  n  Xi=1  q  (cid:17) vuut  2/q  E k(ǫ1ixi, . . . , ǫT ixi)k  2 2q = E   Xt kǫtixik  q  !  ≤ T 2/q  kxik  2  Now  so  RI mc (W2,p) = 1 N E  N  Xi=1 hW, ǫ1ixi, . . . , ǫT ixii ≤  N  q  Xi=1 kxik  T B  N vuut  2 = Bs  qT tr( ˆC) n  .  Note that the (very harmless) condition  2  i∈It kxik  ≥ q−1 in part (iii) is automatically satisﬁed  if kxik = 1.  P  A.2 Trace Norm Constraints  Theorem A.2  In this section we prove the following result, which contains Theorem 3.2 as as special case and improves over [17] which only applies to the multi-task learning setting.  RI (Wtr, x) ≤  B N r  2T maxt  |It| tr( ˆCt) (ln N + 1) + B N vuut  T λmax  Xt  |It| ˆCt!  .  For the proof we use k.k∞ to denote the operator norm on H and (cid:23) and (cid:22) to refer to the ordering induced by the cone of positive operators. For x ∈ H we deﬁne the rank-1 operator Qx on H by Qxv = hv, xi x. We use the following result, the proof of which can be found in [17]. Theorem A.3 Let M ⊆ H be a subspace of dimension d and suppose that A1, . . . , AN are independent random operators satisfying Ak (cid:23) 0, Ran (Ak) ⊆ M a.s. and  EAmk (cid:22) m!Rm−1EAk  for some R ≥ 0, all m ∈ N and all k ∈ {1, . . . , N }. Then  E  E  vuut  Ak(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) ∞ ≤ vuut  (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  Xk  (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  Ak(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  Xk  ∞  p  +  R (ln dim (M ) + 1).  14   Lemma A.4 Let x1, . . . , xn be in Rd and denote  α =  n  2 .  Xi=1 kxik  Deﬁne a random vector by V =  i ǫixi. Then for p ≥ 1  E  Qp V  (cid:22) (2p − 1)!!αp−1E [QV ] ,  P  p  (cid:3)  (cid:2) where (2p − 1)!! = Proof. Let v ∈ Rd be arbitrary. By the deﬁnition of V and QV we have for any v ∈ Rd that  i=1 (2i − 1) = (2p − 1) (2 (p − 1) − 1) × · · · × 5 × 3 × 1.  Q  E  Qp V  v, v  =  n  E  Xj1,...,j2p=1  ǫj1ǫj2 · · · ǫj2p  hv, xj1i hxj1, xj2i · · ·  xj2p, v  .  (cid:3)  (cid:2)  (cid:11)  (cid:10)  (cid:2) (cid:10) The properties of independent Rademacher variables imply that E = 0 unless the sequence i = (i1, . . . , i2p) has the property that each index ik occurs in it an even number of times, in which case E  = 1. Let us call sequences with this property admissible. Thus  (cid:11) ǫi1ǫi2 · · · ǫi2p  (cid:3)  (cid:3)  (cid:2)  ǫi1ǫi2 · · · ǫi2p  (cid:2)  (cid:3)  hE [Qpw] v, vi =  Xi admissible hv, xi1i hxi2, xi3i · · · Xi admissible |hv, xi1i| Yk=2 kxik k  2p−1  (cid:10)  (cid:12)(cid:12)(cid:10)  xi2p, v  xi2p, v  ,  (cid:11)  (cid:11)(cid:12)(cid:12)  ≤  using Cauchy-Schwarz. For every admissible sequence i there exists at least one partition π of {1, .., 2p} into p pairs (l, r) with l < r, such that the indices ik1 and ik2 are equal, whenever k1 and k2 belong to the same pair. Let us denote the latter condition by i ∼ π. It is easy to show by induction that there are (2p − 1)!! such partitions into pairs. Given π we can write {1, . . . , 2p} = Lπ ∪ Rπ, where Lπ = {l : ∃ (l, r) ∈ π} and Rπ = {r : ∃ (l, r) ∈ π}. We always have 1 ∈ Lπ and 2p ∈ Rπ and |Lπ| = |Rπ| = p. Thus  hE [Qpw] v, vi ≤  2p−1  Xπ Xi∼π |hv, xi1i| |hv, xi1 i|    Xπ Xi∼π  Xπ Xi∼π hv, xi1i  2p−1  xi2p, v  Yk=2 kxik k (cid:12)(cid:12)(cid:10) (cid:11)(cid:12)(cid:12) Yk=2,ik∈Lπ kxik k Yk=2,ik∈Lπ kxik k  2p−1  2 .    2  =  ≤  2p−1  xi2p, v  Yk=2,ik∈Rπ kxik k    (cid:11)(cid:12)(cid:12)   (cid:12)(cid:12)(cid:10)  The last step follows from the Cauchy-Schwarz inequality and realizing that the two resulting factors are equal by symmetry. But for i ∼ π we just need to sum over the indices in Lπ, the others  15   being constrained to be equal. Thus, writing Lπ = {l1, . . . , lp} such that l1 = 1 the last expression above is just  p  2  2  Yk=2 kxik k  p−1  n  = (2p − 1)!!    n  Xπ Xi1,...,ip hv, xi1i Xi=1 kxik Xi=1 kxik     n  = (2p − 1)!!  2  2  !  !  p−1  Qxiv, v+  *  Xi=1 hE [QV ] v, vi .  The conclusion follows since for symmetric matrices (∀v, hAv, vi ≤ hB, v, vi) =⇒ A (cid:22) B. Proof of Theorem A.2. We have  RI (Wtr, x) = 1  N E sup  W ∈Wtr  ǫti hwt, xii = 1  N E sup  W ∈Wtr  tr(W ∗D),  Xt Xi∈It where the random operator D : H → RT is deﬁned for v ∈ H by (Dv)t = inequality gives  v,  i∈It ǫtixi  . H¨older’s  (cid:10)  P  (cid:11)  We proceed to bound E kDk∞. Let Vt be the random vector Vt = corresponding rank-one operator QVt is deﬁned by QVtv = hv, Vti Vt = P T Then D∗D = t=1 QVt, so by Jensen’s inequality  nti∈It ǫtixi and recall that the nti∈It ǫtixi.  nti∈It ǫtixi  v,  (cid:10)  P  (cid:11) P  RI (Wtr, x) ≤  B√T N E kDk∞ .  P  E  E kDk∞ ≤ vuut  .  ∞  QVt(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  Xt  (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  The range of any of the realizations of QVt lies in the span of the xi which has less than N . By Lemma A.4 we have with αt =  2  P E [(QV t)m] (cid:22) (2p − 1)!!αm−1  t  2 maxt αt  m−1 E [QVt] ,  (cid:17) so Theorem A.3 with R = 2 maxt αt and d = N now gives  (cid:16)  i∈It kxik E [QVt] (cid:22) m!  E  vuut  QVt(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  Xt  (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  ∞ ≤  2 maxt αt (ln N + 1) + vuut  q  E  (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  Xt  .  ∞  QVt(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  16   But E [QVt] =  i∈It Qxi = |It| ˆCt, so  P  RI (Wtr, x) ≤  B√T N E kDk∞ ≤  B√T  E  Xt  QVt(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) N vuut (cid:13)(cid:13)(cid:13)(cid:13)(cid:13) |It| tr( ˆCt) (ln N + 1) + vuut  ∞  B N r  ≤  2T maxt  T (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  Xt  .  ∞  |It| ˆCt(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  A.3 Nonlinear Compositions  For the statement of a general version of Theorem 3.3 we extend the deﬁnition of θmc and θmt by setting for any map I : {1, . . . , T } → 2{1,...,N }  θI = inf  θ : ∀ (a1, . . . , aN ) , ai ≥ 0, (  T  Xt=1 Xi∈It  ai ≤ θ2  N  Xi=1  .  ai)  This deﬁnition coincides with the previous one in the case of multi-task and 1-vs-all multi-category learning.  Theorem A.5 There are universal constants c1 and c2 such that under the above conditions  RI (Vφ (W2,∞) , x) ≤ Lφab∞θI    RI (Vφ (W2,2) , x) ≤ Lφab2θI   RI (Vφ (W2,1) , x) ≤ Lφab1θI    c1Ks  tr( ˆC) nT + c2s  Kλmax( ˆC) n  K tr( ˆC) nT  c1s  λmax  ˆC (cid:16) n    (cid:17)  + c2vuut  2tr( ˆC) + 8λmax( ˆC) ln K nT  c1s       + c2s  λmax( ˆC)  .  n     The proof uses the following recent result on the expected suprema of Gaussian processes [18].  For a set Y ⊆ Rm the Gaussian width G (Y ) is deﬁned as  G (Y ) = E sup  y∈Y hγ, yi = E sup  y∈Y  γiyi,  m  Xi=1  where γ = (γ1, . . . , γm) is a vector of independent standard normal variables.  17   Theorem A.6 Let Y ⊆ Rn have (Euclidean) diameter D (Y ) and let F be a class of functions f : Y → Rm, all of which have Lipschitz constant at most L (F). Let F (Y ) = {f (y) : f ∈ F, y ∈ Y }. Then for any y0 ∈ Y  G (F (Y )) ≤ c1L (F) G (Y ) + c2W (Y ) Q (F) + G (F (y0)) ,  (7)  where c1 and c2 are universal constants and  Q (F) =  sup y,y′∈Y, y6=y′  E sup f ∈F  hγ, f (y) − f (y′)i ky − y′  k  .  Proof of Theorem 3.3. We will use Theorem A.6 by setting  Y =  W x = (hwk, xii)k≤K, i≤N : W ∈ Wo ⊆ RKN  n  where W will be either W2,∞, W 2,2 or W2,1. For F we take the set of functions  (yki) ∈ RKN  (  7→ (hvt, φ (yi)i)t≤T,i∈It ∈  R|It| : v ∈ V)  T  Yt=1  restricted to Y . By a well known bound on Rademacher averages in terms of Gaussian averages [14]  E  sup  W ∈V,W ∈W Xt Xi∈It  ǫtiV φ (W xi) ≤ r  π 2 E  sup  γtiV φ (W xi)  W ∈V,W ∈W Xt Xi∈It  π 2 G (F (Y )) .  =  r  (8)  To bound G (F (Y )) we then just need to bound the terms in the right hand side of equation (7) Since φ (0) = 0, we can at once set G (F (y0)) = 0, by setting 0 = y0, so f (0) = 0 for all f ∈ F.  Bounding the Lipschitz constant. For any v ∈ V and y, y′  ∈ Y ⊆ RKN ,  hvt, φ (yi)i −  vt, φ  y′i  2  (cid:10)  (cid:0)  (cid:1)(cid:11)(cid:1)  Xt,i∈It (cid:0)  2  Xt kvtk ≤ ≤ a2L2φ  Xi∈It (cid:13)(cid:13) Xt Xi∈It (cid:13)(cid:13)  φ (yi) − φ yi − y′i  2  2  y′i  (cid:1)(cid:13)(cid:13) (cid:0) ≤ a2L2φθ2I  (cid:13)(cid:13)  2 ,  y − y′ (cid:13)(cid:13)  (cid:13)(cid:13)  so L (F) ≤ aLφθI .  18   Bounding Q (F). Again with y, y′ γ, f (y) − f  E sup f ∈F  y′  ∈ Y  (cid:10) = E sup  v∈V Xti  γti  (cid:0)  (cid:1)(cid:11) hvt, φ (yi)i − (cid:0)  vt, φ  y′i  = E sup  vt,  γti  φ (yi) − φ  v∈V Xt *  Xi∈It  (cid:0)  (cid:0)  (cid:1)(cid:11)(cid:1)  y′i  (cid:0) 2  (cid:1)(cid:1)+  1/2  (cid:10)  y′i  (cid:1)(cid:1)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  1/2  (cid:0)  2  ≤ aE  Xt (cid:13)(cid:13)(cid:13)(cid:13)(cid:13) ≤ aLφ√T  γti  φ (yi) − φ (cid:0)  Xi∈It  yi − y′i   Xt Xi∈It (cid:13)(cid:13)  !  (cid:13)(cid:13)  ≤ √T a   Xt ≤ aLφθI √T  E (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  ,  y − y′ (cid:13)(cid:13)  (cid:13)(cid:13)  γti  φ (yi) − φ  Xi∈It  (cid:0)  y′i  (cid:0)      (cid:1)(cid:1)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  so Q (F) ≤ aLφθI √T . Bounding the diameters. We have  2  s  sup  sup  D (Wx) ≤ 2  W Xki hwk, xii W Xk kwkk From kW k2,2 ≤ kW k2,1 and kW k2,2 ≤ √K kW k2,∞ we obtain  2 = vuut W Xk kwkk 2 N λmax( ˆC) = kW k2,2  ≤ s  sup  q  2  , xi  (cid:29)  wk kwkk Xi (cid:28) N λmax( ˆC).  D (W2,∞) ≤ b∞  KN λmax( ˆC), and both D (W2,2) , D (W2,1) ≤ b2  N λmax( ˆC).  q  Bounding the Gaussian width.  G (W2,∞x) = E sup  W ∈W∞  wk,  Xk *  Xi≤N  γkixi+  = b∞  Xk  Xi≤N  N tr( ˆC).  ≤ b∞K  q  similarly  q  γkixi(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  2  E (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) E (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  W ∈W2  G (W2,2x) = E sup  Xk *wk, The Gaussian width of W1x is a little more complicated. Let W mations W  γkixi+ = b2vuuutXk  be the class of linear transfor1 = {x 7→ (0, . . . , hw, xi , . . . , 0) : kwk ≤ b1}, where only the k-th coordinate is different  γkixi(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)  KN tr( ˆC).  ≤ b∞  Xi≤N  Xi≤N  (k) 1  q  (k)  19   from zero. Then W1x is the convex hull of W that  (1)  1 x ∪ · · · ∪ W  (K) 1 x. It follows from Lemma 2 in [19]  G (W2,1x) ≤ maxk G  2 ln K  (k) 1 x (cid:17)  + 2  sXk,i hwk, xii  (cid:16)W N tr( ˆC) + 2vuutXk kwkk  N tr( ˆC) + 2b1  2  Xi (cid:28) N λmax( ˆC) ln K  q  2N  tr( ˆC) + 8λmax (cid:16)  ˆC (cid:16)  (cid:17)  ln K  .  (cid:17)  ≤ b1  ≤ b1 ≤ b1  q  q  r  wk kwkk  2  (cid:29)  , xi  ln K  Collecting these bounds in Theorem A.6 and using (8) gives the three inequalities of Theorem 3.3.  References  [1] Y. Amit, M. Fink, N. Srebro, and S. Ullman. Uncovering shared structures in multiclass classiﬁcation. In Proceedings of the 24th international conference on Machine learning, pages 17–24, 2007.  [2] R. K. Ando and T. Zhang. A framework for learning predictive structures from multiple tasks  and unlabeled data. Journal of Machine Learning Research, 6, 1817–1853, 2005.  [3] M. Anthony and P. L. Bartlett. Neural network learning: Theoretical foundations. Cambridge  University Press, 1999.  [4] P. L. Bartlett and S. Mendelson. Rademacher and Gaussian Complexities: Risk bounds and  structural results. Journal of Machine Learning Research, 3:463–482, 2002.  [5] J. Baxter. A model of inductive bias learning. Journal of Artiﬁcial Intelligence Research, 12:149–  [6] S. Boucheron, G. Lugosi, and P. Massart. Concentration Inequalities, Oxford University Press,  198, 2000.  2013  [7] G. Cavallanti, N. Cesa-Bianchi, and C. Gentile. Linear algorithms for online multitask classiﬁ cation. Journal of Machine Learning Research, 11:2597–2630, 2010.  [8] K. Crammer and Y. Singer. On the algorithmic implementation of multiclass kernel-based  vector machines. Journal of Machine Learning Research, 2, 265–292, 2002  20   [9] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proceedings of the 2014 Conference on Computer Vision and Pattern Recognition, pages 580–587, 2014.  [10] S. Haykin. Neural Networks: A Comprehensive Foundation. Prentice-Hall, 1999.  [11] S. M. Kakade, S. Shalev-Shwartz, A. Tewari. Regularization techniques for learning with ma trices. Journal of Machine Learning Research 13:1865–1890, 2012.  [12] V. Koltchinskii and D. Panchenko. Empirical margin distributions and bounding the general ization error of combined classiﬁers. Annals of Statistics, 30(1):1–50, 2002.  [13] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document  recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998  [14] M. Ledoux, M. Talagrand. Probability in Banach Spaces: Isoperimetry and Processes. Springer,  Berlin, 1991.  [15] Y. Lei, U., Dogan, A. Binder, and M. Kloft. Multi-class SVMs: From tighter data-dependent generalization bounds to novel algorithms. In Advances in Neural Information Processing Systems, pages 2026–2034, 2015.  [16] A. Maurer. Bounds for linear multi-task learning. Journal of Machine Learning Research,  7:117–139, 2006.  [17] A. Maurer, and M. Pontil. Excess risk bounds for multitask learning with trace norm regularization. In Proceeding of the 26th Annual Conference on Learning Theory, pages 55–76, 2013.  [18] A. Maurer. A chain rule for the expected suprema of Gaussian processes. In Proceedings of the  25th International Conference on Algorithmic Learning Theory, pages 245–259, 2014  [19] A. Maurer, M. Pontil, and B. Romera-Paredes. An inequality with applications to structured sparsity and multitask dictionary learning. In Proceedings of the 27th Conference on Learning Theory, pages 440–460, 2014.  [20] A. Maurer, M. Pontil, and B. Romera-Paredes. The beneﬁt of multitask representation learning.  arXiv preprint arXiv:1505.06279.  [21] A. Maurer. A vector-contraction inequality for Rademacher complexities. arXiv preprint  arXiv:1605.00251.  [22] R. Meir and T. Zhang. Generalization error bounds for Bayesian mixture algorithms. Journal  of Machine Learning Research, 4:839–860, 2003.  [23] Y. Mroueh, T., Poggio, R. Rosasco, and J. Slotine. Multiclass learning with simplex coding. In  Advances in Neural Information Processing Systems, pages 2789–2797, 2012.  [24] B. Neyshabur, R. Tomioka, and N. Srebro. Norm-based capacity control in neural networks.  In Proceedings of the 28th Conference on Learning Theory, pages 1376–1401, 2015.  21   [25] D. Slepian. The one-sided barrier problem for Gaussian noise. Bell System Tech. J., 41:463–  501, 1962.  [26] N. Srebro and A. Shraibman. Rank, trace-norm and max-norm. Annual Conference on Learning Theory, pages 545–560, 2005.  In Proceedings of the 18th  22   