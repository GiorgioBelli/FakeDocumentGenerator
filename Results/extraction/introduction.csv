Introduction  Continual learning—also called cumulative learning and lifelong learning—is the problem setting where an agent faces a continual stream of data, and must continually make and learn new predictions. The two main goals of continual learning are (1) to exploit existing knowledge of the world to quickly learn predictions on new samples (accelerate future learning) and (2) reduce interference in updates, particularly avoiding overwriting older knowledge. Humans, as intelligence agents, are capable of doing both. For instance, an experienced programmer can learn a new programming language signiﬁcantly faster than someone who has never programmed before and does not need to forget the old language to learn the new one. Current state-of-the-art learning systems, on the other hand, struggle with both (French, 1999; Kirkpatrick et al., 2017).  Several methods have been proposed to address catastrophic interference. These can generally be categorized into methods that (1) modify the online update to retain knowledge, (2) replay or generate samples for more updates and (3) use semi-distributed representations. Knowledge retention methods prevent important weights from changing too much, by introducing a regularization term for each parameter weighted by its importance (Kirkpatrick et al., 2017; Aljundi et al., 2018; Zenke et al., 2017; Lee et al., 2017; Liu et al., 2018). Rehearsal methods interleave online updates with updates on samples from a model. Samples from a model can be obtained by replaying samples from older data (Lin, 1992; Mnih et al., 2015; Chaudhry et al., 2019; Riemer et al., 2019; Rebufﬁ et al., 2017; Lopez-Paz and Ranzato, 2017; Aljundi et al., 2019), by using a generative model learned on previous data (Sutton, 1990; Shin et al., 2017), or using knowledge distillation which generates targets using  1We release an implementation of our method at https://github.com/khurramjaved96/mrcl  33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.   Figure 1: An example of our proposed architecture for learning representations for continual learning. During the inner gradient steps for computing the meta-objective, we only update the parameters in the prediction learning network (PLN). We then update both the representation learning network (RLN) and the prediction learning network (PLN) by taking a gradient step with respect to our meta-objective. The online updates for continual learning also only modify the PLN. Both RLN and PLN can be arbitrary models.  predictions from an older predictor (Li and Hoiem, 2018). These ideas are all complementary to that of learning representations that are suitable for online updating.  Early work on catastrophic interference focused on learning semi-distributed (also called sparse) representations (French, 1991, 1999). Recent work has revisited the utility of sparse representations for mitigating interference (Liu et al., 2019) and for using model capacity more conservatively to leave room for future learning (Aljundi et al., 2019). These methods, however, use sparsity as a proxy, which alone does not guarantee robustness to interference. A recently proposed online update for neural networks implicitly learns representations to obtain non-interfering updates (Riemer et al., 2019). Their objective maximizes the dot product between gradients computed for different samples. The idea is to encourage the network to reach an area in the parameter space where updates to the entire network have minimal interference and positive generalization. This idea is powerful: to specify an objective to explicitly mitigate interference—rather than implicitly with sparse representations.  In this work, we propose to explicitly learn a representation for continual learning that avoids interference and promotes future learning. We propose to train the representation with OML – a meta-objective that uses catastrophic interference as a training signal by directly optimizing through an online update. The goal is to learn a representation such that the stochastic online updates the agent will use at meta-test time improve the accuracy of its predictions in general. We show that using our objective, it is possible to learn representations that are more effective for online updating in sequential regression and classiﬁcation problems. Moreover, these representations are naturally highly sparse. Finally, we show that existing continual learning strategies, like Meta Experience Replay (Riemer et al., 2019), can learn more effectively from these representations. 
1 INTRODUCTION Development of machine learning (ML) applications is governed by an iterative process: starting with an initial workflow, developers iteratively modify their workflow, based on previous results, to improve performance. They may add or modify data sources, features, hyperparameters, and training algorithms, among others. These iterations of trial-and-error are necessary due to data variability, algorithmic complexity, and overall unpredictability of ML. A detailed, statistical characterization of how developers iteratively modify ML workflows can serve as a benchmark for human-in-theloop ML systems. At present, due to the lack of such studies, we are forced to resort to anecdotal evidence to identify usage patterns and motivate design decisions.  To this end, we conduct a statistical study of iteration by surveying the applied ML literature across five application domains. The statistics collected in this study provide the first quantitative evidence of how developers iterate on ML workflows, beyond anecdotal ones. Moreover, the insights and trends discovered from our survey provide concrete guidelines on desired human-in-the-loop ML system properties, while the models and statistics provide a starting point for the development of benchmarks for standardized and automatic evaluation of human-in-the-loop ML systems.  Statistical studies of end-to-end ML workflow development pose several challenges. First, it is difficult to gather data that captures the entire process, and not just the final snapshot. One approach, for example, may involve examining code repositories over time to determine what has changed—one downside of this approach is that developers may not commit intermediate iterations, leading to less transparency for the overall process. Moreover, this approach will require understanding code, and mapping code fragments to classes of iterative modifications, both of which are extremely challenging  to do. Second, we need to ensure that our study captures a diverse set of application domains. Surveys [1, 3, 9, 12] often end up focusing on industry-relevant application areas (e-commerce, recommendations), and data-types (language, vision). Since our eventual goal is to develop a benchmark for general-purpose human-in-the-loop ML systems, this limited view may hinder our ability to adequately support all application domains. Third, once the data is collected, we need to devise methods to analyze the data and collect statistics related to iteration. Finally, we need to turn the raw statistics into models that capture iteration and relate trends and insights discovered from these models to ML system design.  Our study includes an analysis of 105 applied machine learning papers sampled from multiple conferences in 2016 and across five application domains, including social sciences, natural sciences, web application, computer vision, and natural language processing. We collect statistics from each paper that capture iterative development and use these statistics to infer common practices in each application domain surveyed. We describe the statistics collected, how they are used to estimate iteration counts, and discuss the limitations of our approach in the next section. To ensure the quality of our statistics, we take consensus over results collected by multiple surveyors, and open-source the final aggregated data for further studies by interested readers, as well as development of formal benchmarks. We conduct data analysis on our survey results to highlight key insights unearthed by our survey and propose system requirements suggested by our analysis.  Related Work. To the best of our knowledge, our survey is the first effort in conducting a statistical study of machine learning model development from empirical evidence. However, the pursuit of understanding iterative ML development is not singularly ours. Several surveys have been conducted in recent years to profile industry and academic ML users [1, 3, 9, 12]. These surveys differ from ours in that they were self-reported responses from a select set of industry and academic users. Findings from self-reporting surveys are known to suffer from response bias [13]. Many articles discuss general trends and design patterns in ML workflows [2, 6, 7], while a number of articles focus on providing guidance and taxonomies for novice users to perform iteration better [14, 15, 18]. Other works such as [4] and [11] study general trends and needs in data science using NLP techniques to study a large corpus en masse. Vartak et al. [16] describe a system-building vision for iterative human-in-the-loop ML. Kery et al. [8] specifically study the versioning aspect of iterative development, whereas Koesten et al. [10] analyze in-depth surveys to understand the typical workflow for data scientists.  The rest of paper is organized as follows: In Section 2, we describe the data, the statistics collected from the data, and the methods to   • Devising estimators that do no rely on information about the  order of operations, to be elaborated in Section 2.4. 
1. Introduction  The ﬁeld of quantum technologies has experienced a signiﬁcant boost in the past ﬁve years. The interest of multinational companies such as Google, IBM, Microsoft, Intel, and Alibaba in this area has increased the worldwide competition and available funding not only from these ﬁrms, but also from national and supranational governments, such as the European Union [1, 2]. Most of these companies have also a strong focus on machine learning, which is a wider-deployed technology, as it is currently more advanced. Increases in the past decade in computing power, via, e.g., Graphical Processing Units (GPUs), and the extensive availability of data in internet, have enabled a signiﬁcantly good performance of deep learning. Among others, image recognition,   Quantum machine learning and quantum biomimetics: A perspective  2  language translation, search engines, automated cars, and personal assistants, have become widespread nowadays [3, 4].  Given that quantum systems are well described by linear algebra, and this also applies to several machine learning algorithms, it was only a matter of time that these two ﬁelds merged in a new area, namely, quantum machine learning. An exponentially-growing amount of papers has appeared in this area in the past three to four years [5], and already several books and reviews on this ﬁeld have been published [6, 7, 8, 9, 10, 11, 12]. Existing algorithms include quantum solvers of linear systems of equations [13], quantum support vector machines [14], quantum principal component analysis [15], quantum gradient estimation [16], and distributed secure quantum machine learning [17], among others. Further research areas inside quantum machine learning include quantum reinforcement learning [18, 19, 20, 21, 22, 23, 24, 25], quantum autoencoders [26, 27, 28, 29, 30, 31], quantum neural networks [11, 27, 32, 33, 34, 35, 36, 37], as well as quantum annealing [38, 39, 40], quantum Boltzmann [41, 42, 43] and quantum Helmholtz machines [44, 45]. Another research avenue complementary to the former ones, consists in employing machine learning algorithms to better control quantum systems, reduce gate errors, increase state preparation ﬁdelities, and compute quantum phases of matter [46, 47, 48, 49, 50, 51, 52, 53]. Moreover, inside this emerging area, a growing amount of papers in the ﬁeld of machine learning for better understanding quantum systems can be also classiﬁed in reinforcement learning [54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66], supervised learning [67, 68, 69, 70, 71, 72, 73, 74, 75], and unsupervised learning [76, 77] works. For a recent review on this speciﬁc ﬁeld, see [78]. Finally, another interesting topic that has appeared recently is the one of quantum-inspired algorithms, namely, classical machine learning algorithms that get inspiration from quantum algorithms [79, 80].  Another ﬁeld that aims at connecting two previously disconnected research areas such as quantum technologies and biological systems [81, 82, 83] is the one of quantum biomimetics. This has some overlap with quantum machine learning in topics such as, e.g., quantum neural networks, which are also biomimetic: They consist of a quantization of neural networks that, in turn, get inspiration from the human brain, a biological system. Quantum artiﬁcial life is an area inside quantum biomimetics in which the aim is to design quantum individuals that can self-replicate in a quantum fashion, namely, without breaking the no-cloning theorem [84, 85, 86, 87]. They can also mutate, and evolve with a quantum Darwinian process. Even though this is still a ﬁeld in its infancy, we expect that it could have connections with quantum game theory [88] and could allow one for encoding optimization problems, being this way connected again with the quantum machine learning ﬁeld. Related research has been carried out by diverse groups [89, 90, 91, 92]. A second area inside quantum biomimetics is the one of quantum memristors [93, 94, 95, 96]. These are devices with processing power, memory, and quantum character, inspired in the classical memristor, the fourth element in electronic engineering in addition to the resistor, capacitor, and inductor [97]. A classical memristor has processing capacity at the same time as memory, and has been   Quantum machine learning and quantum biomimetics: A perspective  3  conjectured to be able to solve NP problems in polynomial time. Classical memristors may provide a novel paradigm for computing, with a neuromorphic architecture, and, equivalently, quantum memristors represent the basic building block for a neuromorphic quantum computer. They have also a close connection to quantum neural networks, and may provide a platform to quantum simulate non-Markovian quantum open systems.  In this Perspective, we will revise the ﬁelds of quantum machine learning and quantum biomimetics, without the goal of being exhaustive, and focusing mainly on our own research of the past six years, as well as related research by other groups. Our motivation is to give our vision of what has been the development of these two ﬁelds in the past few years, and what could be their future evolution. Even though these two areas may seem rather disconnected at ﬁrst sight, they have a strong relationship, as described for example in Ref. [82] for the classical cases: living systems, either natural or artiﬁcial, have often the ability to learn. Being this article also a Perspective, it is naturally more biased towards my own research, and that of my collaborators at the QUTIS Group in University of the Basque Country [98], which has considered these two ﬁelds in parallel and with multiple links. As examples of this, one can mention the international conference we coorganized in Bilbao in March 2018, on “Quantum Machine Learning & Biomimetic Quantum Technologies”, as well as the Special Issue we edited on “Quantum Machine Learning and Bioinspired Quantum Technologies” [99]. We will ﬁrst start with Section 2, on quantum machine learning, in which we will describe two emerging topics inside this area, namely, quantum reinforcement learning, and quantum autoencoders. In Section 3, on quantum biomimetics, we will revise other two topics, i.e., quantum artiﬁcial life, both as a proposal and its experimental realization in the IBM cloud quantum computer, and quantum memristors. We will then give our conclusions in Section 4.  2. Quantum machine learning  Machine learning is one of the ﬁelds with a larger impact in computer science nowadays [4]. Its inﬂuence is widespread along a large number of technologies and economies, and this will only grow in the future. One of the reasons for this success is the so-called deep learning technology [3]. This kind of approach, based on neural networks with several layers, and the backpropagation algorithm, has existed since the 80’s, but only recently has started to work eﬃciently. This is due to the availability of higher processing capabilities, via GPUs, and the large amount of data at disposal, i.e., Big Data from the internet [3]. The typical machine learning algorithms are divided into three classes. A ﬁrst class of machine learning algorithms is named supervised learning [4]. These algorithms are trained via feeding them with labeled data, e.g., training a neural network with pictures of cats. After several iterations of the learning process, the network is able, if properly trained, to diﬀerentiate a picture from a cat from one of, say, a dog. A second class of machine learning algorithms is named unsupervised learning [4]. In this case, no labeled data is provided, while, in turn, the learning is   Quantum machine learning and quantum biomimetics: A perspective  4  produced via establishing correlations in the available data itself that one wants to classify. Via grouping this data in clusters, one is able to allocate new data inside one of these clusters, according to the highest proximity to it following some ﬁgure of merit, e.g., mathematical distance. Finally, a third class of machine learning algorithms, that is possibly more similar to the way the human brain itself learns, is the one of reinforcement learning [4, 100]. In this kind of learning, a system, the agent, which can be, for instance, a robot, a computer program, a chemical molecule, or a quantum device, interacts with another system, the environment, which is the outer world to it, that is also relevant to its dynamics [4, 100]. In this interaction, the agent obtains information from the environment, and also carries out some action on it, possibly modifying it. It then decides on a strategy, or policy, on how to proceed, depending on the feedback obtained from the interaction and action, and, iterating this procedure several times, aims at achieving some ﬁnal goal. Reinforcement learning is the kind of learning that has taken more time to develop inside machine learning, but it has proven one of the most successful ones in the past few years, with the impressive achievements of AlphaGo and AlphaGo Zero in beating the Grandmasters of Go [101, 102]. Go is a highly strategic game, much more complex than chess, which was not expected to be won by an artiﬁcial intelligence anytime soon. However, via a combination of supervised and reinforcement learning, AlphaGo beat some of the leading human experts at Go [101]. Later on, AlphaGo Zero beat AlphaGo by 100-0, employing only reinforcement learning, playing millions of times against itself and learning in each iteration a bit more, an impressive achievement without any external training [102].  A diﬀerent kind of approach is the concept of autoencoder [3]. It consists of a neural network that allows for compressing information, in the following fashion: the network contains an input layer (encoder), with a number of neurons, say, n. Then, it has one or more inner layers, with a number of neurons n(cid:48) < n. And ﬁnally, it is connected to an output layer (decoder) with again n neurons. One then trains this kind of network with data, assuming that it can be compressed (namely, it has common features). The process consists on aiming at matching the output signal of the network with the input signal, i.e., being able to employ only the n(cid:48) neurons to encode the information, instead of the n initial ones, which is a larger number. If the process is successful, one may then discard the decoder and keep only the input layer, the encoder, therefore compressing the information.  In this Section, we will focus ﬁrstly on the machine learning algorithm known as reinforcement learning, and its recent development in the quantum realm, i.e., quantum reinforcement learning. We will describe the pioneering work by diﬀerent groups in this topic, as well as our own results of the past few years.  Later on, we will analyze the quantum version of autoencoders, namely, quantum autoencoders, and describe the eﬀorts by several groups both in theory and experiments in developing this technology.   Quantum machine learning and quantum biomimetics: A perspective  5  2.1. Quantum reinforcement learning  Figure 1. Scheme of reinforcement learning. A system, called agent, interacts with the external world, the environment, realizing some action on it, as well as obtaining information from it, via a percept. Subsequently, the agent decides on a strategy on how to act or improve itself, by means of a reward criterion that depends on the action and percept, and the process is iterated. The motivation for the agent to follow this procedure is achieving a ﬁnal goal. In the quantum reinforcement learning scenario, either agent, environment, or both, should be quantum, and they may exchange either quantum or classical information, or a mixture of both, with possible feedback in each iteration. Adapted from Ref. [21].  In the ﬁeld of quantum machine learning, quantum reinforcement learning (see Fig. 1) is a paradigm that has emerged in recent years [18, 19, 20, 21, 22, 23, 24, 25, 54, 55]. Some of the published works consider a quantum agent and a quantum environment (so called QQ scenario) [20, 21, 22, 23, 24, 25], others consider a quantum agent and classical environment (QC) [18, 19, 20], another possibility would be to analyze a classical agent and quantum environment (CQ), while the fourth available combination (CC) corresponds to the purely classical situation of standard reinforcement learning.  In Ref.  [18], a mapping of classical reinforcement learning onto quantum reinforcement learning, connecting states of the former with quantum states of the is proposed. Quantum superposition and entanglement are involved in the latter, quantum algorithm, giving evidence of a possible resource gain with respect to classical reinforcement learning. The proposed protocol is based on Grover algorithm for unstructured search with quantum computers [103].  Ref. [19] analyzes a possible quantum advantage of a quantum agent interacting with a classical environment with classical channels, where the speedup would come   Quantum machine learning and quantum biomimetics: A perspective  6  from a faster quantum processor in the agent. This would be based, as in the previous case, in Grover search.  Ref. [20] explores quantum reinforcement learning among other types of quantum learning, showing that quadratic improvements in learning eﬃciency, as well as exponential improvements in performance over limited amounts of time, may be achieved. For this, they consider a quantum agent and a quantum oracular environment. The series of references [21, 22, 23, 24, 25] deal with quantum reinforcement learning in the QQ scenario, namely, quantum agent and quantum environment, in an increasing amount of complexity, and focusing on possible implementations. Refs. [21, 22] propose basic protocols of quantum reinforcement learning with superconducting circuits, including either coherent feedback inside the protocol, or projective measurements. In both cases, a single copy of the quantum environment state is considered, and the goal of the agent is to achieve a ﬁnal quantum state that is identical to the environment one while, necessarily, modifying the latter. Ref. [23] goes a step forward, taking into account several copies of the quantum environment state, such that the agent can achieve an increasing overlap with this state, which is its ﬁnal goal. In Ref. [24], an experimental implementation of the previous proposal in quantum photonics was carried out. Interestingly, a gain of this quantum reinforcement learning protocol with respect to standard quantum tomography was achieved, in the limited resources scenario. In the subsequent Ref. [25], an extension of the protocol to unknown operations, instead of states, was analyzed. Namely, this proposal would allow one to determine an unknown quantum operation, or, equivalently, its eigenvectors and eigenvalues, via a quantum reinforcement learning protocol.  2.2. Quantum autoencoders  Recently, proposals and experiments for quantum autoencoders have been explored by diﬀerent groups (see Fig. 2). In Refs. [26, 27], one is given a set of states, inside a certain Hilbert space, and the aim is to be able to consider a smaller section of the Hilbert space that contains all the relevant information, namely, to somehow compress the quantum information onto a smaller amount of quantum bits or qubits. To this aim, in analogy with classical autoencoders, a quantum circuit composed of an input series of qubits is connected, via a parameterized unitary operation, to a smaller amount of qubits, and, subsequently, by means of a second parameterized unitary gate, to the same amount of qubits as the input. By feeding this quantum circuit with the set of states considered initially, and by measuring the output of the circuit, one may train the device, via classical feedback onto the parameters of the two unitary gates, in order to maximize the output ﬁdelity with respect to the input states. This is similar to the standard autoencoder but in a quantum scenario. If the training is successful, then one may discard the ﬁnal unitary gate, equivalent to the decoder, and keep only the initial one, the encoder, therefore reducing the amount of quantum information needed for practical applications. This could be useful, e.g., for quantum simulations [26]. An   Quantum machine learning and quantum biomimetics: A perspective  7  experimental realization of the previous proposal [26] has been carried out in a quantum photonics platform employing a three-level quantum system, a qutrit [29].  Figure 2. Scheme of a quantum autoencoder, based on the algorithms in Refs. [26, 27]. A set of input quantum states in a certain Hilbert space is encoded into a smaller Hilbert space via a learning process. Adapted from Ref. [28].  A diﬀerent approach to quantum autoencoders was put forward in Refs. [28, 30] (see Fig. 3). This is based on encoding the initial quantum information in a more reduced amount of qubits via the use of approximate quantum adders. In Ref. [104], a theorem was proven that showed that a unitary operation able to add two unknown quantum states is forbidden by the laws of quantum physics (see also Ref. [105]). Nevertheless, this paper deﬁned approximate quantum adders optimized according to diverse prespeciﬁed criteria. In Ref. [49], an optimization of approximate quantum adders based on genetic algorithms, a kind of machine learning algorithm, was realized. Subsequently, Ref. [28] developed a proposal for a quantum autoencoder based on the quantum adders optimized in Ref. [49]. Finally, Ref. [30] implemented the previous proposal in the Rigetti cloud quantum computer, showing its feasibility.  Finally, another kind of autoencoders in the quantum realm has been proposed and implemented in the same article [31], namely, variational quantum autoencoders, which describe generative models implemented via quantum Boltzmann machines [41].  3. Quantum biomimetics  Quantum biomimetics is the ﬁeld that aims at connecting other two previously disconnected research areas such as quantum technologies and biological systems [81, 83]. This has links to quantum machine learning in areas such as, e.g., quantum neural networks, which are also biomimetic systems. Quantum artiﬁcial life is a ﬁeld inside quantum biomimetics in which the objective is to design quantum individuals that can self-replicate in a quantum way, namely, in a compatible manner with the no-cloning theorem [84, 85, 86, 87]. A second ﬁeld in quantum biomimetics is the one called quantum memristors [93, 94, 95, 96]. These are inspired in the classical memristor,  M1| 1i| 2i|0iM2M2U1U2 Quantum machine learning and quantum biomimetics: A perspective  8  Figure 3. Scheme of a quantum autoencoder based on approximate quantum adders. The two unknown input qubit states are encoded onto a single qubit, to a certain ﬁdelity, via an approximate quantum adder operation. Adapted from Ref. [28].  the fourth element in electronic engineering in addition to the resistor, capacitor, and inductor [97]. A classical memristor can process information at the same time as having a memory, and may provide a novel paradigm for computing, with a neuromorphic architecture. Equivalently, quantum memristors constitute a basic building block for a neuromorphic quantum processor.  In this Section, we will ﬁrst revise the topic of quantum artiﬁcial life, beginning with theoretical works [84, 85] and ﬁnishing with an experimental implementation in the IBM cloud quantum computer [86].  Later on, we will describe the topic of quantum memristors, according to a series  of results in the literature [93, 94, 95, 96].  3.1. Quantum artiﬁcial life  Artiﬁcial life is a research ﬁeld that aims to reproduce biological properties common to living systems in artiﬁcially engineered systems [81, 82]. Some examples are selfassembling robots [106], self-replicating chemicals [107] or computing programs [108], as well as living neurons grown in the lab and connected to external devices [109]. One of the main areas inside this thriving ﬁeld is the self-replicating systems. Living systems acquire complexity and structure via Darwinian evolution, or natural selection, and this is a combination of self-replication, introduction of variability via mutations as well as genome exchange, and selection of the ﬁttest. Therefore, self-replication is In the research line of quantum artiﬁcial life, a series one of the hallmarks of life. of works has explored the possibility for elementary quantum systems to undergo selfreplication [84, 85, 86] . This is a non-trivial issue given that the no-cloning theorem [87] prevents the perfect copying of unknown quantum states. Thus, perfect self-replication onto distinct progeny individuals would not be allowed. What these works show is that the full quantum information can be faithfully transferred to the progeny individuals,  Memory1| 1i| 2iUautadd| outi⇠| 1i+| 2i|0iMemory2 Quantum machine learning and quantum biomimetics: A perspective  9  under ideal conditions, if one maps the classical information of the diagonal elements of the parent density matrix onto the diﬀerent progeny systems. On the other hand, the coherences of the parent density matrix would be mapped onto quantum correlations of the progeny systems. Therefore, entanglement plays a crucial role in the context of having self-replicating quantum systems.  Figure 4. Scheme for quantum artiﬁcial life. A quantum living unit, or quantum individual, is created from two qubits, which constitute the genotype and phenotype. The phenotype then decoheres when coupled with a quantum reservoir, until producing the “death” of the quantum individual. While still “alive”, the quantum individual can undergo self-replication, via coupling with further ancillary qubits. In order to transfer its full quantum information, the original quantum individual becomes entangled with its progeny quantum individuals. Adapted from Ref. [85].  In Ref. [84], a ﬁrst analysis of biomimetic cloning of quantum observables was carried out, suggesting that the full quantum information may be transferred onto successive generations via cloning of classical information together with controlled transfer of quantum correlations. Later on, Ref. [85] proposed an implementation of a model of quantum artiﬁcial life. In this model, a quantum living unit, or quantum individual, is composed of two qubits, one for the genetic information, or genotype, and another for the expression of the genotype in the environment, or phenotype. The individual is created via a partial cloning operation of the genotype onto the phenotype via a Controlled-NOT operation, a kind of entangling two-qubit quantum gate. Subsequently, the phenotype can get coupled with a quantum reservoir, that induces decoherence on it. After a certain amount of time, the phenotype has almost totally decohered, and one considers that it has “died”, at least as an artiﬁcial life individual, and according to this model. While the quantum individual is still “alive”,   Quantum machine learning and quantum biomimetics: A perspective  10  it can couple with further ancillary qubits, carrying out additional partial cloning operations with Controlled-NOT gates, and produce new quantum individuals, which become entangled to the initial one, as previously explained (see Fig. 4).  Figure 5. Quantum circuit for the most complex quantum artiﬁcial life protocol experimentally carried out in Ref. [86]. The number of two-qubit Controlled-NOT entangling gates is of 20. H denotes a Hadamard gate, and the numbers inside the single-qubit gates indicate diﬀerent phases, as described in Ref. [86].  Figure 6. Theoretical (yellow) and experimental (blue) data of the diﬀerent experiments of a quantum artiﬁcial life system in the IBM cloud quantum computer. Adapted from Ref. [86].  In Ref. [86], a quantum implementation of the quantum artiﬁcial life model of Ref. [85] was carried out in the IBM cloud quantum computer. Fig. 5 shows the most complex quantum circuit that was implemented in this experiment. The number of entangling gates was of 20. On the other hand, Fig. 6 depicts the theoretical (yellow) together with the experimental (blue) data of the diﬀerent experiments of quantum artiﬁcial life carried out in the IBM cloud quantum computer. Even though the  1/43/4HHHHHHHHS1/41/4,0,1|0i1|0i0|0i2|0i4T+1/4-1/4T1/4-1/40,3/40,-1/2HHHHHH1/81/81/81/8Basis elementProbability00.20.40.60.8IBasis elementProbability00.20.40.60.8IIBasis elementProbability00.050.10.15IIIBasis elementProbability00.10.20.30.40.50.6IVBasis elementProbability00.10.20.30.40.5V Quantum machine learning and quantum biomimetics: A perspective  11  ﬁdelities are not perfect, the experimental setup qualitatively reproduces the theoretical prediction to a large extent, for an experiment of a certain complexity.  3.2. Quantum memristors  Subsequently,  The other topic in quantum biomimetics we will describe here is the one of quantum In Ref. [93], a quantum version of a memristor was memristors [93, 94, 95, 96]. introduced, in which a two level quantum system encodes the quantum information, being supplemented with a weak measurement to acquire information, as well as It was proven feedback onto the system depending on the measurement outcome. that this device possesses hysteresis, and therefore a memory, in addition to processing capabilities. It was conjectured to be able to simulate non-Markovian quantum systems. two proposals for implementations of quantum memristors in diﬀerent quantum platforms were put forward, namely, superconducting circuits [94] and quantum photonics [95]. In the former, the memristive behavior emerges from quasiparticle-induced tunneling when supercurrent cancellation takes place. For realistic parameters, the appearing hysteretic behavior may be measured using state-of-theart tomography of the phase-driven tunneling current. In the latter, the memristive behaviour arises from a tunable beam splitter, to which the input state is directed, together with feedback from one of the output ports onto the beam splitter that modiﬁes its reﬂectivity depending on the output signal.  Finally, another result has been published on some complementary devices to  quantum memristors, namely, qubit-based memcapacitors and meminductors [96].  As we have introduced, classical memristors constitute a paradigm for neuromorphic Equivalently, quantum memristors represent a building block for a computing. neuromorphic quantum device. A proven speedup with respect to their classical counterparts is still an open problem. Nevertheless, they represent a novel and promising quantum system that may play an important role in the future in a wide variety of scenarios as distributed quantum computing, quantum neural networks, and simulation of non-Markovian quantum systems. 
I. INTRODUCTION  Motivation. Research has shown the importance of extracting requirements related information from user feedback to improve software products and user satisfaction [32]. As user feedback on social media or app stores can come thousandfold daily, a manual analysis of that feedback is cumbersome [31]. However, analyzing this feedback brings opportunities to understand user opinions better because it contains valuable information like problems users encounter or features they miss [31], [12]. Researchers have applied supervised machine learning to ﬁlter noisy, irrelevant feedback and to extract requirements related information [27], [14]. Most related works rely on traditional machine learning approaches, which require domain experts to represent the data with hand-crafted features. In contrast, end-to-end deep learning approaches automatically learn high-level feature representations from raw data without domain knowledge, achieving remarkable results in different classiﬁcation tasks [11], [33], [38]. Objective. In this work, we aim at understanding if and to what extent deep learning can improve state-of-the-art results for classifying user feedback into problem reports, inquiries, and irrelevant. We focus on these three categories because practitioners seek for automated solutions to ﬁlter noisy feedback (irrelevant), to identify and ﬁx bugs (problem reports), and to ﬁnd feature requests as inspiration for future releases (inquiries) [27]. We consider all user feedback as problem reports, that state a concrete problem related to a  software product or service (e.g., “Since the last update the app crashes upon start”). We deﬁne inquires as user feedback that asks for either new functionality, an improvement, or requests information for support (e.g., “It would be great if I could invite multiple friends at once”). We consider user feedback as irrelevant if it does not belong to problem reports or inquires (e.g., “I love this app”).  To fulﬁll our objective, we employ supervised machine learning fed with crowd-sourced annotations of 10,000 English and 15,000 Italian tweets from telecommunication Twitter support accounts, and 6,000 annotations of English app reviews. We apply best practices for both machine learning approaches (traditional and deep learning) and report on a benchmark. Preliminary results. Our preliminary results show that, within our setting, traditional machine learning can achieve comparable results to deep learning. One possible explanation is that domain experts’ knowledge in traditional machine learning brings considerable performance improvements using simple but powerful features, including speciﬁc keywords. In general, the classiﬁcation of irrelevant user feedback achieves the best results meaning that practitioners could use our reported models to ﬁlter noisy feedback. Contribution. The contribution of this paper is threefold. First, we give insights on how traditional machine learning compares to deep learning on classifying feedback by describing both approaches and by performing a large series of experiments. Second, we provide a replication package containing the scripts and experiment setups. Third, we report the conﬁgurations of top-performing machine learning models. Structure. In Section II, we introduce the methodology of this paper by detailing our research questions, design, and data. Section III describes the pipeline and the setup for both machine learning approaches. Section IV reports on our classiﬁcation benchmark showing the accuracy and the conﬁguration of the top-performing models. Then, Section V discusses the implications of the results and possible application ﬁelds, as well as the threats to validity. Section VI summarizes the related work while Section VII concludes the paper. 
INTRODUCTION  Predicting criminal recidivism using statistics has been the subject of almost a hundred years of research in criminal  justice, psychology, and law. Today, actuarial risk assessments are in wide use across many countries, helping judges make  life-changing decisions in pretrial release, sentencing, and probation. Risk assessments can help reduce costs, racial  disparity, and incarceration rates—and these beneﬁts have already been realized in some jurisdictions [1]. However,  some of the most widely used algorithms are secret, black-box models created by corporations. As a result, individuals  affected by these algorithms cannot know how these decisions were made, or whether they were made in error. These  problems resulted in various lawsuits over the last decade, and came to the fore in 2016, when investigative journalists from the nonproﬁt organization ProPublica claimed that the COMPAS1 black-box recidivism prediction model was rife  with racial bias [2, 3].  Though ProPublica’s ﬁndings were not validated [4, 5, 6], the COMPAS scandal demonstrated the issues with  for-proﬁt, secret algorithms making decisions in the justice system—namely, possible violations of defendants’ due  process rights, difﬁculty in ensuring that the scores were calculated based on correct inputs, and the lack of independent  fairness or performance guarantees. It highlighted the ways that systemic bias in data can be propagated into the future,  and was symptomatic of growing public distrust in the algorithms that impact our daily lives [7, 8, 9].  To prevent errors, prevent due process violations, allow independent validation of models, and gain public trust, we  must create transparent, interpretable and fair models. Fortunately, techniques for interpretable machine learning and  theories of fairness have advanced considerably over the last few years. Multiple works have demonstrated that publicly  available interpretable machine learning algorithms can perform as well as black-box machine learning algorithms  [10, 11, 12]. Moreover, high-dimensional data sets on criminal recidivism have become increasingly available. However,  most machine learning papers treat recidivism prediction as a toy problem to test new machine learning algorithms.  They do not consider factors such as data quality or ease of computation of model predictions, which are paramount  for creating models that would be useful in practice. To our knowledge, there is only one prior work [13] that jointly  considers interpretability, fairness, and predictive performance; however, it does not do so in a comprehensive way and  focuses primarily on the design of a new algorithm.  Beyond the problem of model optimization, various methodological questions remain with existing risk assessment  systems. First, existing systems—such as COMPAS (Correctional Offender Management Proﬁling System for Alternative  Sanctions) and LSI-R (Level of Service Inventory Revised)—are often used across various states (or even countries)  with only minor normalization [14, 15]. However, populations in different states can signiﬁcantly differ because the  data generation process is not the same, so applying the same model across states may not lead to the best possible  performance. Second, empirical evidence indicates that the underlying probability distribution of recidivism has  changed over time in multiple locations [16]. For instance, a signiﬁcant shift in the age distribution—a key predictor in  many recidivism prediction models—has been observed in New York [17]. Thus, rather than using a static model with  uneven performance across districts, a better solution might be to algorithmically generate models, so that they can be  trained for speciﬁc locations and retrained if recidivism distributions shift over time.  Using modern tools of both interpretable and black-box machine learning, we revisit the recidivism prediction  problem. We deﬁne recidivism as a new charge that an individual is convicted for within a certain time frame (six months  1COMPAS stands for Correctional Offender Management Proﬁling for Alternative Sanctions.   4  WANG & HAN ET AL.  or two years). We ﬁnd that (1) black-box models do not perform signiﬁcantly better than interpretable models for any of  the twelve recidivism problems we consider. (2) Interpretable models generally perform better than existing actuarial  risk assessments. (3) Models do not generalize well across regions. (4) Only a small subset of the many proposed fairness  deﬁnitions can be applied to regression problems and they vary across different models. We also note that existing  techniques to enforce fairness generally require non-interpretable transformations, and therefore do not work well  with interpretable models.  This paper is structured as follows. Section 2 describes our contributions. Section 3 discusses the evolution of risk  assessment in America, the current debate over risk assessments, and brieﬂy reviews the machine learning literature on  risk assessment. Section 4 describes the study’s data sources. Section 5 discusses aspects of our methodology, including  the prediction problems, problem setup, and the existing risk assessments we compare against. Section 6 presents the  performance of baseline, non-interpretable machine learning methods, while Section 7 presents the performance of  interpretable machine learning methods. Section 8 examines the generalization of recidivism prediction models across  states. In Section 9, we describe the selection of fairness metrics and assess the fairness of the interpretable models. In  Section 10, we discuss broader impacts and future lines of inquiry. 
1 Introduction  The main focus of this paper is to study statistical bounds for (shared) representation learning under a general class of feature maps and loss functions. This study is motivated by the development of data-dependent generalization bounds for multi-category learning with T classes, and for multitask learning with T tasks. We show that both problems can be treated in parallel under a uniﬁed framework.  We give bounds on the Rademacher complexity of composite vector-valued function classes  F ◦ G =  x ∈ H 7→ f (g (x)) ∈ RT : f ∈ F, g ∈ G (cid:8)  (cid:9)  ,  where the input space H is a ﬁnite or inﬁnite dimensional Hilbert space, G is a class of functions (or → RT . feature-maps or representations) g : H → RK, and F is a class of output functions f : RK  1   Functions in F ◦ G are chosen on the basis of a ﬁnite number N of independent observations and we are interested in uniformly bounding the incurred estimation errors in terms of the parameters T , K and N , or alternatively n = N/T , the number of observations per output unit.  There are two main contributions of this work:  • We provide a common method to derive data dependent bounds for multi-task and multicategory learning in terms of the complexity of general vector-valued function classes. In passing we improve on a recent result in [15] on multi-category learning. Our framework is also general enough to be applied to hybrid coding schemes for multi-category classiﬁcation such as 1-vs-1 pairwise classiﬁcation.  • We apply this method to a large class of vector-valued functions with shared feature maps to demonstrate that the conditions under which shared representations are beneﬁcial for multitask learning are equally applicable to multi-category learning.  Our principal ﬁnding is a data-dependent generalization bound, whose dominant terms have  the form  tr( ˆC) nT   θs  λmax( ˆC)  ,  n   θs  + O        O    where ˆC is the empirical covariance operator (see below). When testing multi-task learning we are always told which task we are testing and thus the relevant component of our vector-valued hypothesis. In the one-vs-all multi-category setting we of course withhold the identity of the correct class and thus also of the relevant component. This simple fact is reﬂected in the presence of the factor θ, which is one for multi-task learning and √T for multi-category learning.  Bounds of this form are given for a large class of neural networks with one hidden layer and rather general nonlinear activation functions, which may involve inter-unit couplings or intermediate maps to inﬁnite-dimensional spaces. A similar bound also holds for linear classes with tracenorm constraints, which can also be interpreted as composite classes, see e.g. [26].  As T increases the second term dominates the above expression. This term however depends only on the largest eigenvalue, instead of the trace, of the empirical covariance. If T is large and the data is high-dimensional the intermediate representation can therefore give a considerable advantage. This has been established for multi-task learning in several works and, as we show here, holds equally for multi-category learning, in agreement with previous empirical studies of the beneﬁt of trace-norm regularization in multi-category learning [1].  In Section 2 we explain how the complexities of multi-category and multi-task learning can be reduced to the complexities of vector-valued function classes and bounded by a common expression. We brieﬂy discuss independent and linear classes in Section 3.1 and 3.2. Then in Section 3.3, we present our principal result on nonlinear composite classes. The appendix contains statements and proofs of our results in their most general form.  2   1.1 Previous Work  Bounds for multi-layered networks are given in the now classical work [3] in terms of covering numbers. More recently there are bounds using Rademacher averages [24]. These works mainly consider scalar outputs and ignore the regularizing effects of intermediate representations.  Early work to consider the potential beneﬁts of shared representations was in the setting of multi-task learning and learning to learn [5]. Subsequent work has focused more on learning bounds for linear feature learning [7, 16]. Recently [20] presented a general bound for multitask representation learning. Although there has been substantial work on the statistical analysis of learning shared representations for multi-task learning, less has been done for multi-category learning. This is in contrast with the large body of empirical work on deep networks, which are often trained with a multi-class loss [9], such as the soft max or multi-class hinge loss. In this work we close this gap. 