PAPER PATH: ../datasets/downloaded/2005.04176v1.In_Pursuit_of_Interpretable_Fair_and_Accurate_Machine_Learning_for_Criminal_Recidivism_Prediction.pdf


================TABLE OF CONTENTS================
207:	INTRODUCTION
315:	2 | CONTRIBUTION
365:	3 | BACKGROUND
583:	3.3 | Fair Machine Learning
629:	4 | DATA
694:	5 | METHODOLOGY
803:	5.1 | Prediction Labels
913:	5.2 | Problem Setup
937:	6 | BASELINE MACHINE LEARNING METHODS
1008:	6.1 | Broward Baseline Results
1029:	6.2 | Kentucky Baseline Results
1228:	7.2 | Broward Prediction Results for Interpretable Models
1257:	7.3 | Kentucky Prediction Results for Interpretable Models
1283:	7.4 | Tables and Visualizations of Interpretable Models
1293:	7.4.1 | EBM Models
1321:	7.4.2 | Additive Stumps
1343:	7.4.3 | RiskSLIM
1434:	8 | RECIDIVISM PREDICTION MODELS DO NOT GENERALIZE WELL ACROSS
1493:	8.1 | Training on One Region and Testing on the Other
1573:	9 | FAIRNESS
1601:	9.1 | Selection of Fairness Metrics: Calibration, Balance for Positive/Negative Class, Bal
1772:	9.2 | Fairness Results
2089:	10 | DISCUSSION AND FUTURE WORK
2589:	11 | APPENDIX
2591:	11.1 | Broward Data Processing
2699:	11.2 | Kentucky Data Processing
2868:	11.3 | Why We Compare Only Against COMPAS and the PSA
3148:	11.4 | Hyperparameters
3385:	11.5 | Tables
4179:	21. ADE ≥ 1
4195:	29. Intercept
5262:	11.6 | Figures
5361:	11.7 | Nested Cross Validation Procedure
5396:	11.8 | RiskSLIM Tables
6188:	11.9 | Features
========================================
====================ABSTRACT====================

========================================
====================INTRODUCTION====================
INTRODUCTION

Predicting criminal recidivism using statistics has been the subject of almost a hundred years of research in criminal

justice, psychology, and law. Today, actuarial risk assessments are in wide use across many countries, helping judges make

life-changing decisions in pretrial release, sentencing, and probation. Risk assessments can help reduce costs, racial

disparity, and incarceration rates—and these beneﬁts have already been realized in some jurisdictions [1]. However,

some of the most widely used algorithms are secret, black-box models created by corporations. As a result, individuals

affected by these algorithms cannot know how these decisions were made, or whether they were made in error. These

problems resulted in various lawsuits over the last decade, and came to the fore in 2016, when investigative journalists
from the nonproﬁt organization ProPublica claimed that the COMPAS1 black-box recidivism prediction model was rife

with racial bias [2, 3].

Though ProPublica’s ﬁndings were not validated [4, 5, 6], the COMPAS scandal demonstrated the issues with

for-proﬁt, secret algorithms making decisions in the justice system—namely, possible violations of defendants’ due

process rights, difﬁculty in ensuring that the scores were calculated based on correct inputs, and the lack of independent

fairness or performance guarantees. It highlighted the ways that systemic bias in data can be propagated into the future,

and was symptomatic of growing public distrust in the algorithms that impact our daily lives [7, 8, 9].

To prevent errors, prevent due process violations, allow independent validation of models, and gain public trust, we

must create transparent, interpretable and fair models. Fortunately, techniques for interpretable machine learning and

theories of fairness have advanced considerably over the last few years. Multiple works have demonstrated that publicly

available interpretable machine learning algorithms can perform as well as black-box machine learning algorithms

[10, 11, 12]. Moreover, high-dimensional data sets on criminal recidivism have become increasingly available. However,

most machine learning papers treat recidivism prediction as a toy problem to test new machine learning algorithms.

They do not consider factors such as data quality or ease of computation of model predictions, which are paramount

for creating models that would be useful in practice. To our knowledge, there is only one prior work [13] that jointly

considers interpretability, fairness, and predictive performance; however, it does not do so in a comprehensive way and

focuses primarily on the design of a new algorithm.

Beyond the problem of model optimization, various methodological questions remain with existing risk assessment

systems. First, existing systems—such as COMPAS (Correctional Offender Management Proﬁling System for Alternative

Sanctions) and LSI-R (Level of Service Inventory Revised)—are often used across various states (or even countries)

with only minor normalization [14, 15]. However, populations in different states can signiﬁcantly differ because the

data generation process is not the same, so applying the same model across states may not lead to the best possible

performance. Second, empirical evidence indicates that the underlying probability distribution of recidivism has

changed over time in multiple locations [16]. For instance, a signiﬁcant shift in the age distribution—a key predictor in

many recidivism prediction models—has been observed in New York [17]. Thus, rather than using a static model with

uneven performance across districts, a better solution might be to algorithmically generate models, so that they can be

trained for speciﬁc locations and retrained if recidivism distributions shift over time.

Using modern tools of both interpretable and black-box machine learning, we revisit the recidivism prediction

problem. We deﬁne recidivism as a new charge that an individual is convicted for within a certain time frame (six months

1COMPAS stands for Correctional Offender Management Proﬁling for Alternative Sanctions.


4

WANG & HAN ET AL.

or two years). We ﬁnd that (1) black-box models do not perform signiﬁcantly better than interpretable models for any of

the twelve recidivism problems we consider. (2) Interpretable models generally perform better than existing actuarial

risk assessments. (3) Models do not generalize well across regions. (4) Only a small subset of the many proposed fairness

deﬁnitions can be applied to regression problems and they vary across different models. We also note that existing

techniques to enforce fairness generally require non-interpretable transformations, and therefore do not work well

with interpretable models.

This paper is structured as follows. Section 2 describes our contributions. Section 3 discusses the evolution of risk

assessment in America, the current debate over risk assessments, and brieﬂy reviews the machine learning literature on

risk assessment. Section 4 describes the study’s data sources. Section 5 discusses aspects of our methodology, including

the prediction problems, problem setup, and the existing risk assessments we compare against. Section 6 presents the

performance of baseline, non-interpretable machine learning methods, while Section 7 presents the performance of

interpretable machine learning methods. Section 8 examines the generalization of recidivism prediction models across

states. In Section 9, we describe the selection of fairness metrics and assess the fairness of the interpretable models. In

Section 10, we discuss broader impacts and future lines of inquiry.

========================================
====================CORPUS====================

========================================
====================CONCLUSION====================
10 | DISCUSSION AND FUTURE WORK

From this analysis, we conclude that the interpretable models can indeed perform approximately as well as the black-box

models in various recidivism prediction problems, and much can be gained in interpretability for small sacriﬁces in

accuracy. On the Broward data set, we found that RiskSLIM, EBM, and Additive Stumps perform as well or better than

the best black-box models. On the Kentucky data set, we observed that EBM and Additive Stumps have extremely close

performance to the best black-box models—Random Forest and XGBoost— with average AUC differences around 1%,

which is less than the uncertainty gap.

We observed that machine learning models for six-month outcomes generally outperform those for two-year

outcomes (conditioning on the recidivism type). This may be because treatment/rehabilitation programs have a greater

chance of taking effect over a two-year time span (as compared to the six-month time span), altering the probability of

recidivism. Future work could investigate this hypothesis, or pose other hypotheses to explain this observation.

We also observed that machine learning models do not generalize well across states, perhaps due to differences

in the feature distributions between regions—in particular, we observed that the age distributions for Kentucky and

Broward County are considerably different. One might easily imagine regional feature distributions shifting over time

as well, which is supported by several studies [17, 81, 82, 83]. Even though these studies focused on disparate crime

types, they consistently observed a drop in the rate of offending among younger people since the 1990s. Studies have

explicitly shown that the distributions of age versus arrest rate has changed over time as well. For instance, Kim et al.

[17] has reported that in the state of New York, the mean age of the total arrested population increased by two years


WANG & HAN ET AL.

29

between 1990 and 2010. They hypothesized that a decrease in arrests in younger people and an increase in arrests in

older people together contributed to the increase in mean age.

There are many reasons why data would change over time and over jurisdictions. Changing policies (e.g., the NYC

stop and frisk program) could potentially alter who would be arrested and for what types of crime. New cultural phe
nomena (e.g., in video games and media) could also inﬂuence people’s behavior at a large scale. The above observations

lead us to conclude that different recidivism prediction models could be constructed for different locations and should

be periodically updated. Machine learning models are well-suited for efﬁcient creation and updating of these kinds of

models. A possible future line of work is to separate the Kentucky data at the jurisdiction level, and perform a causal

analysis of the effects of different judicial and policing practices on the recidivism distribution.

Simple, transparent models have been used for criminal justice applications for almost a century [65, 84]. They

have the advantage that one can easily quantify the contributions of each feature to the predicted score. Judicial

actors without much statistics background can understand these scores, and use them to help solve societal issues.

Interpretable models are extremely valuable for current decision-making processes in criminal justice: they allow

error-checking, help ensure due process, and allow judges to incorporate information outside the database into their

decision-making process in a calibrated manner.

However, our work on interpretable risk prediction is only one step closer to what we view as the ultimate goal—

placing recidivism prediction into the framework of formal decision analysis. Decision-making in the context of decision

analysis involves the minimization of costs rather than risks. Towards this end, Lakkaraju and Rudin [85] considered

several costs related to pretrial release decisions; these include the societal cost of releasing an individual who might

commit a crime before their trial, the cost of assigning an ofﬁcer to an individual, and the cost to taxpayers of keeping an

individual incarcerated. The importance of risk predictions vary between decision-making problems (release, parole,

sentencing, etc.). In some cases, they play a minor role, yet in others, predictions may comprise the sole deciding factor.

Because of this, it would be useful to have a cost-beneﬁt analysis per decision that would help determine exactly when

and where risk scores should participate.

Hence, an important and necessary direction for the future work would be to incorporate the framework of

classical decision analysis into decision-making in the criminal justice system. Decision analysis tools would ideally

allow practitioners to strike a balance between relevant considerations (e.g., future risks to society, costs of treatment

programs to society, costs to families involved in the criminal justice system, costs to the individual, as well as more

traditional modelling objectives such as fairness, interpretability, transparency, and predictive performance). While

the full data measuring costs and risks to all stakeholders in the criminal justice process may never be available, it is

important to move in this direction, as this would bring us closer to more consistent and informed decision making.

A C K N O W L E D G E M E N T S

We acknowledge partial funding from Arnold Ventures, the Duke Computer Science Undergraduate Research Fellows

Program, the Lord Foundation of North Carolina and the Duke Department of Electrical and Computer Engineering.

This report represents the ﬁndings of the authors and does not represent the views of any of the funding agencies. We

thank the Broward County Sheriff’s ofﬁce and the Kentucky Department of Shared Services, Research and Statistics for

their assistance and provision of data. We would also like to thank Daniel Sturtevant from the Kentucky Department of

Shared Services, Research and Statistics for providing signiﬁcant insight into the Kentucky data set, and Berk Ustun for

his advice on training RiskSLIM. Finally, we thank Brandon Garrett from Duke, Stuart Buck and Kristin Bechtel from

Arnold Ventures, and Kathy Schiﬂett, Christy May, and Tara Blair from Kentucky Pretrial Services for their thoughtful

comments on the article.


30

C O D E

R E F E R E N C E S

Our code is here: https://github.com/BeanHam/interpretable-machine-learning

WANG & HAN ET AL.

[1] Berk R. An Impact Assessment of Machine Learning Risk Forecasts on Parole Board Decisions and Recidivism. Experi
mental Criminology 2017 April;13:193–216.

[2] Larson J, Mattu S, Kirchner L, Angwin J. How We Analyzed the COMPAS Recidivism Algorithm. ProPublica; 2016.

[3] Freeman K. Algorithmic Injustice: How the Wisconsin Supreme Court Failed to Protect Due Process Rights in State V.
Loomis. North Carolina Journal of Law & Technology 2016 December;18. http://ncjolt.org/wp-content/uploads/
2016/12/Freeman_Final.pdf.

[4] Rudin C, Wang C, Coker B. The age of secrecy and unfairness in recidivism prediction. arXiv:181100731 2019 Novem
ber;Accepted to Harvard Data Science Review.

[5] Flores AW, Lowenkamp CT, Bechtel K. False Positives, False Negatives, and False Analyses: A Rejoinder to “Machine Bias: There’s Software Used Across the Country to Predict Future Criminals". Federal probation 2016 September;80(2).

[6] Dieterich W, Mendoza C, Brennan T. COMPAS Risk Scales: Demonstrating Accuracy Equity and Predictive Parity: Per
formance of the COMPAS Risk Scales in Broward County; 2016.

[7] Barabas C, Dinakar K, Doyle C. The Problems With Risk Assessment Tools. The New York Times 2019 July;https:

//www.nytimes.com/2019/07/17/opinion/pretrial-ai.html.

[8] O’Neil C. Weapons of Math Destruction. Crown Books; 2016.

[9] Wexler R. When a Computer Program Keeps You in Jail: How Computers are Harming Criminal Justice. New York

Times 2017 June;p. 27. Section A.

[10] Zeng J, Ustun B, Rudin C. Interpretable classiﬁcation models for recidivism prediction. Journal of the Royal Statistical

Society: Series A (Statistics in Society) 2017;180(3):689–722.

[11] Angelino E, Larus-Stone N, Alabi D, Seltzer M, Rudin C. Certiﬁably optimal rule lists for categorical data. Journal of

Machine Learning Research 2018;19:1–79.

[12] Lou Y, Caruana R, Gehrke J, Hooker G. Accurate intelligible models with pairwise interactions.

In: 19th ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD); 2013. p. 623–631. DOI:
10.1145/2487575.2487579.

[13] Soares E, Angelov PP. Fair-by-design explainable models for prediction of recidivism. ArXiv 2019;abs/1910.02043.

[14] MHS Assessments. Level of Service/Case Management Inventory: An Offender Management System. MHS Public

Safety 2017;https://issuu.com/mhs-assessments/docs/ls-cmi.lsi-r.brochure_insequence.

[15] Northpointe. Practitioner’s Guide to COMPAS Core; 2013, http://www.northpointeinc.com/downloads/compas/

Practitioners-Guide-COMPAS-Core-_031915.pdf.

[16] Gelb A, Velazquez T, Trust PC, of America US. The Changing State of Recidivism: Fewer People Going Back to Prison.

The Pew Charitable Trusts 2018;.

[17] Kim J, Bushway S, Tsao H. Identifying Classes of Explanation for Crime Drop: Period and Cohort Effects for New York

State. Journal of Quantitative Criminology 2016;32:357–375.


WANG & HAN ET AL.

31

[18] Bureau of Justice Assistance; Bureau of Justice Assistance. History of Risk Assessment. Bureau of Justice Assistance

2020;https://psrac.bja.ojp.gov/basics/history.

[19] Kehl D, Guo P, Kessler S. Algorithms in the Criminal Justice System: Assessing the Use of Risk Assessments in Sentenc
ing. 2017 July;https://cyber.harvard.edu/publications/2017/07/Algorithms.

[20] Public Safety Assessment. Risk Factors and Formulas. Laura and John Arnold Foundation 2019 9;(https://www.

psapretrial.org/about/).

[21] Latessa E, Smith P, Lemke R, Makarios M, Lowenkamp C. Creation and Validation of the Ohio Risk Assessment System.

University of Cincinnati School of Criminal Justice Center for Criminal Justice Research; 2009.

[22] Electronic Privacy Information Center. Algorithms in the Criminal Justice System. Electronic Privacy Information

Center 2016 6;https://epic.org/algorithmic-transparency/crim-justice/.

[23] Hanson R, Thornton D. Notes on the development of Static-2002. Ottawa, Ontario: Department of the Solicitor Gen
eral of Canada 2003;.

[24] Tollenaar N, van der Heijden PGM. Which method predicts recidivism best?: a comparison of statistical, machine
learning and data mining predictive models. Journal of the Royal Statistical Society: Series A (Statistics in Society)
2013;176(2):565–584.

[25] Howard P, Francis B, Soothill K, Humphreys L. OGRS 3: The revised offender group reconviction scale. Ministry of

Justice; 2009.

[26] Dawes RM, Faust D, Meehl PE. Clinical versus actuarial judgment. Science 1989;243(4899):1668–1674.

[27] Grove WM, Meehl PE. Comparative efﬁciency of informal (subjective, impressionistic) and formal (mechanical, algorithmic) prediction procedures: The clinical–statistical controversy. Psychology, Public Policy, and Law 1996;2(2):293.

[28] Wolfgang ME. Delinquency in a birth cohort. University of Chicago Press; 1987.

[29] Sherman LW. The power few: experimental criminology and the reduction of harm. Journal of Experimental Criminol
ogy 2007;3(4):299–321.

[30] Milgram A, Milgram A, editor, Why smart statistics are the key to ﬁghting crime. Ted Talk; 2014.

[31] James N. Risk and Needs Assessment in the Federal Prison System. Congressional Research Service; 2018.

[32] Zweig J.

Extraordinary Conditions Of Release Under The Bail Reform Act. Harvard Journal On Legislation

2010;47:555–585.

[33] Desmarais S, Garrett B, Rudin C. Risk Assessment Tools Are Not A Failed ’Minority Report’.

Law360 2019
July;https://www.law360.com/access-to-justice/articles/1180373/risk-assessment-tools-are-not-a-failedminority-report-.

[34] The Leadership Conference on Civil and Human Rights. The Use of Pretrial "Risk Assessment" Instrument: A Shared
Statement of Civil Rights Concerns. 2018 August;http://civilrightsdocs.info/pdf/criminal-justice/PretrialRisk-Assessment-Full.pdf.

[35] Pretrial Justice Institute. Updated Position on Pretrial Risk Assessment Tools. Pretrial Justice Institute 2020;https:

//www.pretrial.org/wp-content/uploads/Risk-Statement-PJI-2020.pdf.

[36] Angwin J, Larson J, Mattu S, Kirchner L. Machine Bias. ProPublica; 2016.

[37] Stevenson M. Assessing Risk Assessment in Action. Minnesota Law Review 2018;http://www.minnesotalawreview.

org/wp-content/uploads/2019/01/13Stevenson_MLR.pdf.


32

WANG & HAN ET AL.

[38] Skeem J, Lin Z, Jung J, Goel S. The limits of human predictions of recidivism. Science Advances 2020;6.

[39] Garrett B, Stevenson M. Open Risk Assessments. Behavioral Science & Law 2020;https://sites.law.duke.edu/
justsciencelab/2019/09/15/comment-on-pattern-by-brandon-l-garrett-megan-t-stevenson/, forthcoming.

[40] Roberts J, von Hirsch A. Previous Convictions at Sentening - Theoretical and Applied Perspective. Bloomsbury Publish
ing; 2010.

[41] Frase RS, Roberts J, Hester R, Mitchell KL, of Criminal Law RI, Justice C, editors, Robina Institute of Criminal Law and
Criminal Justice, Criminal History Enhancements Sourcebook. Robina Institute of Criminal Law and Criminal Justice;
2015. https://robinainstitute.umn.edu/publications/criminal-history-enhancements-sourcebook.

[42] Starr SB. The Risk Assessment Era: An Overdue Debate. Federal Sentencing Reporter 2015 April;27:205–206.

[43] American Law Institute, Model Penal Code; 2017. https://www.ali.org/projects/show/sentencing/.

[44] Neuilly MA, Zgoba KM, Tita GE, Lee SS. Predicting recidivism in homicide offenders using classiﬁcation tree analysis.

Homicide studies 2011;15(2):154–176.

[45] Friedman JH. Stochastic gradient boosting. Computational Statistics &amp; Data Analysis 2002;38(4):367–378.

[46] Palocsay SW, PingWang, Brookshire RG. Predicting criminal recidivism using neural networks. Socio-Economic Plan
ning Sciences 2000 December;34:271–284.

[47] Berk RA, He Y, Sorenson SB. Developing a practical forecasting screener for domestic violence incidents. Evaluation

Review 2005;29(4):358–383.

[48] Goel S, Rao JM, Shroff R. Precinct or Prejudice? Understanding Racial Disparities in New York City’s Stop-And-Frisk

Policy. Institute of Mathematical Statistics 2016;10(1):365–394.

[49] Rudin C. Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models

Instead. Nature Machine Intelligence 2019 May;1:206–215.

[50] Hardt M, Price E, Srebro N. Equality of opportunity in supervised learning. In: Advances in neural information process
ing systems; 2016. p. 3315–3323.

arXiv:180302453 2018;.

arXiv:160905807 2016 November;.

January;81:1–11.

2018. p. 1–7.

[51] Agarwal A, Beygelzimer A, Dudík M, Langford J, Wallach H. A reductions approach to fair classiﬁcation. arXiv preprint

[52] Kleinberg J, Mullainathan S, Raghavan M.

Inherent Trade-Offs in the Fair Determination of Risk Scores.

[53] Pleiss G, Raghavan M, Wu F, Kleinberg J, Weinberger K. On fairness and calibration. In: Advances in Neural Information

Processing Systems; 2017. p. 5680–5689.

[54] Binns R. Fairness in Machine Learning: Lessons from Political Philosophy. Journal of Machine Learning Research 2018

[55] Verma S, Rubin J. Fairness Deﬁnitions Explained. In: ACM/IEEE International Workshop on Software Fairness ACM;

[56] Berk R, Heidari H, Jabbari S, Kearns M, Roth A. Fairness in Criminal Justice Risk Assessments: The State of the Art.

Sociological Methods & Research 2017 03;.

[57] Berk R. Accuracy and Fairness for Juvenile Justice Risk Assessments.

Journal of Empirical Legal Studies 2019

March;16(1):174–194.


WANG & HAN ET AL.

33

[58] Corbett-Davies S, Pierson E, Feller A, Goel S, Huq A. Algorithmic decision making and the cost of fairness. In: In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; 2017. p. 797–806.

[59] Barocas S, Selbst AD. Big Data’s Disparate Impact. California Law Review 2016;104:671–732.

[60] Corbett-Davies S, Goel S. The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning.

arXiv:180800023v2 2018 August;.

[61] Vapnik V, Chervonenkis A. A note on one class of perceptrons. Automation and Remote Control 1964;25.

[62] Breiman L, Friedman J, Stone CJ, Olshen RA. Classiﬁcation and regression trees. CRC press; 1984.

[63] Freund Y, Schapire RE. A decision-theoretic generalization of on-line learning and an application to boosting. Journal

of computer and system sciences 1997;55(1):119–139.

[64] Chen T, Guestrin C. Xgboost: A scalable tree boosting system. In: Proceedings of the 22nd acm sigkdd international

conference on knowledge discovery and data mining; 2016. p. 785–794.

[65] Burgess EW, on Indeterminate-Sentence Law IC, Parole Springﬁeld I, editors, Factors determining success or failure on

parole. Illinois Committee on Indeterminate-Sentence Law and Parole Springﬁeld, IL; 1928.

[66] Ustun B, Rudin C. Optimized Risk Scores.

In: Proceedings of the 23rd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining KDD ’17, New York, NY, USA: ACM; 2017. p. 1125–1134. http://doi.acm.
org/10.1145/3097983.3098161.

[67] Stevenson MT, Slobogin C. Algorithmic Risk Assessments and the Double-Edged Sword of Youth. Washington University Law Review 2018;96(Vanderbilt Law Research Paper No. 18-36). http://dx.doi.org/10.2139/ssrn.3225350.

[68] Bindler A, Hjalmarsson R. How punishment severity affects jury verdicts: Evidence from two natural experiments.

American Economic Journal: Economic Policy 2018;10.

[69] Bushway SD, Piehl AM. The inextricable link between age and criminal history in sentencing. Crime & Delinquency

2007;53(1):156–183.

table/KY,US/PST045219.

[70] United States Census Bureau. QuickFacts: Kentucy; United States. 2019;https://www.census.gov/quickfacts/fact/

[71] United States Census Bureau. Hispanic or Latino Origin By Race 2011-2015 American Community Survey 5-Year Estimates. 2015;https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_15_
5YR_B03002&prodType=table.

[72] Mishra A. Climate and Crime. Global Journal of Science Frontier Research: H, Environment & Earth Science 2014;14.

[73] Ranson M. Crime, weather, and climate change. Journal of Environmental Economics and Management 2014;67.

[74] Defronzo J. Climate and Crime: Tests of an FBI Assumption. Environment and Behavior 1984;16.

[75] Kleiman M, Ostrom BJ, Cheesman FL. Using risk assessment to inform sentencing decisions for nonviolent offenders

in Virginia. Crime & Delinquency 2007;53(1):106–132.

[76] Dwork C, Hardt M, Pitassi T, Reingold O, Zemel R. Fairness Through Awareness. In: Proceedings of the 3rd Innovations
in Theoretical Computer Science Conference ITCS ’12, New York, NY, USA: ACM; 2012. p. 214–226. http://doi.acm.
org/10.1145/2090236.2090255.

[77] Chouldechova A. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data

2017;5(2):153–163.


34

WANG & HAN ET AL.

[78] Zemel R, Wu Y, Swersky K, Pitassi T, Dwork C. Learning fair representations. In: International Conference on Machine

Learning; 2013. p. 325–333.

preprint arXiv:170602409 2017;.

arXiv:190512843 2019;.

37.

[79] Berk R, Heidari H, Jabbari S, Joseph M, Kearns M, Morgenstern J, et al. A convex framework for fair regression. arXiv

[80] Agarwal A, Dudík M, Wu ZS. Fair Regression: Quantitative Deﬁnitions and Reduction-based Algorithms. arXiv preprint

[81] Cook P, Laub J. After the Epidemic Recent Trends in Youth Violence in the United States. Crime and Justice 2002;29:1–

[82] Alfred B. The Crime Drop in America: An Explanation of Some Recent Crime Trends. Journal of Scandinavian Studies

in Criminology and Crime Prevention 2006;7:17–35.

[83] Matthews B, Minton J. Rethinking one of the criminology’s ’brute facts’: The age-crime curve and the crime drop in

Scotland. European Journal of Criminology 2017;15(3):296–320.

[84] Hart H. Predicting Parole Success. Journal of Criminal Law and Criminology 1924;14.

[85] Lakkaraju H, Rudin C. Learning Cost-Effective and Interpretable Treatment Regimes. In: Singh A, Zhu J, editors. Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics, vol. 54 of Proceedings of Machine Learning Research Fort Lauderdale, FL, USA: PMLR; 2017. p. 166–175. http://proceedings.mlr.press/v54/
lakkaraju17a.html.

[86] Brennan T, Dieterich W, Ehret B. Evaluating the Predictive Validity of the COMPAS Risk and Needs Assessment System.

Criminal Justice and Behavior 2009 January;36(1):21–40.

[87] Northpointe Inc . Measurement & Treatment Implications of COMPAS Core Scales; 2009.

[88] Carollo J, Hedlund J, Hines M. Expanded Validation of a Decision Aid for Pretrial Conditional Release; 2007.

[89] The Colorado Pretrial Assessment Tool (CPAT): Administration, Scoring, and Reporting Manual. Colorado Association of Pretrial Services; 2015, https://university.pretrial.org/HigherLogic/System/DownloadDocumentFile.
ashx?DocumentFileKey=47e978bb-3945-9591-7a4f-77755959c5f5.

[90] Turner S, Hess J, Jannetta J. Development of the California Static Risk Assessment Instrument (CSRA). CEBC Working

Papers 2009;.

2011;75(2).

[91] Cadigan TP, Lowenkamp CT. Implementing Risk Assessment in the Federal Pretrial Services System. Federal Probation

[92] Hoffman PB, Adelberg S. The Salient Factor Score: A Nontechnical Overview. Fed Probation 1980;44:44.

[93] Nafekh M, Motiuk LL. The Statistical Information on Recidivism, Revised 1 (SIR-R1) Scale: A Psychometric Examination.

Correctional Service of Canada. Research Branch; 2002.

[94] Orbis, Orbis, editor, Service Planning Instrument: An Innovative Assessment and Case Planning Tool. Orbis; 2014.

https://orbispartners.com/wp-content/uploads/2014/07/SPIn-Brochure.pdf.

[95] Lazarsfeld PF. An Evaluation of the Pretrial Services Agency of the Vera Institute of Justice. New York: Vera Institute

1974;.

[96] Harris GT, Rice ME. Violence Risk Appraisal Guide (VRAG). In: Cutler BL, editor. Encyclopedia of Psychology and Law
SAGE Publications, Inc.; 2008. p. 848. https://sk.sagepub.com/reference/download/psychologylaw/n345.pdf.


WANG & HAN ET AL.

35

[97] Virginia Pretrial Risk Assessment Instrument - (VPRAI). Virginia Department of Criminal Justice Services; 2018,

https://www.dcjs.virginia.gov/sites/dcjs.virginia.gov/files/publications/corrections/virginia-pretrialrisk-assessment-instrument-vprai_0.pdf.

[98] Fan RE, Chang KW, Hsieh CJ, Wang XR, Lin CJ. LIBLINEAR: A Library for Large Linear Classiﬁcation. J Mach Learn Res

2008 Jun;9:1871–1874.

[99] Smith B. Auditing Deep Neural Networks to Understand Recidivism Predictions. PhD thesis, Haverford College; 2016.

[100] Ustun B, Rudin C. Supersparse linear integer models for optimized medical scoring systems. Machine Learning 2015;p.

1–43. http://dx.doi.org/10.1007/s10994-015-5528-6.

11 | APPENDIX

11.1 | Broward Data Processing

The Broward County data set consists of publicly available criminal history, court data and COMPAS scores from

Broward County, Florida. The criminal history and demographic information were computed from raw data released by

ProPublica [36]. The probational history was computed from public criminal records released by the Broward Clerk’s

Ofﬁce.

The screening date is the date on which the COMPAS score was calculated. The features and labels were computed

for an individual with respect to a particular screening date. For individuals who have multiple screening dates, we

compute the features for each screening date, such that the set of events for calculating features for earlier screening

dates is included in the set of events for later screening dates. On occasion, an individual will have multiple COMPAS

scores calculated on the same date. There appears to be no information distinguishing these scores other than their

identiﬁcation number, so we take the scores with the larger identiﬁcation number.

The recidivism labels were computed for the timescales of six months and two years. Some individuals were

sentenced to prison as a result of their offense(s). We used only observations for which we have six months/two years

of data subsequent to the individual’s release date.

Below, we describe details of the feature and label generation process.

•

•

•

• Degree “(0)” charges seem to be very minor offenses, so we exclude these charges. We infer whether a charge is a

felony, misdemeanor, or trafﬁc charge based off the charge degree.

Some of our features rely on classifying the type of each offense (e.g., whether or not it is a violent offense). We

infer this from the statute number, most of which correspond to statute numbers from the Florida state crime code.

The raw Propublica data includes arrest data as well as charge data. Because the arrest data does not include the

statute, which is necessary for us to determine offense type, we use the charge data to compute features that

require the offense type. We use both charge and arrest data to predict recidivism.

For each person on each COMPAS screening date, we identify the offense—which we call the current offense—that

most likely triggered the COMPAS screening. The current offense date is the date of the most recent charge that

occurred on or before the COMPAS screening date. Any charge that occurred on the current offense date is part

of the current offense. In some cases, there is no prior charge that occurred near the COMPAS screening date,

suggesting charges may be missing from the data set. For this reason we consider charges that occurred within

30 days of the screening date for computing the current offense. If there are no charges in this range, we say the

current offense is missing. We exclude observations with missing current offenses. We used some of the COMPAS


36

•

•

•

•

•

WANG & HAN ET AL.

subscale items as features for our machine learning models. All such components of the COMPAS subscales that

we compute are based on data that occurred prior to (not including) the current offense date.

The events/documents data includes a number of events (e.g., “File Afﬁdavit Of Defense” or “File Order Dismissing

Appeal”) related to each case, and thus to each person. To determine how many prior offenses occurred while on

probation, or if the current offense occurred while on probation, we deﬁne a list of event descriptions indicating

that an individual was taken on or off probation. Unfortunately, there appear to be missing events, as individuals

often have consecutive “On” or consecutive “Off” events (e.g., two “On” events in a row, without an “Off” in between).
In these cases, or if the ﬁrst event is an “Off” event or the last event is an “On” event, we deﬁne two thresholds, t on
and t of f . If an offense occurred within t on days after an “On” event or t of f days before an “Off” event, we count the
offense as occurring while on probation. We set t on to 365 and t of f to 30. On the other hand, the “number of times
on probation” feature is just the count of “On” events and the “number of times the probation was revoked” feature

is just the count of “File order of Revocation of Probation” event descriptions (i.e., we do not infer missing probation

events for these two features).

• Current age is deﬁned as the age in years, rounded down to the nearest integer, on the COMPAS screening date.
• A juvenile charge is deﬁned as an offense that occurred prior to the defendant’s 18th birthday.

Labels and features were computed using charge data.

The ﬁnal data set contains 1,954 records and 41 features.

11.2 | Kentucky Data Processing

The Kentucky pretrial and criminal court data was provided by the Department of Shared Services, Research and

Statistics in Kentucky. The Pretrial Services Information Management System (PRIM) data contains records regarding

defendants, interviews, PRIM cases, bonds etc., that are connected with the pretrial services’ interviews conducted

between July 1, 2009 and June 30, 2018. The cases were restricted to have misdemeanor, felony, and other level charges.

The data from another system, CourtNet, provided further information about cases, charges, sentences, dispositions

etc. for CourtNet cases matched in the PRIM system. The Kentucky data can be accessed through a special data request

to the Kentucky Department of Shared Services, Research and Statistics.

CourtNet and PRIM data were processed separately and then combined together. We describe the details below:

For the CourtNet data, we ﬁltered out cases with ﬁling date prior to Jan. 1st, 1996, which were claimed to be less

reliable records by the Kentucky Department of Shared Services, Research and Statistics (which provided the

data). To investigate what types of crimes the individuals were involved in for each charge, such as drug, property,

trafﬁc-related crime, we used the Kentucky Uniform Crime Reporting Code (UOR Code), as well as detecting

keywords in the UOR description.

From the PRIM system data, we extracted the probation, failure to appear, case pending, and violent charge

information at the PRIM case level, as well as the Arnold PSA risk scores computed at the time of each pretrial

services’ interview. Since Kentucky did not use Arnold PSA until July 1st, 2013, we ﬁltered out records before the

this date. We omitted records without risk scores since we want to compare the performance of the PSA with other

models. Only 33 records are missing PSA scores; therefore we do not worry about missing records impacting the

results. Additionally, some cases in the PRIM system have “indictment” for the arrest type, along with an “original”

arrest case ID, indicating that those cases were not new arrests. We matched these cases with the records that

correspond to the original arrests to avoid overcounting the number of prior arrests. Then we inner-joined the data

from the two systems using person-id and prim-case-id.


WANG & HAN ET AL.

37

•

•

•

For each individual, we used the date that is two years before the latest charge date in the Kentucky data, as a

cutoff date. The data before the cutoff are used as criminal history information to compute features. The data

after the cutoff are used to compute labels and check recidivism. In the data before the cutoff, the latest charge is

treated as the current charge (i.e., the charge that would trigger a risk-assessment) for each individual. We compute

features and construct labels using only convicted charges. However, the current charge can be either convicted or

non-convicted. This ensures that our analysis includes all individuals that would receive a risk assessment, even

if they were later found innocent of the current charge that triggered the risk assessment. It also ensures that

criminal history features use only convicted charges, so that our risk assessments are not inﬂuenced by charges for

crimes that the person may not have committed.

In order to compute the labels, we must ensure that there are at least two years of data following an individual’s

current charge date. For individuals who are sentenced to prison due to their current charge, we consider their

release date instead of the current charge date. We omitted individuals for whom there were less than two years of

data between their current charge date or release date, and the last date recorded in the data set.

To get the age at current charge information, we ﬁrst calculated the date of birth (DOB) for each individual, using

CourtNet case ﬁling date and age at the CourtNet case ﬁling date. Then we calculated “age at current charge” using

the DOB and charge date (the charge date sometimes differs from the case ﬁling date). Notice that there are many

errors in age records in the data. For instance, some people have age recorded over 150, which is certainly wrong

but there is no way to correct it. To ensure the quality of our data, we limited the ﬁnal current age feature to be

inclusively between 18 and 70. This is also consistent with the range from Broward analysis. If the person was

not sentenced to prison, we deﬁne current age as the age at current charge date. If the person was sentenced to

prison, we compute current age by adding the sentence time to the age at the current charge date. Note that this

differs from the way risk scores are computed in practice—usually risk scores are computed prior to the sentencing

decision. This helps to handle distributional shift between the individuals with no prison sentence (for whom a

2-year evaluation can be handled directly) and the full population (some of whom may have been sentenced to

prison and cannot commit a crime during their sentence).

• We computed features using the data before the current charge date. The CourtNet data is organized by CourtNet
cases, and each CourtNet case has charge level data. The PRIM data is organized by PRIM cases. Each CourtNet
case can connect to multiple PRIM cases.14 Therefore, to compute the criminal history information, we ﬁrst grouped

on PRIM case level to summarize the charge information. Next, we grouped on CourtNet case level to summarize

PRIM case level information. Last, we grouped on the individual level to summarize the criminal histories.

• On computing the ADE feature: The ADE feature means number of times the individual was assigned to alcohol
and drug education classes. Note that by Kentucky state law, any individual convicted for a DUI is assigned to ADE

classes. This does not indicate whether the individual successfully completed ADE classes.

• We compute labels using the two years of data after the current charge date/release date. We constructed the
general recidivism labels by checking whether a “convicted charge” occurred within two years or six months
from the current charge (or release date). Then, using the charge types of the convicted charge, other recidivism

prediction labels were generated, such as drug or property-related recidivism. The ﬁnal data set contains 250,778

Note: there are degrees of experimenter freedom in some of these data processing choices; exploring all the possible choices

records and 40 features.

here is left for future studies.

The Arnold PSA features that were included in the Kentucky data set (e.g., prior convictions, prior felony convictions

14This occurs because a new PRIM case is logged when an update occurs in the defendant’s CourtNet case (for example, if the defendant fails to appear in court).


38

WANG & HAN ET AL.

etc.) were computed by pretrial ofﬁcers who had access to criminal history data from both inside and outside of Kentucky.

However, the Kentucky data set we received contained criminal history information from within Kentucky only. Thus,

the Arnold PSA features for Kentucky (which are included in our models as well) use both in-state and out-of-state

information, but the remaining features (which we compute directly from the Kentucky criminal history data) are limited

to in-state criminal history.

Additionally, we were informed by Kentucky Pretrial Services team that the data set ’s sentencing information

may not be reliable due to unmeasured confounding, including shock probation and early releases that would allow

a prisoner to be released much earlier than the end date of the sentence. Because the sentence could be anywhere

from zero days to the full length, we conducted a sensitivity analysis by excluding the sentence information in the data

processing, which is equivalent to the assumption that no prison sentence was served. For that analysis, the current age

of each individual was calculated to be the age at the current charge, and the prediction labels were generated from

new charges within six months (or two years) from the current charge. The sensitivity analysis yielded predictive results

that were almost exactly the same as the results in the main text, when the sentence information was used to determine

age and prediction interval.

11.3 | Why We Compare Only Against COMPAS and the PSA

The variables included in risk assessments are often categorized into static and dynamic factors. Static factors are deﬁned

as factors that cannot be reduced over time (e.g. criminal history, gender, and age-at-ﬁrst-arrest). Dynamic factors

are deﬁned as variables that can change over time to decrease the risk of recidivism; they allow insight into whether a

high-risk individual can lower their risk through rehabilitation, and sometimes improve prediction accuracy. Examples

of dynamic factors include current age, treatment for substance abuse, and mental health status [19]. Dynamic factors

are often included in risk-and-needs-assessments (RNAs), which in addition to identifying risk of recidivism, recommend

interventions to practitioners (e.g., treatment programs, social services, diversion of individuals from jail).

With the exception of current age, our features all fall under the “static” classiﬁcation. This renders us unable to

compare against the risk assessment tools that use dynamic factors, whose formulas are public. The risk assessments

that we examined are listed in Table 4. Since we have only criminal history and age variables, the only model we could

compute from our data was the Arnold PSA.

However, as we demonstrated in the main body of the paper, the fact that we do not possess dynamic factors is

not necessarily harmful to the predictive performance of our models. The goal behind including dynamic factors in

models is to improve prediction accuracy as well as be able to recommend interventions that reduce the probability of

recidivism. While an admirable goal, the inclusion of dynamic factors does not come at zero cost and may not actually

produce performance gains for recidivism prediction. In Sections 6 and 7, we show that standard machine learning

techniques (using only the static factors) and interpretable machine learning models (using only static factors) are

able to outperform a criminal justice model that utilizes both static and dynamic factors (COMPAS). Furthermore, the

inclusion of additional, unnecessary factors increases the risk of data entry errors, or exposes models to additional

feature bias [60]. As Rudin et al. [4] reveals, data entry errors appear to be common in COMPAS score calculations and

could lead to scores that are either too high or too low.

Although the COMPAS suite is a proprietary (and thus black-box) risk-and-needs assessment, we were still able

to compare against its risk assessments thanks to the Florida’s strong open-records laws. Created by Northpointe (a

subsidiary company of Equivant), COMPAS is a recidivism prediction suite which is used in criminal justice systems

throughout the United States. It is comprised of three scores: Risk of General Recidivism, Risk of Violent Recidivism,

and Risk of Failure to Appear. In this work, we examine the two risk scores relating to violent recidivism and general


WANG & HAN ET AL.

39

recidivism. Each risk score is an integer from one to ten [86].

As COMPAS scores are proprietary instruments, the precise forms of its models are not publicly available. How
ever, it is known that the COMPAS scores are computed from a subset of 137 input variables that include voca
tional/educational status, substance abuse, and probational history, in addition to the standard criminal history vari
ables [86]. As such, we cannot directly compute these risk scores, and instead utilize the COMPAS scores released by

ProPublica in the Broward County recidivism data set. We do not compare against COMPAS on the Kentucky data set,

as our data set does not include COMPAS scores.

The PSA was created by Arnold Ventures, and is a publicly available risk assessment tool. Similar to the COMPAS

suite, it is comprised of three risk scores: Failure to Appear, New Criminal Activity, and New Violent Criminal Activity.

Again, we compare against latter two scores. Both are additive integer models which take nine factors as input, relating

to age, current charge, and criminal history. The New Criminal Activity model outputs a score from 1 to 6, while the New

Violent Criminal Activity model outputs a binary score [20]. The PSA is an interpretable model.

TA B L E 4 Variable comparison for currently-utilized actuarial risk assessments. We only have criminal history and
age variables, but most models include many other variables. Abbreviations are: Correctional Offender Management
Proﬁling for Alternative Sanctions (COMPAS); Connecticut Risk Assessment for Pretrial Decision Making
(Connecticut); Colorado Pretrial Risk Assessment Tool (CPAT); California Static Risk Assessment (CSRA); Ohio Risk
Assessment System (ORAS); Level-of-Service Case Management Inventory (LSI-CMR); Public Service Assessment(PSA);
(Federal) Pretrial Risk Assessment (PTRA); Statistical Information on Recidivism Score (SIRS); Service Planning
Instruments (SPIn); Vera Point Scale (VERA); Violence Risk Appraisal Guide (VRAG); Virginia Pretrial Risk Assessment
Instrument (VPRAI).

Models

Criminal History Age

Finance Residential Info

Edu/Emp

Peer/Family Mental Health Alc/Subs Abuse Other

COMPAS [87]

Connecticut [88]

CPAT [89]

CSRA [90]

ORAS [21]

LSI-CMI [14]

PSA [20]

PTRA [91]

SIRS [93]

SPIn [94]

VERA [95]

VRAG [96]

VPRAI [97]

Salient Factor [92]

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X


40

WANG & HAN ET AL.

11.4 | Hyperparameters

| Baseline Models, CART, EBM

We applied nested cross validation to tune the hyperparameters. Please refer to Table 5 for parameter details.

TA B L E 5 Hyperparameters for (cid:96)1 and (cid:96)2 Penalized Logistic Regression, Linear SVM, CART, Random Forest,
XGBoost, and EBM. RiskSLIM and Additive Stumps are discussed separately.

Models

Kentucky

Broward

(cid:96)2 Logistic Regression class_weight: balanced

class_weight: balanced

solver: liblinear[98]

solver: liblinear

penalty: (cid:96)2
C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]

penalty: (cid:96)2
C ∈ 100 values in [1e-5, 1e-2]

(cid:96)1 Logistic Regression class_weight: balanced

solver: liblinear

class_weight: balanced

solver: liblinear

penalty: (cid:96)1
C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]

penalty: (cid:96)1
C ∈ 100 values in [1e-5, 1e-2]

LinearSVM

C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]

C ∈ 100 values in [1e-5, 1e-2]

CART

max_depth ∈ [5,6,7,8,9,10]

Random Forest

n_estimator ∈ [100,150,200]
max_depth ∈ [7,8,9]

max_depth ∈ [1,2,3,4,5]
min_impurity_decrease ∈ [1e-3, 2e-3, . . . 5e-3]

n_estimator ∈ [50,100,200,400,600]
max_depth ∈ [1,2,3]
min_impurity_decrease ∈ [1e-3, 2e-3, . . . , 1e-2]

XGBoost

learning_rate ∈ [0.1]
n_estimator ∈ [100,150]
max_depth ∈ [4,5,6]

EBM 15

n_estimator ∈ [60]
max_tree_splits ∈ [2]
learning_rate ∈ [0.1]

learning_rate ∈ [0.05]
n_estimator ∈ [50,100,200,400,600]
max_depth ∈ [1,2,3]
gamma ∈ [6,8,10,12]
min_child_weight ∈ [6,8,10,12]
subsample ∈ [0.5]

n_estimator ∈ [40,60,80,100]
max_tree_splits ∈ [1,2,3]
learning_rate ∈ [0.01]
holdout_split ∈ [0.7, 0.9]

| Additive Stumps

Stumps were created for each feature as detailed in Section 7.1. An additive model was created from the stumps

using (cid:96)1-penalized logistic regression, and no more than 15 original features were involved in the additive models. But
multiple stumps corresponding to each feature could be used in the models. We chose to limit the size of the model to

15 original features because then at most 15 plots would be generated to visualize the full model, which is a reasonable

number of visualizations for users to digest.

We started with the smallest regularization parameter on (cid:96)1 penalty that provides at most 15 original features from
the model. This will be our lower bound for nested cross validation. From there, we perform nested cross validation over

a grid of regularization parameters, all of which are greater than or equal to the minimum value of the regularization

parameter found above. Please refer to Table 6 for more details.

15The training procedure is slow for EBM, due to the size of Kentucky data, the nested cross validation we applied, and the cross-validation within the algorithm

to choose number of pairwise interactions. Therefore, we tested only one set of parameters, which gave reliable results.


WANG & HAN ET AL.

41

TA B L E 6 Hyperparameters for Additive Stumps

Models

Two Year

Six Month

Two Year

Six Month

Kentucky

Broward

General

C ∈ [1e-3, 2e-3]

C ∈ [1e-3, 1.5e-3]

C ∈ [1e-2, 2e-2. . . 1e-1]

C ∈ [1e-2, 2e-2. . . 1e-1]

Violent

C ∈ [6e-4, 8e-4, 1e-3]

C ∈ [5e-4, 7e-4]

C ∈ [1e-2, 2e-2 . . . 7e-2]

C ∈ [1e-2, 2e-2 . . . 7e-2]

Drug

C ∈ [1e-3, 2e-3, 2.5e-3]

C ∈ [1e-3, 2e-3]

C ∈ [1e-2, 2e-2 . . . 9e-2]

C ∈ [1e-2, 2e-2 . . . 6e-2]

Property

C ∈ [1e-3, 1.5e-3]

C ∈ [1e-3, 1.5e-3]

C ∈ [1e-2, 2e-2 . . . 8e-2]

C ∈ [1e-2, 2e-2 . . . 6e-2]

Felony

C ∈ [1e-3, 1.5e-3]

Misdemeanor C ∈ [1e-3, 1.5e-3]

C ∈ [5e-4, 8e-4]

C ∈ [5e-4, 1e-3]

C ∈ [1e-2, 2e-2 . . . 8e-2]

C ∈ [1e-2, 2e-2 . . . 8e-2]

C ∈ [1e-2, 2e-2 . . . 7e-2]

C ∈ [1e-2, 2e-2 . . . 7e-2]

All the models use "balanced" for the class_weight, "liblinear" for the solver, and (cid:96)1 for the penalty.

| RiskSLIM

RiskSLIM is challenging to train, because it uses the CPLEX optimization software, which can be difﬁcult to install and

requires a license. Moreover, since RiskSLIM solves a very difﬁcult mixed-integer nonlinear optimization problem, it

can be slow to prove optimality, which makes it difﬁcult to perform nested cross validation as nested cross validation

requires many solutions of the optimization problem. A previous study [99] also noted similar problems with algorithms

that use CPLEX (this study trained on SLIM [100], which is similar to the training process of RiskSLIM in that they both

require CPLEX). Here we provide details of how we trained RiskSLIM to help others use the algorithm more efﬁciently.

• We ran (cid:96)1-penalized logistic regression on the stumps training data with a relatively large regularization parameter
to obtain a small subset of features (that is, we used (cid:96)1-penalized logistic regression for feature selection). Then we
trained RiskSLIM using nested cross validation with this small subset of features. The maximum run-time, maximum

offset, and penalty value were set to 1,000 seconds, 100, and 1e-6 respectively. The coefﬁcient range was set to [-5,

5], which would give us small coefﬁcients that are easy to add/subtract.

•

If the model converged to optimality (optimality gap less than 5%) within 1,000 seconds, we then ran (cid:96)1-penalized
logistic regression again with a smaller regularization parameter to obtain a slightly larger subset of features to work

with. We then trained RiskSLIM with nested cross validation again on this larger subset of features. If RiskSLIM

also generated an optimality gap less than 5% within 1,000 seconds and had better validation performance, we

• Once either RiskSLIM could not converge to a 5% optimality gap within 1,000 seconds, or the validation performance did not improve by adding more stumps, we stopped there, using the previously obtained RiskSLIM model as

repeated this procedure.

the ﬁnal model.

•

This procedure generally stopped with between 12 and 20 stumps from (cid:96)1-penalized logistic regression. Beyond
this number of stumps, we did not observe improvements in performance in validation.


42

11.5 | Tables

WANG & HAN ET AL.

TA B L E 7 Broward baseline models. Results are the average value of test AUCs from ﬁve-fold nested cross
validation, with standard deviation listed in parentheses.

Labels

Logistic ((cid:96)2)

Logistic((cid:96)1)

Linear SVM

RF

XGBoost

Performance Range

Baseline Models

Two Year

0.670 (0.021)

0.650 (0.021)

0.670 (0.020)

0.658 (0.027)

0.655 (0.022)

0.675 (0.037)

0.663 (0.039)

0.659 (0.032)

0.671 (0.036)

0.676 (0.048)

0.711 (0.048)

0.733 (0.035)

0.695 (0.037)

0.703 (0.040)

0.722 (0.039)

0.717 (0.052)

0.730 (0.057)

0.683 (0.048)

0.712 (0.027)

0.733 (0.034)

0.646 (0.041)

0.648 (0.050)

0.621 (0.036)

0.647 (0.046)

0.644 (0.037)

Misdemeanor

0.630 (0.019)

0.597 (0.013)

0.628 (0.018)

0.629 (0.027)

0.627 (0.024)

Six Month

0.625 (0.022)

0.608 (0.022)

0.618 (0.028)

0.615 (0.026)

0.623 (0.014)

0.685 (0.024)

0.651 (0.038)

0.619 (0.036)

0.668 (0.045)

0.685 (0.033)

0.673 (0.084)

0.696 (0.022)

0.640 (0.081)

0.675 (0.055)

0.698 (0.038)

0.727 (0.047)

0.725 (0.053)

0.659 (0.069)

0.687 (0.047)

0.725 (0.048)

0.611 (0.050)

0.613 (0.054)

0.580 (0.086)

0.591 (0.061)

0.585 (0.066)

Misdemeanor

0.612 (0.038)

0.586 (0.040)

0.586 (0.016)

0.593 (0.039)

0.608 (0.031)

TA B L E 8 Kentucky baseline models. Results are the average value of test AUCs from ﬁve-fold nested cross
validation, with standard deviation listed in parentheses.

Labels

Logistic ((cid:96)2)

Logistic((cid:96)1)

Linear SVM

RF

XGBoost

Performance Range

Baseline Models

Two Year

0.745 (0.004)

0.745 (0.004)

0.746 (0.004)

0.753 (0.003)

0.759 (0.003)

0.768 (0.002)

0.769 (0.003)

0.769 (0.003)

0.777 (0.005)

0.784 (0.004)

0.730 (0.003)

0.730 (0.003)

0.733 (0.003)

0.743 (0.002)

0.749 (0.002)

0.785 (0.005)

0.785 (0.005)

0.787 (0.005)

0.801 (0.004)

0.806 (0.004)

0.765 (0.001)

0.765 (0.001)

0.768 (0.002)

0.779 (0.002)

0.784 (0.001)

Misdemeanor

0.729 (0.005)

0.729 (0.005)

0.730 (0.006)

0.738 (0.005)

0.744 (0.005)

Six Month

0.761 (0.004)

0.761 (0.004)

0.764 (0.005)

0.779 (0.003)

0.785 (0.004)

0.833 (0.007)

0.834 (0.006)

0.833 (0.007)

0.843 (0.006)

0.847 (0.005)

0.782 (0.003)

0.782 (0.003)

0.785 (0.003)

0.803 (0.003)

0.811 (0.002)

0.834 (0.012)

0.834 (0.013)

0.831 (0.014)

0.857 (0.011)

0.860 (0.011)

0.799 (0.002)

0.800 (0.002)

0.804 (0.003)

0.824 (0.003)

0.831 (0.002)

Misdemeanor

0.746 (0.007)

0.746 (0.007)

0.748 (0.007)

0.765 (0.006)

0.774 (0.006)

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

0.020

0.017

0.038

0.051

0.027

0.033

0.017

0.066

0.058

0.068

0.034

0.027

0.014

0.016

0.019

0.021

0.019

0.016

0.024

0.014

0.029

0.029

0.032

0.028


WANG & HAN ET AL.

43

TA B L E 9 AUCs of intepretable models on Broward data. For the violence problem, we use the Arnold New Violent
Criminal Activity score. For the general problem, we use the Arnold New Criminal Activity score.

Labels

CART

EBM

Additive Stumps

RiskSLIM

Performance Range

Arnold PSA

COMPAS

Interpretable Models

Existing Risk Models

0.613 (0.025) 0.664 (0.027)

0.651 (0.020)

0.624 (0.022)

0.605 (0.022) 0.631 (0.019)

0.613 (0.045) 0.673 (0.045)

0.665 (0.034)

0.655 (0.055)

0.649 (0.028)

0.666 (0.026) 0.685 (0.043)

0.716 (0.037)

0.697 (0.027)

0.686 (0.059) 0.736 (0.034)

0.736 (0.033)

0.717 (0.020)

0.596 (0.033) 0.655 (0.050)

0.631 (0.028)

0.590 (0.036)

Misdemeanor 0.577 (0.036) 0.636 (0.029)

0.609 (0.020)

0.579 (0.015)

Two Year

Six Month

0.569 (0.074) 0.672 (0.043)

0.656 (0.068)

0.650 (0.068)

0.637 (0.052) 0.725 (0.031)

0.725 (0.036)

0.703 (0.023)

0.513 (0.014) 0.606 (0.049)

0.574 (0.036)

0.561 (0.045)

Misdemeanor 0.535 (0.021) 0.608 (0.042)

0.582 (0.036)

0.576 (0.024)

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

0.051

0.059

0.049

0.052

0.065

0.059

0.074

0.049

0.102

0.089

0.093

0.073



















0.549 (0.021) 0.622 (0.022)

0.620 (0.019)

0.585 (0.021)

0.577 (0.018) 0.609 (0.019)

0.631 (0.050) 0.680 (0.040)

0.676 (0.029)

0.671 (0.039)

0.675 (0.038)

TA B L E 1 0 AUCs of interpretable models on Kentucky data. For the violence problem, we use the Arnold New
Violent Criminal Activity score. For the general problem, we use the Arnold New Criminal Activity score.

Labels

CART

EBM

Additive Stumps

RiskSLIM

Performance Range

Arnold PSA

Interpretable Models

Existing Risk Models

0.746 (0.003)

0.751 (0.004)

0.748 (0.004)

0.708 (0.003)

0.763 (0.007)

0.777 (0.004)

0.770 (0.005)

0.744 (0.008)

0.736 (0.002)

0.740 (0.001)

0.738 (0.002)

0.708 (0.005)

0.790 (0.003)

0.798 (0.006)

0.796 (0.005)

0.761 (0.003)

0.771 (0.002)

0.776 (0.001)

0.773 (0.002)

0.757 (0.007)

Misdemeanor

0.730 (0.005)

0.735 (0.005)

0.729 (0.006)

0.701 (0.002)

Two Year

Six Month

0.772 (0.005)

0.773 (0.004)

0.771 (0.004)

0.737 (0.002)

0.822 (0.011)

0.843 (0.006)

0.836 (0.004)

0.810 (0.009)

0.794 (0.003)

0.793 (0.004)

0.796 (0.004)

0.763 (0.004)

0.839 (0.014)

0.850 (0.012)

0.851 (0.010)

0.832 (0.010)

0.811 (0.003)

0.820 (0.003)

0.813 (0.003)

0.790 (0.006)

Misdemeanor

0.760 (0.006)

0.757 (0.006)

0.751 (0.006)

0.705 (0.005)

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

0.042

0.032

0.032

0.037

0.019

0.033

0.037

0.033

0.033

0.019

0.030

0.055

0.711 (0.004)

0.743 (0.003)

0.718 (0.004)

0.794 (0.011)










44

WANG & HAN ET AL.

TA B L E 1 1 Additive Stumps on two-year general recidivism. The model consists of twenty-eight stumps with an
intercept. These binary features represent ﬁfteen original features; coefﬁcients were rounded for display purposes
only.

1. age at current charge ≤ 20

2. age at current charge ≤ 21

3. age at current charge ≤ 24

4. age at current charge ≤ 27

5. age at current charge ≤ 35

6. age at current charge ≤ 39

7. age at current charge ≤ 43

8. age at current charge ≤ 47

9. prior arrest ≥ 2

10. prior arrest ≥ 3

11. prior arrest ≥ 4

12. prior arrest ≥ 5

13. prior charges ≥ 2

14. prior charges ≥ 2 3

15. prior violence ≥ 1

16. prior felony ≥ 1

17. prior misdemeanor ≥ 2

18. prior misdemeanor ≥ 3

19. prior misdemeanor ≥ 4

20. prior trafﬁc ≥ 1

21. ADE ≥ 1

22. prior fta two year ≥ 1

23. prior fta two year ≥ 2

24. prior pending charge ≥ 1

25. prior probation ≥ 1

26. prior incarceration ≥ 1

27. six month ≥ 1

28. three year ≥ 1

29. Intercept

0.0082

0.0053

0.0322

0.0270

0.0108

0.1223

0.0311

0.0686

0.6762

0.3489

0.2339

0.1226

0.0124

0.0065

0.0474

0.1721

0.0162

0.0764

0.0733

0.0394

0.1583

0.3398

0.0617

0.3874

0.2265

0.3577

0.0148

0.0005

-1.1500

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

-...

+...

+...

+...

+...

+...

-...

+...

+...

ADD POINTS FROM ROWS 1 TO 29

SCORE

= .....

Probability: Pr(Y = 1) = exp(score) / (1 + exp(score))


WANG & HAN ET AL.

45

TA B L E 1 2 Training baseline models and interpretable models on the Kentucky data set using ﬁve-fold nested cross
validation and testing the best-performing model on the Broward data set.

Labels

Logistic ((cid:96)2)

Logistic ((cid:96)1)

Linear SVM Random Forest

XGBoost

CART

EBM

Additive Stumps

RiskSLIM

Baseline Models

Interpretable Models

0.615 (0.001) 0.614 (0.001) 0.610 (0.000) 0.619 (0.001) 0.617 (0.003) 0.595 (0.009)

0.612 (0.002)

0.608 (0.001)

0.568 (0.000)

0.655 (0.001) 0.653 (0.002) 0.630 (0.000) 0.652 (0.000) 0.652 (0.004) 0.622 (0.030) 0.640 (0.0100)

0.652 (0.002)

0.629 (0.018)

0.629 (0.001) 0.629 (0.001) 0.618 (0.000) 0.614 (0.002) 0.637 (0.002) 0.621 (0.010)

0.629 (0.003)

0.631 (0.001)

0.625 (0.000)

0.664 (0.001) 0.672 (0.001) 0.649 (0.000) 0.668 (0.002) 0.674 (0.008) 0.649 (0.017)

0.665 (0.011)

0.659 (0.001)

0.639 (0.021)

0.630 (0.001) 0.630 (0.001) 0.624 (0.000) 0.631 (0.001) 0.627 (0.005) 0.611 (0.003)

0.623 (0.005)

0.624 (0.000)

0.614 (0.000)

Misdemeanor 0.558 (0.000) 0.558 (0.000) 0.551 (0.000) 0.561 (0.001) 0.576 (0.002) 0.555 (0.004)

0.571 (0.003)

0.557 (0.000)

0.539 (0.002)

0.577 (0.002) 0.576 (0.001) 0.569 (0.000) 0.577 (0.001) 0.581 (0.002) 0.562 (0.007)

0.571 (0.004)

0.562 (0.001)

0.553 (0.000)

0.641 (0.002) 0.644 (0.001) 0.614 (0.000) 0.643 (0.001) 0.626 (0.004) 0.611 (0.013)

0.622 (0.009)

0.650 (0.001)

0.637 (0.002)

0.607 (0.004) 0.604 (0.003) 0.589 (0.000) 0.567 (0.005) 0.593 (0.007) 0.580 (0.018)

0.618 (0.006)

0.576 (0.001)

0.566 (0.020)

0.662 (0.001) 0.665 (0.002) 0.635 (0.000) 0.652 (0.002) 0.656 (0.013) 0.634 (0.016)

0.657 (0.008)

0.640 (0.004)

0.619 (0.000)

0.586 (0.001) 0.584 (0.002) 0.575 (0.000) 0.589 (0.002) 0.58 (0.002)

0.563 (0.003)

0.571 (0.005)

0.574 (0.001)

0.550 (0.001)

Misdemeanor 0.558 (0.002) 0.558 (0.000) 0.550 (0.000) 0.552 (0.002) 0.563 (0.004) 0.554 (0.012)

0.559 (0.002)

0.542 (0.001)

0.526 (0.003)

TA B L E 1 3 Training baseline models and interpretable models on the Broward County data set using ﬁve-fold
nested cross validation and testing the resulting best-performing model on a held out portion of the Broward data set.

Labels

Logistic ((cid:96)2)

Logistic ((cid:96)1)

Linear SVM Random Forest

XGBoost

CART

EBM

Additive Stumps

RiskSLIM

Baseline Models

Interpretable Models

0.669 (0.020) 0.649 (0.021) 0.670 (0.020) 0.657 (0.034) 0.659 (0.019) 0.629 (0.028) 0.663 (0.031)

0.644 (0.027)

0.622 (0.021)

0.679 (0.038) 0.662 (0.035) 0.662 (0.034) 0.675 (0.037) 0.677 (0.05)

0.600 (0.037) 0.675 (0.049)

0.673 (0.035)

0.670 (0.032)

0.716 (0.047) 0.734 (0.034) 0.702 (0.043) 0.688 (0.044) 0.720 (0.034) 0.672 (0.041) 0.690 (0.054)

0.709 (0.044)

0.706 (0.027)

0.721 (0.057) 0.731 (0.057) 0.687 (0.052) 0.725 (0.039) 0.729 (0.04)

0.685 (0.058) 0.738 (0.031)

0.733 (0.039)

0.703 (0.036)

0.651 (0.040) 0.652 (0.053) 0.622 (0.036) 0.649 (0.045) 0.647 (0.039) 0.598 (0.034) 0.656 (0.050) 0.6400 (0.031) 0.603 (0.042)

Misdemeanor 0.634 (0.017) 0.602 (0.012) 0.632 (0.017) 0.629 (0.022) 0.624 (0.020) 0.585 (0.041) 0.633 (0.025)

0.603 (0.016)

0.558 (0.026)

0.624 (0.024) 0.607 (0.019) 0.619 (0.026) 0.620 (0.025) 0.621 (0.019) 0.553 (0.014) 0.620 (0.027)

0.617 (0.035)

0.600 (0.021)

0.680 (0.027) 0.650 (0.038) 0.614 (0.039) 0.670 (0.039) 0.689 (0.031) 0.623 (0.043) 0.683 (0.040)

0.683 (0.032)

0.691 (0.032)

0.672 (0.082) 0.696 (0.025) 0.649 (0.080) 0.687 (0.065) 0.686 (0.044) 0.569 (0.074) 0.655 (0.035)

0.704 (0.054)

0.719 (0.039)

0.726 (0.049) 0.725 (0.053) 0.648 (0.058) 0.698 (0.046) 0.720 (0.052) 0.637 (0.052) 0.723 (0.030)

0.699 (0.038)

0.663 (0.048)

0.620 (0.058) 0.613 (0.054) 0.587 (0.086) 0.611 (0.076) 0.601 (0.047) 0.524 (0.015) 0.605 (0.052)

0.584 (0.034)

0.557 (0.043)

Misdemeanor 0.616 (0.030) 0.583 (0.039) 0.590 (0.022) 0.601 (0.049) 0.620 (0.044) 0.543 (0.033) 0.612 (0.050)

0.576 (0.037)

0.556 (0.040)

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

Two Year

Six Month

Two Year

Six Month


46

WANG & HAN ET AL.

TA B L E 1 4 Training baseline and interpretable models on the Broward County data set using ﬁve-fold nested cross
validation and testing the resulting best-performing model on the Kentucky data set.

Labels

Logistic ((cid:96)2)

Logistic ((cid:96)1)

Linear SVM Random Forest

XGBoost

CART

EBM

Additive Stumps

RiskSLIM

Baseline Models

Interpretable Models

0.664 (0.007) 0.653 (0.001) 0.658 (0.007) 0.701 (0.005) 0.689 (0.006) 0.626 (0.025) 0.704 (0.003)

0.653 (0.009)

0.649 (0.037)

0.674 (0.005) 0.650 (0.007) 0.611 (0.013) 0.729 (0.005) 0.724 (0.005) 0.589 (0.053) 0.720 (0.005)

0.657 (0.018)

0.663 (0.025)

0.649 (0.008) 0.632 (0.003) 0.554 (0.005) 0.655 (0.022) 0.650 (0.006) 0.613 (0.013) 0.656 (0.008)

0.626 (0.009)

0.634 (0.012)

0.628 (0.022) 0.663 (0.014) 0.556 (0.017) 0.695 (0.018) 0.669 (0.023) 0.548 (0.018) 0.687 (0.011)

0.590 (0.014)

0.593 (0.052)

0.671 (0.006) 0.661 (0.002) 0.592 (0.014) 0.724 (0.003) 0.706 (0.014) 0.592 (0.042) 0.725 (0.006)

0.676 (0.023)

0.631 (0.059)

Misdemeanor 0.638 (0.007) 0.619 (0.026) 0.579 (0.01)

0.665 (0.011) 0.645 (0.014) 0.574 (0.053) 0.669 (0.007)

0.621 (0.017)

0.631 (0.025)

0.676 (0.006) 0.665 (0.004) 0.601 (0.011) 0.698 (0.009) 0.685 (0.010) 0.613 (0.018) 0.709 (0.005)

0.663 (0.012)

0.602 (0.046)

0.653 (0.015) 0.662 (0.021) 0.533 (0.011) 0.762 (0.047) 0.773 (0.007) 0.625 (0.059) 0.757 (0.004)

0.728 (0.026)

0.723 (0.004)

0.663 (0.031) 0.678 (0.008) 0.521 (0.006) 0.682 (0.009) 0.658 (0.027) 0.600 (0.082) 0.609 (0.037)

0.619 (0.025)

0.635 (0.017)

0.681 (0.012) 0.708 (0.009) 0.529 (0.012) 0.719 (0.053) 0.718 (0.010) 0.555 (0.007) 0.715 (0.018)

0.643 (0.022)

0.696 (0.053)

0.685 (0.008) 0.679 (0.008) 0.556 (0.011) 0.719 (0.018) 0.683 (0.025) 0.552 (0.049) 0.724 (0.010)

0.652 (0.039)

0.621 (0.036)

Misdemeanor 0.664 (0.003) 0.658 (0.008) 0.558 (0.016) 0.670 (0.004) 0.662 (0.006) 0.604 (0.019) 0.676 (0.006)

0.615 (0.019)

0.583 (0.070)

TA B L E 1 5 Training baseline models and interpretable models on the Kentucky data set using ﬁve-fold nested cross
validation and testing the resulting best-performing model on a held out portion of the Kentucky data set.

Labels

Logistic ((cid:96)2)

Logistic ((cid:96)1)

Linear SVM Random Forest

XGBoost

CART

EBM

Additive Stumps

RiskSLIM

Baseline Models

Interpretable Models

0.739 (0.003) 0.739 (0.003) 0.740 (0.004) 0.752 (0.004) 0.757 (0.003) 0.746 (0.003) 0.750 (0.004)

0.747 (0.004)

0.704 (0.004)

0.765 (0.001) 0.766 (0.002) 0.767 (0.002) 0.776 (0.004) 0.783 (0.004) 0.763 (0.007) 0.776 (0.004)

0.771 (0.005)

0.741 (0.010)

0.723 (0.002) 0.723 (0.002) 0.727 (0.002) 0.739 (0.002) 0.745 (0.002) 0.733 (0.002) 0.737 (0.002)

0.734 (0.003)

0.708 (0.002)

0.78 (0.004)

0.779 (0.004) 0.784 (0.004) 0.801 (0.004) 0.805 (0.004) 0.79 (0.004)

0.797 (0.005)

0.796 (0.005)

0.764 (0.009)

0.758 (0.002) 0.758 (0.002) 0.763 (0.002) 0.778 (0.002) 0.783 (0.001) 0.771 (0.002) 0.775 (0.001)

0.773 (0.001)

0.765 (0.001)

Misdemeanor 0.722 (0.005) 0.722 (0.005) 0.724 (0.006) 0.736 (0.006) 0.742 (0.005) 0.729 (0.005) 0.733 (0.006)

0.729 (0.006)

0.693 (0.010)

0.752 (0.004) 0.752 (0.004) 0.757 (0.004) 0.775 (0.003) 0.780 (0.003) 0.769 (0.005) 0.770 (0.004)

0.768 (0.004)

0.736 (0.004)

0.828 (0.006) 0.830 (0.005) 0.834 (0.005) 0.843 (0.005) 0.846 (0.005) 0.821 (0.011) 0.842 (0.005)

0.837 (0.004)

0.809 (0.005)

0.770 (0.003) 0.771 (0.003) 0.777 (0.004) 0.794 (0.004) 0.799 (0.002) 0.783 (0.005) 0.785 (0.004)

0.786 (0.004)

0.752 (0.006)

0.830 (0.010) 0.829 (0.011) 0.830 (0.013) 0.856 (0.009) 0.860 (0.011) 0.839 (0.014) 0.849 (0.011)

0.851 (0.010)

0.835 (0.009)

0.790 (0.002) 0.791 (0.002) 0.798 (0.003) 0.823 (0.003) 0.829 (0.003) 0.811 (0.005) 0.818 (0.004)

0.812 (0.004)

0.790 (0.005)

Misdemeanor 0.735 (0.006) 0.735 (0.006) 0.740 (0.007) 0.760 (0.005) 0.766 (0.005) 0.754 (0.005) 0.753 (0.006)

0.750 (0.006)

0.705 (0.005)

Two Year

Six Month

Two Year

Six Month

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony


WANG & HAN ET AL.

47

TA B L E 1 6 Arnold Public Safety Assessment (PSA): New Criminal Activity (NCA)

New Criminal Activity (NCA)

Risk Factor

Value

Points

Age at Current Arrest

23 or older

Total NCA Points NCA Scaled Score

Point Scaling

Pending Charge at Time of Offense

22 or younger

0

2

0

3

0

1

0

1

0

1

1

2

0

1

2

0

2

No

Yes

No

Yes

No

Yes

0

1

2

0

1

No

Yes

3 or more

2 or more

Prior Misdemeanor Conviction

Prior Felony Conviction

Prior Violent Conviction

Prior FTA in Past 2 Years

Prior Sentence to Incarceration

0

1

2

3

4

5

6

7

8

9

10

11

12

13

1

2

2

3

3

4

4

5

5

6

6

6

6

6

TA B L E 1 7 Arnold Public Safety Assessment (PSA): New Violent Criminal Activity (NVCA)

New Violent Criminal Activity (NVCA)

Risk Factor

Value

Points

Current Violent Offense

Point Scaling

Total NVCA Points NVCA Scaled Score

Current Violent Offense and 20 Years or Younger

Pending Charge at Time of Offense

Prior Conviction (Misdemeanor or Felony)

Prior Violent Conviction

No

Yes

No

Yes

No

Yes

No

Yes

0

1

2

3 or more

0

2

0

1

0

1

0

1

0

1

1

2

0

1

2

3

4

5

6

7

No

No

No

No

Yes

Yes

Yes

Yes


48

WANG & HAN ET AL.

TA B L E 1 8 AUCs of the Arnold NVCA Raw, EBM and RiskSLIM on Kentucky for two-year violent recidivism,
conditioned on sensitive attributes. AUC ranges are also given for each sensitive attribute class

Kentucky

Race

Sex

Model

Label

Afr-Am.

Cauc.

Other Race

race_range

Female

Male

sex_range

Arnold NVCA Raw

violent_two_year

0.728

0.740

0.767

0.039

0.728

0.734

0.006

EBM

violent_two_year

0.775

0.770

0.766

0.009

0.744

0.766

0.022

RiskSLIM

violent_two_year

0.744

0.736

0.680

0.063

0.706

0.730

0.024

TA B L E 1 9 Race and gender distributions for Kentucky. Due to the low percentage of the Asians and Indians in
Kentucky, we included them in the "Other" category in the fairness analysis.

Kentucky

Attribute

Attribute Value

num_inds % total

African-American

42197

16.83

race

race

race

race

race

sex

sex

Asian

843

0.34

Caucasian

202341

80.69

Indian

Other

195

5202

0.08

2.07

female

79207

31.58

male

171571

68.42


WANG & HAN ET AL.

11.6 | Figures

49

F I G U R E 1 0 Base rates of all twelve types of recidivism on Kentucky data, conditioned (separately) on race and
gender.

F I G U R E 1 1 Probabilities of two-year and six-month violent recidivism, given the age at current charge.

drug_six_monthdrug_two_yearfelony_six_monthfelony_two_yeargeneral_six_monthgeneral_two_yearmisdemeanor_six_monthmisdemeanor_two_yearproperty_six_monthproperty_two_yearviolent_six_monthviolent_two_yearPrediction Problem0.000.050.100.150.200.250.30P(Y = 1 | Attr = attr)Cond. prob. of recidivism for all prediction problems on KentuckyAfrican-AmericanCaucasianOtherfemalemale                      S U R E D E L O L W \ O R F D W L R Q     . < W Z R B \ H D U V L [ B P R Q W K                                                                                               D J H B D W B F X U U H Q W B F K D U J H                      S U R E D E L O L W \ O R F D W L R Q     ) / 9 L R O H Q W  5 H F L G L Y L V P
50

WANG & HAN ET AL.

F I G U R E 1 2 Calibration of the Arnold NVCA Raw, EBM and RiskSLIM for two-year violent recidivism on
Kentucky.

(a) For the Arnold NVCA raw score, the curves satisfy mono
tonic calibration until the score value of 7, where the prob
abilities drop to 0. This may be because there are few

individuals with an Arnold NVCA raw score equal to 7 in

the data. The curves for African-Americans/Caucasians and

males/females are close enough to satisfy group calibration

(but we note that the African-American (respectively, male)

curve is consistently higher than the Caucasian (respectively,

female) curve), especially for larger raw NVCA scores.

(b) For EBM, the calibration curves for both gender and race

(c) For RiskSLIM, the curves are monotonically increasing and

groups are irregular, demonstrating that EBM satisﬁed nei
roughly overlap with each other. The calibration curve for

ther group calibration nor monotonic calibration, on race and

African-Americans is slightly higher than for the Caucasian

gender groups.

and the “Other” race groups. For the two gender groups, the

curves are close to each other. We conclude that both race

and gender approximately satisfy group calibration.

0246Arnold NVCA Raw Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of Arnold NVCA Raw on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale0.0-0.10.1-0.20.2-0.30.3-0.40.4-0.50.5-0.60.6-0.70.7-0.80.8-0.90.9-1.0EBM Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of EBM on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale0.0-0.10.1-0.20.2-0.30.3-0.40.4-0.50.5-0.60.6-0.70.7-0.80.8-0.90.9-1.0RiskSLIM Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of RiskSLIM on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale
WANG & HAN ET AL.

51

F I G U R E 1 3 Balance for Positive and Negative Class for the Arnold NVCA Raw, EBM and RiskSLIM on the two-year
violent prediction problem in Kentucky. Red line indicates the maximum value output by models.

(a) Differences in expected scores for African-Americans

and Caucasians are greater than the threshold (0.2):

0.29 (race, negative class), 0.29 (race, positive class).

Differences in expected scores for gender are also

greater than the threshold: 0.38 (gender, negative

class) and 0.50 (gender, positive class).

(b) Differences in expected scores for African-Americans

(c) Differences in expected scores for African-Americans

and Caucasians are less than 0.03: 0.01 (race, negative

and Caucasians are less than 0.03: 0.01 (race, negative

class), 0.01 (race, positive class). Differences in expected

class), 0.02 (race, positive class). Differences in expected

scores for gender also satisfy the threshold: 0.00 (gender,

scores for gender satisfy the threshold for the negative

negative class) and 0.02 (gender, positive class).

class, but not for the positive class: 0.03 (gender, negative

class) and 0.06 (gender, positive class).

violent_bncviolent_bpc02468E(Arnold | Attr = attr, Y = i)1.863.131.572.841.152.551.352.491.732.99BPC/BNC for Arnold on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMaleviolent_bncviolent_bpc0.00.20.40.60.81.0E(EBM | Attr = attr, Y = i)0.010.030.00.020.00.010.00.010.00.03BPC/BNC for EBM on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMaleviolent_bncviolent_bpc0.00.20.40.60.81.0E(RiskSLIM | Attr = attr, Y = i)0.040.080.030.060.010.030.010.020.040.08BPC/BNC for RiskSLIM on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMale
52

WANG & HAN ET AL.

11.7 | Nested Cross Validation Procedure

We applied ﬁve-fold nested cross validation to tune parameters. We split the entire data set into ﬁve equally-sized folds

for the outer cross validation step. One fold was used as the holdout test set and the other four folds were used as the
training set (call it “outer training set”). The inner loop deals only with the outer training set ( 45 ths of the data). On this
outer training set, we conducted ﬁve-fold cross validation and grid-searched hyperparameter values. After this point,

each hyperparameter value had ﬁve validation results. We selected the parameter values with the highest average

validation results and then trained the model with this best set of parameters on the entire outer training set and tested

We repeated the process above until each one of the original ﬁve folds was used as the holdout test set. Ultimately,

we had ﬁve holdout test results, with which we were able to calculate the average and standard deviation of the

it on the holdout test set.

performance.

We applied a variant of the nested cross validation procedure described above to perform the analysis discussed

in Section 8—where we trained models on one region and tested on the other region. For instance, when we trained

models on Broward and tested them on Kentucky, the Kentucky data was treated as the holdout test set. We split

the Broward data into ﬁve folds and used four folds to do cross validation and constructed the ﬁnal model using the

best parameters. We then tested the ﬁnal model on the entire Kentucky data set, as well as the holdout test set from

Broward. We rotated the four folds and repeated the above process ﬁve times.


WANG & HAN ET AL.

11.8 | RiskSLIM Tables

53

TA B L E 2 0 Two Year Prediction Problems—Kentucky. Here, counts of prior arrests indicate the counts of arrests
with at least one convicted charge. All charges mentioned are convicted charges. ADE indicates assignment to alcohol
and drug education classes.

Two Year General Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-6 + score)))

Two Year Violent Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))

sex = Male

number of prior arrests≥2

number of prior arrests≥3

number of prior arrests≥5

1 points

1 points

1 points

+...

+...

+...

age at current charge ≤ 27

number of prior arrests≥2

number of prior violent charges≥1

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

sentenced to incarceration before = Yes

1 points

1 points

1 points

1 points

1 points

+...

+...

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....

Two Year Drug Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

number of prior arrests≥2

number of prior drug related

charges≥1

1 points

1 points

+...

+...

charges≥1

number of times charged with

1 points

+...

a new offense when there is a pending case≥1

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

Two Year Property Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

number of prior property related

1 points

+...

number of prior arrests≥3

number of times charged with

1 points

1 points

+...

+...

a new offense when there is a pending case≥1

number of prior ADE ≥1

-1 points

+...

ADD POINTS FROM ROWS 1 TO 4

SCORE

= .....

Two Year Felony Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

Two Year Misdemeanor Recidivism

age at current charge ≤ 43

number of prior arrests≥2

number of prior felony level charges≥1

number of times charged with

a new offense when there is a pending case≥1

1 points

1 points

1 points

1 points

+...

+...

+...

+...

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

number of prior arrests≥2

number of times charged with

a new offense when there is a pending case≥1

1 points

1 points

+...

+...

sentenced to incarceration before = Yes

1 points

+...

sentenced to incarceration before = Yes

1 points

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....


54

WANG & HAN ET AL.

TA B L E 2 1 Six Month Prediction Problems—Kentucky. Here, counts of prior arrests indicate the counts of arrests
with at least one convicted charge. All charges mentioned are convicted charges. ADE means assignment to alcohol and
drug education classes.

Six Month General Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-7 + score)))

Six Month Violent Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

number of prior arrests≥2

number of prior arrests≥4

number of times charged with

a new offense when there is a pending case≥1

1 points

1 points

1 points

+...

+...

+...

number of prior violent charges≥1

number of prior arrests≥3

number of prior felony level charges≥1

current violent charge = Yes

number of times charged with

1 points

1 points

1 points

1 points

1 points

+...

+...

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

a new offense when there is a pending case≥1

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....

Six Month Drug Recidivism

Six Month Property Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

Pr(Y = +1) = 1 / (1 + exp(-(-7 + score)))

number of prior drug related charges≥1

number of prior property related charges≥1

number of prior drug related charges≥3

number of prior felony level charges≥1

1 points

1 points

1 points

+...

+...

+...

number of times charged with

a new offense when there is a pending case≥1

number of prior FTA within last two years ≥1

1 points

number of times charged with

1 points

number of prior ADE≥1

-1 points

+...

a new offense when there is a pending case≥1

2 points

1 points

+...

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 4

SCORE

= .....

ADD POINTS FROM ROWS 1 TO 4

SCORE

= .....

Six Month Felony Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

number of prior arrests≥3

number of prior felony level charges≥1

number of times charged with

a new offense when there is a pending case≥1

Six Month Misdemeanor Recidivism

1 points

1 points

1 points

+...

+...

+...

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

number of prior arrests≥2

number of prior arrests≥4

1 points

1 points

+...

+...

ADD POINTS FROM ROWS 1 TO 2

SCORE

= .....

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....


WANG & HAN ET AL.

55

TA B L E 2 2 Two Year Prediction Problems—Broward. Here, counts of prior arrests indicate the counts of arrests
with at least one non-convicted or convicted charge. All charges mentioned are non-convicted charges.

Two Year Violent Recidivism

Two Year General Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))

age at current charge≤30

age at current charge ≤31

1 points

number of prior violent charges≥4

number of prior misdemeanor level charges ≥4

1 points

number of prior arrests≥7

had charge(s) within last three years = Yes

1 points

current violent charge=Yes

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

had charge(s) within last three year = Yes

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....

1 points

1 points

1 points

1 points

1 points

1 points

1 points

1 points

1 points

1 points

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

Two Year Property Recidivism

Two Year Drug Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

age at current charge≤33

age at current charge ≤18

age at current charge ≤23

number of prior drug related charges≥1

number of prior property related charges≥1

number of prior drug related charges≥4

number of prior property related charges≥5

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

number of prior violent charges≥4

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....

Two Year Felony Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

age at current charge ≤33

number of prior misdemeanor

level charges≥4

1 points

1 points

+...

+...

Two Year Misdemeanor Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))

age at ﬁrst charge≤30

number of FTA within last two years≥1

1 points

1 points

+...

+...

number of prior property related charges≥4

1 points

+...

ADD POINTS FROM ROWS 1 TO 2

SCORE

= .....

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....


56

WANG & HAN ET AL.

TA B L E 2 3 Six Month Prediction Problems—Broward. Here, counts of prior arrests indicate the counts of arrests
with at least one non-convicted or convicted charge. All charges mentioned are non-convicted charges.

Six Month General Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

age at ﬁrst charge≤28

had charge(s) within last three years = Yes

1 points

1 points

+...

+...

ADD POINTS FROM ROWS 1 TO 2

SCORE

= .....

Six Month Violent Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

current violent charge = Yes

number of prior violent charges ≥4

had charge(s) within last three years = Yes

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

Six Month Drug Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

age at ﬁrst charge≤21

number of prior drug charges≥2

had charge(s) within last year = Yes

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

Six Month Property Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

age at current charge≤29

1 points

+ ...

number of prior misdemeanor level charges≥5

1 points

number of prior property related charges≥1

number of prior property related charges≥4

+...

+...

+...

1 points

1 points

ADD POINTS FROM ROWS 1 TO 4

SCORE

= .....

Six Month Felony Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

age at current charge≤29

number of prior property related charges≥4

1 points

1 points

+...

+...

ADD POINTS FROM ROWS 1 TO 2

SCORE

= .....

Six Month Misdemeanor Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

age at current charge≤19

number of prior weapon related charges≥1

had charge(s) within last three years = Yes

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....


WANG & HAN ET AL.

11.9 | Features

57

TA B L E 2 4 Features from Broward data set. Recall that charges can be convicted or non-convicted.

person_id

unique personal identiﬁer

sex

race

biological sex of the person

race of the person

screening_date

date that triggered the COMPAS screening

age_at_current_charge age at the person’s current charge

age_at_ﬁrst_charge

age at the person’s ﬁrst charge

p_arrest

count of prior arrests

p_charges

count of prior charges

p_violence

count of prior violent charges

p_felony

count of prior felony-level charges

p_misdemeanor

count of prior misdemeanor-level charges

p_juv_fel_count

count of prior felony-level and juvenile charges

p_property

count of prior property-related charges

p_murder

count of prior murder charges

p_famviol

count of prior family violence charges

p_sex_offenses

count of prior sex offense charges

p_weapon

count of prior weapon-related charges

p_felprop_viol

count of prior felony-level, property-related, and violent charges

p_felassault

count of prior felony-level assault charges

p_misdeassault

count of prior misdemeanor-level assault charges

p_trafﬁc

count of prior trafﬁc-related charges

p_drug

p_dui

count of prior drug-related charges

count of prior DUI charges

p_stalking

count of prior stalking charges

p_voyeurism

count of prior voyeurism charges

p_fraud

count of prior fraud charges

p_stealing

count of prior stealing/theft charges

p_domestic

count of prior domestic violence charges

p_trespass

count of prior trespass charges

p_fta_two_year

count of prior failures to appear in court within last two years (≤ 2 years)

p_fta_two_year_plus

count of prior failures to appear in court beyond last two years (> 2 years)

p_pending_charge

count of times charged with a new offense when there was a pending case

p_probation

count of times charged with a new offense when the person was on probation

p_incarceration

whether or not the person was formerly sentenced to incarceration

six_month

whether or not the person had charges within last six months (≤ 6 months)

one_year

whether or not the person had charges within last year (≤ 1 year)

three_year

whether or not the person had charges within last three years (≤ 3 years)

ﬁve_year

whether or not the person had charges within last ﬁve years (≤ 5 years)

current_violence

whether or not the current charge is violent

current_violence20 whether or not the current charge is violent and the person is ≤ 20 years old

total_convictions

total count of convictions


58

WANG & HAN ET AL.

TA B L E 2 5 Features from Kentucky data set. The charges are convicted. ADE means assignment to alcohol and drug
education classes.

current_date

current charge date or the release date if there was a sentence on the current charge.

age_at_current_charge

age at the person’s current charge, or the age at current charge plus the sentence time if there was

person_id

unique personal identiﬁer

sex

race

biological sex of the person

race of the person

a sentence on the current charge

p_arrest

count of prior arrests with convicted charges

p_charges

count of prior convicted charges

p_violence

count of prior violent charges

p_felony

count of prior felony-level charges

p_misdemeanor

count of prior misdemeanor-level charges

p_property

count of prior property-related charges

p_murder

count of prior murder charges

p_assault

count of prior assault charges

p_sex_offenses

count of prior sex offense charges

p_weapon

count of prior weapon-related charges

p_felprop_viol

count of prior felony-level, property-related, and violent charges

p_felassault

count of prior felony-level assault charges

p_misdeassault

count of prior misdemeanor-level assault charges

p_trafﬁc

count of prior trafﬁc-related charges

p_drug

p_dui

count of prior drug-related charges

count of prior DUI charges

p_stalking

count of prior stalking charges

p_voyeurism

count of prior voyeurism charges

p_fraud

count of prior fraud charges

p_stealing

count of prior stealing/theft charges

p_trespass

count of prior trespass charges

ADE

count of times the person was assigned to alcohol/drug education classes

treatment

count of times the person received treatment along with the sentence

p_fta_two_year

count of prior failures to appear in court within last two years (≤ 2 years)

p_fta_two_year_plus

count of prior failures to appear in court beyond last two years (> 2 years)

p_pending_charge

count of times charged with a new offense when there was a pending case

p_probation

count of times charged with a new offense when the person was on probation

p_incarceration

whether or not the person was formerly sentenced to incarceration

six_month

whether or not the person had charges within last six months (≤ 6 months)

one_year

whether or not the person had charges within last year (≤ 1 year)

three_year

whether or not the person had charges within last three years (≤ 3 years)

ﬁve_year

whether or not the person had charges within last ﬁve years (≤ 5 years)

current_violence

whether or not the current charge was violent

current_violence20

whether or not the current charge was violent and the person was ≤ 20 years old

current_pending_charge whether or not the person had a pending case during the current charge



========================================
====================COMPLETE TEXT====================
0
2
0
2
 
y
a
M
 
8
 
 
]
L
M
t.
a
t
[s

 
 
1
v
6
7
1
4
0
.
5
0
0
2
:
v
i
X
r
a

O R I G I N A L A R T I C L E

In Pursuit of Interpretable, Fair and Accurate
Machine Learning for Criminal Recidivism
Prediction

Caroline Wang ∗

| Bin Han ∗

| Bhrij Patel

| Feroze

Mohideen

| Cynthia Rudin

Duke University, Durham, NC 27708, USA

Correspondence
Bin Han, Department of Statistical Science,
Duke University, Durham, NC 27708, USA
Email: bin.han@duke.edu

Funding information
This study was partially supported by
Arnold Ventures and the Department of
Computer Science at Duke University.

In recent years, academics and investigative journalists have

criticized certain commercial risk assessments for their black
box nature and failure to satisfy competing notions of fair
ness. Since then, the ﬁeld of interpretable machine learning

has created simple yet effective algorithms, while the ﬁeld

of fair machine learning has proposed various mathematical

deﬁnitions of fairness. However, studies from these ﬁelds

are largely independent, despite the fact that many appli
cations of machine learning to social issues require both

fairness and interpretability.

We explore the intersection by revisiting the recidivism

prediction problem using state-of-the-art tools from inter
pretable machine learning, and assessing the models for

performance, interpretability, and fairness. Unlike previous

works, we compare against two existing risk assessments

(COMPAS and the Arnold Public Safety Assessment) and

train models that output probabilities rather than binary

predictions. We present multiple models that beat these risk

assessments in performance, and provide a fairness analysis

of these models. Our results imply that machine learning

models should be trained separately for separate locations,

and updated over time.

∗Equally contributing authors.

1


2

WANG & HAN ET AL.

criminal recidivism, interpretability, fairness, COMPAS, machine

K E Y W O R D S

learning

| Abstract of Main Results for Criminal Justice Practitioners

Our goal is to study the predictive performance, interpretability, and fairness of machine learning models for pretrial

recidivism prediction. Machine learning methods are known for their ability to automatically generate high-performance

models (that sometimes even surpass human performance) from data alone. However, many of the most common

machine learning approaches produce “black-box” models—models that perform well, but are too complicated for

humans to understand. “Interpretable” machine learning techniques seek to produce the best of both worlds: models

that perform as well as black-box approaches, but also are understandable to humans. In this study, we generate multiple

black-box and interpretable machine learning models. We compare the predictive performance and fairness of the

machine learning models we generate, against two models that are currently used in the justice system to predict pretrial

recidivism—namely, the Risk of General Recidivism and Risk of Violent Recidivism scores from the COMPAS suite, and

the New Criminal Activity and New Violent Criminal Activity scores from the Arnold Public Safety Assessment.

We ﬁrst evaluate the predictive performance of all models, based on their ability to predict recidivism for six

different types of crime (general, violent, drug, property, felony, and misdemeanor). Recidivism is deﬁned
as a new charge for which an individual is convicted within a speciﬁed time frame (which we specify as six months or

two years). We consider each type of recidivism over the two time periods to control for time, rather than to consider

predictions over an arbitrarily long or short pretrial period. Next, we examine whether a model constructed using data

from one region suffers in predictive performance when applied to predict recidivism in another region. Finally, we

consider the latest fairness deﬁnitions created by the machine learning community. Using these deﬁnitions, we examine

the behavior of the interpretable models, COMPAS, and the Arnold Public Safety Assessment, on race and gender

subgroups.

Our ﬁndings and contributions can be summarized as follows:

• We contribute a set of interpretable machine learning models that can predict recidivism as well as black-box
machine learning methods and better than COMPAS or the Arnold Public Safety Assessment for the location they

were designed for. These models are potentially useful in practice. Similar to the Arnold Public Safety Assessment,

some of these interpretable models can be written down as a simple table that ﬁts on one page of paper. Others can

be displayed using a set of visualizations.

• We ﬁnd that recidivism prediction models that are constructed using data from one location do not tend to perform
as well when they are used to predict recidivism in another location, leading us to conclude that models should be

constructed on data from the location where they are meant to be used, and updated periodically over time.

• We reviewed the recent literature on algorithmic fairness, but most of the fairness criteria don’t pertain to risk
scores, they pertain only to yes/no classiﬁcation decisions. Since we are interested in criminal justice risk scores in

this work, the vast majority of the algorithmic fairness criteria are not relevant. We chose to focus on the evaluation

criteria that were relevant, namely calibration, balance for positive/negative class (BPC/BNC), and balanced group

AUC (BG-AUC). We present an analysis of these fairness measures for two of the interpretable models (RiskSLIM

and Explainable Boosting Machine) and the Arnold Public Safety Assessment (New Criminal Activity score) on the

two-year general recidivism outcome in Kentucky. We found that the fairness criteria were approximately met for

both interpretable models for blacks/whites and males/females (that is, the models were fair according to these


WANG & HAN ET AL.

3

criteria). However, the Arnold Public Safety Assessment’s New Criminal Activity score failed to meet one fairness

criterion (BPC/BNC). The results on fairness were not as consistent for the “Other” race category.

1 |

INTRODUCTION

Predicting criminal recidivism using statistics has been the subject of almost a hundred years of research in criminal

justice, psychology, and law. Today, actuarial risk assessments are in wide use across many countries, helping judges make

life-changing decisions in pretrial release, sentencing, and probation. Risk assessments can help reduce costs, racial

disparity, and incarceration rates—and these beneﬁts have already been realized in some jurisdictions [1]. However,

some of the most widely used algorithms are secret, black-box models created by corporations. As a result, individuals

affected by these algorithms cannot know how these decisions were made, or whether they were made in error. These

problems resulted in various lawsuits over the last decade, and came to the fore in 2016, when investigative journalists
from the nonproﬁt organization ProPublica claimed that the COMPAS1 black-box recidivism prediction model was rife

with racial bias [2, 3].

Though ProPublica’s ﬁndings were not validated [4, 5, 6], the COMPAS scandal demonstrated the issues with

for-proﬁt, secret algorithms making decisions in the justice system—namely, possible violations of defendants’ due

process rights, difﬁculty in ensuring that the scores were calculated based on correct inputs, and the lack of independent

fairness or performance guarantees. It highlighted the ways that systemic bias in data can be propagated into the future,

and was symptomatic of growing public distrust in the algorithms that impact our daily lives [7, 8, 9].

To prevent errors, prevent due process violations, allow independent validation of models, and gain public trust, we

must create transparent, interpretable and fair models. Fortunately, techniques for interpretable machine learning and

theories of fairness have advanced considerably over the last few years. Multiple works have demonstrated that publicly

available interpretable machine learning algorithms can perform as well as black-box machine learning algorithms

[10, 11, 12]. Moreover, high-dimensional data sets on criminal recidivism have become increasingly available. However,

most machine learning papers treat recidivism prediction as a toy problem to test new machine learning algorithms.

They do not consider factors such as data quality or ease of computation of model predictions, which are paramount

for creating models that would be useful in practice. To our knowledge, there is only one prior work [13] that jointly

considers interpretability, fairness, and predictive performance; however, it does not do so in a comprehensive way and

focuses primarily on the design of a new algorithm.

Beyond the problem of model optimization, various methodological questions remain with existing risk assessment

systems. First, existing systems—such as COMPAS (Correctional Offender Management Proﬁling System for Alternative

Sanctions) and LSI-R (Level of Service Inventory Revised)—are often used across various states (or even countries)

with only minor normalization [14, 15]. However, populations in different states can signiﬁcantly differ because the

data generation process is not the same, so applying the same model across states may not lead to the best possible

performance. Second, empirical evidence indicates that the underlying probability distribution of recidivism has

changed over time in multiple locations [16]. For instance, a signiﬁcant shift in the age distribution—a key predictor in

many recidivism prediction models—has been observed in New York [17]. Thus, rather than using a static model with

uneven performance across districts, a better solution might be to algorithmically generate models, so that they can be

trained for speciﬁc locations and retrained if recidivism distributions shift over time.

Using modern tools of both interpretable and black-box machine learning, we revisit the recidivism prediction

problem. We deﬁne recidivism as a new charge that an individual is convicted for within a certain time frame (six months

1COMPAS stands for Correctional Offender Management Proﬁling for Alternative Sanctions.


4

WANG & HAN ET AL.

or two years). We ﬁnd that (1) black-box models do not perform signiﬁcantly better than interpretable models for any of

the twelve recidivism problems we consider. (2) Interpretable models generally perform better than existing actuarial

risk assessments. (3) Models do not generalize well across regions. (4) Only a small subset of the many proposed fairness

deﬁnitions can be applied to regression problems and they vary across different models. We also note that existing

techniques to enforce fairness generally require non-interpretable transformations, and therefore do not work well

with interpretable models.

This paper is structured as follows. Section 2 describes our contributions. Section 3 discusses the evolution of risk

assessment in America, the current debate over risk assessments, and brieﬂy reviews the machine learning literature on

risk assessment. Section 4 describes the study’s data sources. Section 5 discusses aspects of our methodology, including

the prediction problems, problem setup, and the existing risk assessments we compare against. Section 6 presents the

performance of baseline, non-interpretable machine learning methods, while Section 7 presents the performance of

interpretable machine learning methods. Section 8 examines the generalization of recidivism prediction models across

states. In Section 9, we describe the selection of fairness metrics and assess the fairness of the interpretable models. In

Section 10, we discuss broader impacts and future lines of inquiry.

2 | CONTRIBUTION

Our main contribution is a set of interpretable, risk-calibrated linear models that perform better than existing actuarial

risk assessments, and predict speciﬁc crime types. Other important aspects of our contribution are as follows:

• We consider multiple types of recidivism (general, violent, drug, property, felony, and misdemeanor) at two

time scales (six-month, two-year) for a total of 12 prediction problems.

• Our analysis was conducted on two criminal history data sets (one from Broward County, Florida, and the other
from the state of Kentucky), which allowed us to understand variability in model performance across locations. We

found that models do not generalize well between locations, and conclude that models should be trained on data

from the location where they are meant to be used.

• We discuss how our models satisfy fairness and interpretability criteria. To our knowledge, beyond the ﬁelds of fair
and interpretable machine learning, there are few paper that discuss both fairness and interpretability with the

same attention as predictive performance.

•

The risk models trained as part of this study are interpretable, and could potentially be useful in practice after a

careful, location-speciﬁc evaluation of their accuracy and fairness.

Similar to Zeng et al. [10], we use machine learning techniques optimized for interpretability, and address multiple

prediction problems. This work is an improvement over that of Zeng et al. [10] in the following ways. We use inter
pretable machine learning techniques to create risk scores representing probabilities of recidivism, rather than making

binary predictions (the tools we use had not been not invented at the time of Zeng et al. [10]’s publication). We compare

with COMPAS and the Arnold Public Safety Assessment (PSA), two models currently used in the justice system, whereas

Zeng et al. [10] compared only with other machine learning methods. We use data obtained at the pretrial stage rather

than at prison-release. Since many jurisdictions utilize prediction instruments to determine pretrial release, this better

aligns with the use cases of risk scores. Our data come from two locations, and include more detailed information than

in Zeng et al. [10], and are more recent than 1994. Finally, models are assessed for multiple deﬁnitions of fairness (in

addition to performance).


WANG & HAN ET AL.

3 | BACKGROUND

5

Algorithmic risk assessment dates back to the early 1900s [18], and is used today at various stages of the criminal justice

system, such as at pretrial, parole, probation, or even sentencing. In this work, we focus on forecasting recidivism at the

pretrial stage. Though some states have implemented their own tools (Virginia, Pennsylvania, Kentucky), many utilize

systems produced by companies, non-proﬁts and other organizations [19]. These externally-produced risk assessments

and some of the jurisdictions that utilize them include COMPAS (Florida, Michigan, Wisconsin, Wyoming, New Mexico),
the Public Safety Assessment (New Jersey, Arizona, Kentucky,2 Phoenix, Chicago, Houston), LSI-R (Delaware, Colorado,

Hawaii), and the Ohio Risk Assessment System [20, 21, 22]. The United States is not alone in using actuarial risk

assessments. Canada uses the Static-2002 to assess risk of violent and sexual recidivism [23]; the Netherlands uses the

Quickscan to assess static and dynamic risks of recidivism [24]; the U.K. uses the Offender Group Reconviction Scale to

predict reoffense while on probation [25].

3.1 | The Debate over Risk Assessments

Since the inception of actuarial risk assessments, there has been debate over whether they should be used in the

criminal justice system at all. Proponents claim that statistical models reduce overall violence levels and ensure the

most efﬁcient use of treatment and rehabilitative resources by helping judges identify the individuals that are truly

dangerous. A large body of evidence appears to support this claim. Various studies have shown that statistical models

are more accurate than human experts [26, 27]. Others have shown that a small percentage of individuals commit the

majority of crimes [28, 29, 30], indicating that correctly identifying dangerous individuals could lead to substantial

decreases in violence levels. Proponents also claim that risk assessments are instrumental to reducing racial/economic

disparity, allocating social services, and reducing mass incarceration [31]. In particular, some jurisdictions have adopted

risk assessments at the pretrial stage to replace cash bail, which is widely viewed as biased against poor defendants

[32, 33].

In practice, reducing overall violence levels, mass incarceration, and racial/economic disparity through actuarial risk

assessment is complex. Critics have argued that as recidivism prediction models always rely on racially-biased features

such as arrest records, actuarial risk assessment will only exacerbate racial and socioeconomic disparity, and should

therefore be abolished [34, 35]. In a well-known incident, ProPublica claimed that COMPAS was biased against African
Americans because there was a disparity in false positive rates and false negative rates between African-Americans and

Caucasians [36]. Follow-up research showed that this bias was likely a property of the data generation process rather

than the COMPAS model, and that even a model that only relied on age showed a similar disparity in false positives

and false negatives [4]. Actuarial risk assessment might be vulnerable to feature bias, but it is important to remember

that other parts of the court system (such as bail and sentencing guidelines for judges) are not immune to feature bias

either—they also use criminal history and arrest records. Similarly, in one of the ﬁrst large-scale empirical studies,

Stevenson [37] showed that in Kentucky, the use of the Arnold PSA seemingly increased disparity between whites and

blacks at pretrial release. Because the risk scores were applied differently by judges in different counties, it seemed

that white people beneﬁted more than black people in terms of pretrial release numbers—but within the same county,

white and black defendants saw similar increases in release. Thus, rather than eliminating the use of risk scores, using

them uniformly across counties may have made risk assessments more fair across the state.

Others have argued that a fundamental ﬂaw with risk assessments is that their simple labels obscure the true

uncertainty behind their predictions [7]. This may be true for currently used risk assessments, but merely underscores

2Kentucky created and implemented their own tool in 2006 but transitioned to the Arnold PSA in 2013.


6

WANG & HAN ET AL.

the necessity for researchers to develop models which do quantify uncertainty. While actuarial risk assessments are not

perfect, we must remember that in the absence of risk assessments, judges can only rely on their intuition—and human

intuition has been shown to be less reliable than statistical models [26, 27, 33, 38].

Another problem is that some of the most widely used risk prediction algorithms are for-proﬁt and secret (e.g.,
COMPAS 3), yielding concerns over due process rights. In the 2017 Wisconsin Supreme Court case, Loomis v. Wisconsin,

Loomis challenged the use of the proprietary risk prediction software, COMPAS, on the grounds that this violated his

due process and equal protection rights [3]. Yet today, there are plenty of equally accurate, transparent risk prediction

tools that publish their guidelines and full models. See Table 4 in the Appendix for examples. In this article, we compare

against the Arnold PSA, an interpretable and publicly available tool which is used in multiple jurisdictions.

There is also a general fear that the use of risk assessments could lead to situations similar to those depicted in the

movie, “Minority Report”. In Minority Report, individuals were punished before they committed a crime based on oracles’

visions of the future. However, one of the major principles common to American criminal justice texts [40, 41] is that

individuals should be punished based on the crimes they committed in the past. This illustrates why risk assessments

have played only a minor role in sentencing. In reality, risk prediction tools are most heavily used in bail, parole, and

social services decisions.

Risk scores are no “magic bullet,” but abolishing risk assessment without a useful alternative plan will not solve the

problems above either. Reducing feature bias requires generations of community investment; jurisdictions must train

judges on how to use risk scores; and communities must provide treatment resources for those deemed high risk. Risk

assessments and other evidence-driven practices can be an important part of this solution. In the most recent revision

of the Model Penal Code, the American Law Institute has supported giving people shorter prison terms or sending them

to the community through the use of risk assessment tools [42, 43]. By providing simple and transparent risk scores,

we hope to mitigate the possibility that risk assessments are miscomputed, and enable judges and defendants to fully

understand their scores.

3.2 | Black-box and Interpretable Machine Learning for Predicting Criminal Recidivism

There is an abundance of past research on using machine learning methods to predict criminal recidivism. However,

many of these studies utilize black-box, non-interpretable models, and only optimize for predictive performance. For

instance, Neuilly et al. [44] used random forests to predict homicide offender recidivism. Other black-box models

applied to this problem include stochastic gradient boosting [45] and neural networks [46].

In comparison, there is relatively little work using interpretable machine learning techniques to forecast recidivism.
It is not even clear how interpretability should be deﬁned in this domain4. Berk et al. [47] used classical decision trees to

build a simple screener for forecasting domestic violence for the Los Angeles Sheriff’s Department. In 2016, Goel et al.

[48] created a simple scoring system by rounding logistic regression coefﬁcients, which helped address stop-and-frisk

for the New York Police Department. Zeng et al. [10] was the ﬁrst work using modern machine learning methods that

globally optimized over the space of sparse linear integer models to predict criminal recidivism. Despite the range of

interpretable models that have been applied to the criminal recidivism problem, a common thread among these works is

that simple, interpretable models can do just as well as black-box models, and better than humans. For instance, Angelino

et al. [11] found that COMPAS shows no beneﬁt in accuracy over very simple machine learning models involving age

3While COMPAS’ guidelines are published and validation studies have been performed, the full forms of the models are not available and some of the validation
studies do not conform to standards of open science (i.e., the validation data is not publicly available [39], or the studies’ authors are afﬁliated with the

corporations that produced the models.
4See Section 7 for a discussion of what we consider interpretable for the domain of criminal recidivism prediction


WANG & HAN ET AL.

7

and criminal history. Skeem et al. [38] showed that algorithms outperformed humans on predicting criminal recidivism

in three data sets, and demonstrated that the performance gap was especially large when abundant risk factors were

considered for risk prediction.

The approaches outlined above achieved interpretability through training models with interpretable forms. Another

major approach is post-hoc explainability, in which a simpler model provides insights into a black-box model. However,

post-hoc explanations are notoriously unreliable, or are not thorough enough to fully explain the black-box model [49].

Additionally, there seems to be no clear beneﬁt of black-box models over inherently interpretable models in terms of

prediction accuracy on the criminal recidivism problem [10, 24]. Thus, for a high-stakes problem such as predicting

criminal recidivism, we choose not to utilize these methods.

In fact, there have been cases in criminal justice where post-hoc explanations led to incorrect conclusions and

pervasive misconceptions about what information some of the most common recidivism models use. The 2016 COMPAS

scandal—where ProPublica reporters accused the proprietary COMPAS risk scores of an explicit dependence on race

[36]—was caused by a ﬂawed, post-hoc explanation of a black-box model. In particular, ProPublica reasoned that if

a post-hoc explanation of COMPAS depended linearly on race, then COMPAS depended on race (controlling for age

and criminal history). However, as Rudin et al. [4] demonstrated, just because an explanation model depends on a

variable does not mean that the black box model depends on that variable. Thus, ProPublica’s reasoning was incorrect.

In particular, this analysis found that COMPAS does not seem to depend linearly on some of its input variables (age),

and does not seem to depend on race after conditioning on age and criminal history variables. Criminologists have also

criticized the ProPublica work for other reasons [5]. Despite the ﬂaws in the ProPublica article, it is widely viewed as

being a landmark paper on fairness in machine learning.

A notable advantage of interpretable modelling for criminal justice is that some interpretable models allow a

decision-maker to incorporate factors not in the database in a way that black-box models cannot. For instance, scoring

systems (linear models with integer coefﬁcients) place all of the model inputs onto the same scale: every input receives

a number of points. The points of each factor in the model provide clarity on how important each input is relative to the

others.

3.3 | Fair Machine Learning

Fairness is a crucial property of risk scores. As such, the recidivism prediction problem is a key motivator for many of

these works. However, recidivism prediction is rarely the primary focus of fairness papers. Many of these papers seek to

make theoretical contributions by proposing deﬁnitions of fairness and creating algorithms to achieve these deﬁnitions,

using recidivism prediction as a case study [50, 51]. Others have proven fairness impossibility theorems, showing

when different fairness constraints cannot be achieved simultaneously. For instance, the two fairness deﬁnitions at the

heart of the debate over COMPAS’ fairness (calibration and balance for positive/negative class) cannot be achieved
simultaneously in nontrivial cases 5 [52, 53]. These theorems show that many fairness deﬁnitions directly conﬂict,

so there cannot be a single universal deﬁnition of fairness [52, 54, 55]. Moreover, there is often a trade-off between

performance and fairness [56, 57, 58]. The emerging consensus is that any decision about the “best” deﬁnition of

fairness must rely heavily on model characteristics and domain-speciﬁc expertise.

The question of what should count as fair in criminal recidivism prediction can be answered by discussion among

ethicists, judges, legislators, and stakeholders in the criminal justice system. Existing American anti-discrimination law

provides a general legal framework for addressing this question. Under Title VII of the Civil Rights Act of 1964, there are

two theories of liability: disparate impact and disparate treatment [59]. In this article, we use the deﬁnitions of fairness

5However, by placing relaxations on the conditions, the fairness deﬁnitions can be approximately satisﬁed simultaneously.


8

WANG & HAN ET AL.

from the ﬁeld of fair machine learning, as they apply directly to machine learning models and are more speciﬁc than the

general legal guidelines of disparate impact and treatment. Moreover, some of the deﬁnitions of fairness proposed by

the ﬁeld of fair machine learning community are inspired by these guidelines. See Corbett-Davies and Goel [60] for a

detailed discussion of the relationship between algorithmic deﬁnitions of fairness and economic/legal deﬁnitions of

discrimination.

4 | DATA

In this study, we used criminal history data sets from Broward County, Florida, and the state of Kentucky, allowing us to

analyze how models perform across regions. The Broward County data set consists of publicly available criminal history

and court data from Broward County, Florida. This data set consists of the full criminal history, probational history,

and demographic data for the 11,757 individuals who received COMPAS scores at the pretrial stage from 2013-2014

(as released by ProPublica [36]). The probational history was computed from public criminal records released by the

Broward Clerk’s Ofﬁce. Though the full data set includes 11,757 individuals, this analysis includes only the 1,954 for

which we could also compute the PSA. We processed the Broward data using the same methods as Rudin et al. [4]. From

the processed data, we computed various features such as number of prior arrests, prior charges, prior felonies, prior

misdemeanors, etc.

The Kentucky pretrial and criminal court data was provided by the Department of Shared Services, Research and

Statistics in Kentucky. The data came from two systems: the Pretrial Services Information Management System (PRIM)

and CourtNet. The PRIM data contain records regarding defendants, interviews, PRIM cases, bonds, etc., that were

connected with the pretrial service interviews conducted between July 1, 2009 and June 30, 2018. The data from

CourtNet provided further information about cases, charges, sentences, dispositions, etc. When constructing features

from the Kentucky data set, we computed features that were as similar as possible to the Broward features (e.g., prior

arrests, prior charges with different types of crimes, age at current charge) in order to compare models between the

two regions. There are several features from Broward data which could not be computed from the Kentucky data, such

as “age at ﬁrst offense” and “prior juvenile charges”. A limitation of the Kentucky data set is that the policies governing

risk assessments changed over the period when the data was gathered, possibly impacting the consistency of the data

collection.

A difference in the data processing between the two data sets is that when constructing prediction features and

predictive labels, we considered non-convicted charges in the Broward data, but considered convicted charges in the

Kentucky data. The reason for this choice is sample size. The processed Broward data contains only 1,954 records, and

limiting the scope to convicted charges would yield only 1,297 records. The use of convicted versus non-convicted

charges between the two regions might explain some discrepancies in the results in Section 8, where we discuss the

generalization of recidivism prediction models between states. Note that many models currently implemented within

the justice system rely on non-convicted charges (for instance, counts of prior arrests), but for the applications such as

bail and parole, the use of non-convicted charges could be problematic—it holds individuals accountable for crimes that

they may not have committed. Please refer to the Appendix (Section 11) for more details on the data processing and a

full list of features for both data sets.


WANG & HAN ET AL.

5 | METHODOLOGY

9

Throughout our analysis, we compare with two tools that are currently used to predict recidivism in the U.S. justice

system: COMPAS (Correctional Offender Management Proﬁling for Alternative Sanctions) and the Arnold PSA (Public
Safety Assessment, created by Arnold Ventures6). Although we would have liked to compare against more assessment

tools, many of them use data that are not publicly available, or are owned by for-proﬁt companies that do not release

their models. For a detailed discussion of the other risk assessments we considered and the features we were missing,

please consult the Appendix (Section 11).

More speciﬁcally, we compared our models against the Arnold PSA’s New Criminal Activity (NCA) and New Violent

Criminal Activity (NVCA) scores on the general and violent recidivism problems, respectively. Note that the timeframes and labels for prediction are important here, and our choices distinguish this study from past works on recidivism

prediction. Let us explain the time-frames next.

It is important that we chose ﬁxed time-frames for prediction, in our case, two years or six months past the current

charge dates. In reality, the scores are used to assess risks during the pretrial period. However, there is a huge amount

of variation in pretrial periods, which can span a few days to a few years: the average pretrial time-span in Kentucky is

109 days, and could last upwards of 3-4 years. Since the pretrial period depends on the jurisdiction, we chose to ﬁx

time-spans (of six months and two years) so that the models do not depend on the policy used for determining how long

the pretrial period would be. That way, the risk calculations we produce depend mainly on the inherent characteristics

of the individual, rather than the length of the pretrial period (potentially a characteristic of the jurisdiction). Also, this

way, individuals with the same propensity to commit a new crime within six months (or two years depending on which

risk score) are given identical risk scores, even if they have different expected time periods until their respective trials.

The six-month time-span represents an approximate length of pretrial period. The two-year time-span provides more

balanced labels, since two years provides more time to commit crimes than six months. Additionally, our evaluation

metric is AUC, which is a rank-statistic, and considers relative risk rather than absolute risk; that is, an individual who

actually commits crimes within two years of their current charge date should be ranked higher than an individual who

does not. The relative risk within the two-year time-frame is related to the relative risk for other (shorter or longer)

time-frames, allowing these models to potentially generalize to varying pretrial time-frames.

Another important aspect of our prediction problems is the deﬁnition of recidivism we chose. We predict the

occurrence of a convicted charge within six months/two years for Kentucky. In other words, we would like to predict

whether someone will be arrested, within six month or two years from their current charge, for another crime that they

were later convicted for. This deﬁnition potentially alleviates a due process concern: if we instead include non-convicted

charges, our models might be more likely to predict who will be arrested than who will be convicted, which is tied to

policing practices. For Broward, where we did not have conviction information for later charges, we predicted any charge

within six months/two years, which is the typical approach to recidivism prediction.

In Broward, we directly computed Arnold PSA scores, as the Arnold PSA is publicly available. The features used

by the Arnold PSA are provided in Tables 16 & 17 in the Appendix. In Kentucky, we used the unscaled Arnold PSA
scores that came with the data set.7 We compared against COMPAS’ Risk of General Recidivism and Risk of Violent

Recidivism risk scores on the two-year general and two-year violent prediction problems, respectively (both models
are designed to predict recidivism within two years). The COMPAS suite is proprietary, but COMPAS General and

Violent scores were provided with the Broward County data set (we do not compare against COMPAS on the Kentucky

data set). The COMPAS General and COMPAS Violent scores appear to have been developed for a parole population

6previously named the Laura and John Arnold Foundation
7In Kentucky, Arnold PSA scores are reported to judges without scaling.


WANG & HAN ET AL.

10

decisions).

[15], but have been applied for pretrial decisions in Broward. In this study, we consider the COMPAS scores for the

outcomes they were actually applied for (pretrial decisions), rather than the outcomes they were developed for (parole

In Sections 6 and 7, we compare the performance of black-box and interpretable algorithms on the Broward

and Kentucky data sets. We caution readers against comparing an algorithm’s performance in Broward with its

performance in Kentucky. An algorithm’s differences in performance between the data sets could be attributed to the

many differences between the two regions. For instance, the Broward data set is at the county level while the Kentucky

data set is at the state level. As the Kentucky data is at the state level, it embeds diverse information about 120 counties

(e.g., demographics, legislation, culture, local policing practices). Thus, in Sections 6 and 7, the comparisons between

baseline models and interpretable models are conducted within each data set. In Section 8, we discus in detail the

regional differences between Broward County and Kentucky, and present a set of experiments that illustrate model

performance gaps resulting from these regional differences.

5.1 | Prediction Labels

In addition to two-year general recidivism and two-year violent recidivism—the two types of criminal recidivism
considered by COMPAS and the PSA—we computed recidivism prediction labels speciﬁc to various crime types, such as
property, drug related recidivism and recidivism with felony or misdemeanor level charges.8 Note that an individual
could have multiple positive labels, indicating that the newly committed crime involves multiple charge types. We

deﬁned recidivism as a recorded charge within a certain time frame. Out of all the possible recidivism prediction tasks

we considered, we selected the six most balanced: general, violent, drug, property, felony, and misdemeanor. To
investigate the effect of temporal scale on predictive performance, we generated these six tasks using the time windows

two-years and six-months after the current charge date (or release date, if the individual went to prison for their
current charge), for a total of twelve tasks. The summary of prediction tasks and the base rate of recidivism for each

task is provided in Table 1.

Kentucky

Broward

Labels

Two Year P (yi = 1) Six Month P (yi = 1) Two Year P (yi = 1) Six Month P (yi = 1) Explanation

20.4%

5.7 %

45.5%

21.8 %

General

Violent

Drug

Property

Felony

3.4%

8.7%

3.9%

9.6%

21.0%

9.3%

9.0%

17.6%

8.4%

4.0%

5.0 %

8.9 %

0.7%

2.0%

0.9%

2.4%

3.9%

yi = 1 if the defendant had any type of charge within two years (resp. six
months) from current charge date/release date

yi = 1 if the defendant had a violent charge within two years (resp. six
months) from current charge date/release date

yi = 1 if the defendant had a drug-related charge within two years (resp.
six months) from current charge date/release date

yi = 1 if the defendant had a property-related charge within two years
(resp. six months) from current charge date/release date

yi = 1 if the defendant had a felony-level charge within two years (resp. six
months) from current charge date/release date

yi = 1 if the defendant had a misdemeanor-level charge within two years
(resp. six months) from current charge date/release date

Misdemeanor

15.6%

27.2%

12.5 %

TA B L E 1 Label distributions for Broward and Kentucky.

8For clarity, we apply the typewrite font to indicate the prediction tasks.


WANG & HAN ET AL.

5.2 | Problem Setup

11

Due to the binary nature of recidivism tasks, we approached these prediction problems as binary classiﬁcation problems,

but do not binarize the ﬁnal predicted probabilities/scores of the machine learning models for the following reasons.

First, existing risk scores are usually nonbinary. For instance, the Arnold PSA’s unscaled New Criminal Activity (NCA)

score takes integer values from 0 through 13, while the COMPAS Risk of Recidivism and Risk of Violent Recidivism

scores take on integer values from 1 through 10 [15, 20]. Second, we want to create more nuanced risk scores both

by predicting highly-speciﬁc types of recidivism, (in addition to coarser categories like general recidivism), and by

presenting non-binary scores which reﬂect a range of risk values.

Since the predictions are nonbinary, we use Area Under the Curve (AUC) as our evaluation metric. This decision

also impacts the fairness metrics we assess, which we discuss in Section 9. We applied nested cross validation process

to train the models. Please refer to the Appendix (Section 11) for the details.

6 | BASELINE MACHINE LEARNING METHODS

To provide a basis of comparison for the interpretable models (presented in Section 7), we evaluated the performance of

six common, non-interpretable machine learning methods in this section. We present the baseline prediction results for

Broward and Kentucky in Tables 7 and 8 respectively. Baseline models and descriptions are provided below. The tuned

hyperparameters and packages used for each problem are provided in the Appendix (Section 11).

•

•

•

•

•

(cid:96)2 Penalized Logistic Regression: To prevent over-ﬁtting, there is an (cid:96)2 penalty term on the sum of squared
coefﬁcients in the loss function for logistic regression. Although this method produces linear models, we consider

(cid:96)2-penalized logistic regression to be non-interpretable because if the number of input features is large, there could
be a large number of nonzero terms in the model.

(cid:96)1 Penalized Logistic Regression: To prevent over-ﬁtting, there is an (cid:96)1 penalty term on the sum of absolute values
of coefﬁcients in the loss function for logistic regression. This algorithm creates sparser models than (cid:96)2 penalized
logistic regression. Notice that the sparsity of the model depends on the magnitude of the penalty and must be

balanced with consideration of prediction performance. In our experiments, (cid:96)1 models with Broward data were
sparse yet maintained good predictive performances. However, the best (cid:96)1 models with Kentucky data still had
too many features, which made it difﬁcult to interpret the results. Therefore, we classiﬁed (cid:96)1-penalized logistic
regression as a non-interpretable algorithm.

SVM with a Linear Kernel [61]: An algorithm that outputs a hyperplane that separates two classes by maximizing

the sum of margins between the hyperplane and all points. Incorrectly classiﬁed points are penalized. Although

SVM with linear kernel yields a linear model, the concerns with (cid:96)1 and (cid:96)2 penalized logistic regressions apply here
as well: the number of nonzero terms could be large, making it difﬁcult to interpret the model.

Random Forest [62]: An ensemble method that combines the predictions of multiple decision trees, each of which

is trained on a bootstrap sample of the data. The implementation we use combines individual trees by averaging

the probabilistic prediction of each tree. Random Forest is usually considered a black-box classiﬁer because it is

difﬁcult to understand the individual contribution of each feature (which can be found in many trees), and the joint

relationship between features.

Boosted Decision Trees [63]: An ensemble method where a sequence of weak classiﬁers (decision trees) are ﬁt to

weighted versions of the data. Similar to random forest, boosted decision trees produce black-box models because

it is difﬁcult to understand the joint relationships of the features. We use the XGBoost implementation [64].


12

WANG & HAN ET AL.

Major Findings: We found that all baseline machine learning algorithms performed similarly across recidivism

problems for the Kentucky data set. We also found that models performed better on the six-month prediction problems

than on the two-year problems on Kentucky data, but not on Broward data. These ﬁndings will be discussed throughout

the following subsections.

6.1 | Broward Baseline Results

Table 7 in the Appendix contains the performance of baseline algorithms on the Broward data; the results are visualized

in Figure 1 (presented below). We noticed that no algorithm consistently performs better than the others. Simple linear

models can even outperform black-box models in some prediction problems. For instance, in the two-year prediction

problems, (cid:96)2-penalized logistic regression and LinearSVM tie in performance for the general recidivism prediction.
XGBoost performs the best in violent and property prediction problems. (cid:96)1-penalized logistic regression has the best
performance in drug and felony prediction tasks, while (cid:96)2-penalized logistic regression has the best performance in
misdemeanor recidivism prediction. The largest performance gap is 5.1%, from property recidivism prediction.

In the six month prediction problems, we see the same phenomenon that no single model dominates the others

in performance. Overall, the performance gaps across baseline models for the general, felony, and misdemeanor
prediction tasks are small, while other prediction problems have larger gaps.

F I G U R E 1 Visualizations of Broward baseline results from Table 7 in the Appendix. Within each prediction problem,
all algorithms performed similarly. No single algorithm consistently outperformed others.

6.2 | Kentucky Baseline Results

In Kentucky, complex and nonlinear baselines perform slightly better than linear models (see Table 8 in the Appendix

and Figure 4, which is presented below), potentially due to the larger size of the Kentucky data set (1,956 records in

Broward county versus 250K records in Kentucky). In particular, Random Forest and XGBoost uniformly perform

slightly better than all the other algorithms on all prediction tasks, over both time periods we examined. XGBoost

performs the best on all tasks. However, performance gaps, across all prediction problems and in both time frames, are

very small. Thus, we conclude that all the baseline algorithms perform similarly over the Kentucky data set . One thing

we noticed from the Kentucky results is that all algorithms perform slightly better on the six-month recidivism period


WANG & HAN ET AL.

than on the two-year period.

13

F I G U R E 2 Visualizations of Kentucky baseline results from Table 8 in the Appendix. Random Forest and XGBoost
consistently perform better than other models, but the results are similar across all models.

7 |

INTERPRETABLE MACHINE LEARNING METHODS

For recidivism prediction, we considered several different types of interpretable machine learning methods with

different levels of interpretability, ranging from scoring systems to decision trees, to additive models. Since the Burgess

model in 1928 [65], recidivism risk assessments have traditionally been scoring systems, which are sparse linear models

with positive integer coefﬁcients. A scoring system can be visualized as a simple scoring table or set of ﬁgures. There

have only recently been algorithms designed to optimally learn scoring systems directly from data, without manual

feature selection or rounding. Scoring systems have several advantages: they allow an understanding of how variables

act jointly to form the prediction; they are understandable by non-experts; risks can be computed without a calculator;

and they are consistent with the form of model that criminologists have built over the last century, where “points” are

given to the individual, and the total points are transformed into a risk of recidivism. Further, outside information (such

as risk factors that are not in any database) can be more easily incorporated into the risk score: it is much easier to

determine how many points to assign to a new factor if the points are integer-valued for the known risk factors (e.g., we

could choose to subtract three points for drug treatment, to counteract four points of past drug-related arrests).

While scoring systems appear to be the accepted standard for interpretability in the domain of criminal justice,

imposing the constraints of linearity, sparsity, and integrality of coefﬁcients could potentially be strong enough to reduce

accuracy. Thus, we also consider modern algorithms that satisfy a subset of the conditions of interpretability (sparsity in

features, ability to visualize/explain any variable interactions, linearity, integer coefﬁcients). Speciﬁcally, we tested four

interpretable machine learning algorithms: Classiﬁcation and Regression Trees (CART), Explainable Boosting Machine

(EBM), Additive Stumps, and RiskSLIM (Risk-Calibrated Supersparse Linear Integer Models). Algorithm speciﬁcs are

articulated below and the tested hyperparameters are provided in the Appendix (Section 11). We also tested two

existing risk assessments—the Arnold PSA and COMPAS—and compared their performances to both baseline and

interpretable machine learning models.

•

Classiﬁcation and Regression Trees (CART) [62]: A method to create decision trees by continuously splitting input


WANG & HAN ET AL.

14

•

•

features on certain values until a stopping criterion is satisﬁed. CART constructs binary trees using the feature

and threshold that yields the largest information gain at each node. We constrain the maximum depth of the tree

to ensure that it does not use too many features. CART models are nonlinear. They cannot be written as scoring

systems, but can be written as logical models.

Explainable Boosting Machine (EBM) [12]: An algorithm that uses boosting to train Generalized Additive Models
with a few interaction terms (GA2Ms). The contribution by each feature and feature interaction pair can be

visualized. The models are interpretable and modular, thus editable by experts. The models are generally not sparse,

and cannot be written as scoring systems.

RiskSLIM [66]: An algorithm that generates sparse linear models with integer coefﬁcients that have risk-calibrated

probabilities. The models generated by RiskSLIM have form similar to that of models used in criminal justice over

the last century.

• Additive Stumps: An interpretable variation on (cid:96)1-penalized logistic regression: for each feature, we generate
multiple binary stumps (this pre-processing technique is discussed further in the next section), and apply (cid:96)1penalized logistic regression to these stumps. Ideally, the features will have monotonically increasing (or decreasing)

contributions to the estimated probability of recidivism. Models constructed using this method generally use

fewer features than those constructed with vanilla (cid:96)1-penalized logistic regression. These models are ﬂexible and
nonlinear. These models also cannot be written as scoring systems because they are not sparse in the number of

nonlinearities.

• Arnold PSA [20]: A widely-used, publicly available, interpretable risk assessment system that consists of three
scores: New Criminal Activity (NCA), New Violent Criminal Activity (NVCA), and Failure to Appear (FTA). We

compare against the NCA for the general recidivism problem, and against the NVCA for the violent recidivism
problem, on both two-year and six-month time scales. The NCA has 7 factors, while the NVCA has 5 factors.

•

COMPAS [15]: A widely-used risk assessment system that consists of several scores, including the three that we

study: Risk of General Recidivism (COMPAS General), Risk of Violent Recidivism (COMPAS Violent), and Risk of

Failure to Appear. We compare against the COMPAS General score for the two-year general recidivism problem,
and compare against the COMPAS Violent score for the two-year violent problem.

Major Findings: Overall, the best interpretable models performed approximately as well as the best black-box models

on both regions and both prediction time periods we considered.

7.1 | Pre-processing Features into Binary Stumps

We performed a data pre-processing technique for two of the interpretable machine learning algorithms: RiskSLIM and

Additive Stumps. This technique consists of transforming all original features into binary stumps (dummy variables)

using Equation 1. Pre-processing the features into stumps allows us to include nonlinear interactions between the

features (e.g. age, criminal history) and labels. It also allows us to visualize each Additive Stumps model as a set of

monotonically increasing (or decreasing) curves.

Formally, stumps are binary indicators, which are created by splitting features at pre-speciﬁed thresholds. For a

feature X (j ), and a set of threshold values K ∈ (cid:210), we generate decreasing stumps S (j )
k

for all k ∈ K as follows:

k = 
S (j )


1,

for X (j ) ≤ k

0, else

(1)


WANG & HAN ET AL.

15

We can generate increasing stumps analogously by substituting ≥ for ≤ in the deﬁnition above. The rationale behind
the naming convention is as follows. Linear models constructed from increasing (respectively, decreasing) stumps

have the nice property that if one sums the contribution from all stumps corresponding to a ﬁxed original feature
for the feature X (j )), and the coefﬁcients ck are mostly non-negative 9, the resulting function
(i.e., f (X (j )) = (cid:205)
k ∈K

ck S (j )
k

f (X (j )) is monotonically increasing (respectively decreasing), which is desirable for interpretability.

More concretely, the “age_at_current_charge” feature ranges from 18 to 70 in our data. For all age-related features,

we construct decreasing stumps for k = {18, 19, ..., , 60}. We chose decreasing stumps for age features because based
on past studies [e.g., 4, 67] and criminological theory [16, 68, 69] , the probability of recidivism decreases with age. On

the other hand, intuitively, the probability of recidivism should increase as criminal history increases. Thus, we construct

increasing stumps for the remaining features (which relate to criminal history).

To select a collection of stumps for the RiskSLIM and Additive Stumps model, we selected threshold values for all

features by examining each feature visualization from EBM and choosing the threshold values that correspond to sharp

drops in the predicted scores.

7.2 | Broward Prediction Results for Interpretable Models

Table 9 in the Appendix and Figure 3 show the results of interpretable models on the Broward data set. For all prediction

problems in both two-year and six-month prediction periods that we examined, we observed that CART consistently

performed worse than other algorithms. Additive Stumps and EBM performed similarly on all the prediction tasks and

outperformed other models, including the Arnold PSA and COMPAS, on most of the prediction tasks.

The performances of the best interpretable models are very similar to that of the best baseline models—this is true

for each of the prediction problems we considered. The AUC gaps between the best interpretable models and best

baseline models for all two-year prediction tasks range from 0.3% to 1.7% in absolute value, and range from 0.2% to

2.6% for six-month prediction tasks. The two maximum prediction gaps, 1.7% and 2.6%, both come from drug recidivism
prediction tasks. Prediction gaps from all other problems are smaller than 1%.

F I G U R E 3 Broward interpretable model results.

9For decreasing (respectively increasing) stumps, if the coefﬁcient for the largest (respectively smallest) stump is negative, the function f will still be monotonic
because the negative value will be subtracted from all values of the remaining stumps


16

WANG & HAN ET AL.

7.3 | Kentucky Prediction Results for Interpretable Models

The Kentucky prediction results are provided in Table 10 in the Appendix, and visualized in Figure 4. For all prediction

problems in both time frames we considered, CART, EBM, and Additive Stumps all had similar performances. RiskSLIM

had relatively lower results compared to other interpretable models. All interpretable models performed better than

the Arnold PSA, with the exception that the Arnold PSA performed slightly better (0.3%) than RiskSLIM on two-year

general recidivism. Once more, we observed that the best interpretable models can perform approximately as well as
the best black-box models (XGBoost). For the two-year prediction tasks, the differences in performance between the

best interpretable and the best black-box models ranged from 0.7% to 0.9% in absolute value; for six-month problems,

the difference ranged from 0.4% to 1.5%.

F I G U R E 4 Kentucky interpretable model results.

Summary of Interpretable Models’ Results: We found that the best interpretable models performed approxi
mately as well as the best black-box models, on both data sets and both time periods we considered, which is consistent

with previous studies on other data sets [10]. The best interpretable models possess the advantage of being transparent

and interpretable, allowing judges and defendants a better understanding of the predictions that the model outputs.

7.4 | Tables and Visualizations of Interpretable Models

Each of the interpretable machine learning methods produces models that can be visualized, either as a decision tree

(CART), scoring table (RiskSLIM), or as a set of visualizations (EBM, Additive Stumps). In this section, we present these

tables and visualizations for EBM, Additive Stumps and RiskSLIM, to give a clearer understanding of each model’s

interpretability. Here we used the two-year general recidivism prediction problem on Kentucky data as an example.

7.4.1 | EBM Models

The EBM package provides visualizations for each feature in the data set along with a bar chart of feature importance,

both of which are displayed in an interactive dashboard. The dashboard allows users (potentially judges) to see the

scores corresponding to each bar or line by hovering the mouse over it. EBM models are not sparse in the number of

features, so there could be visualizations for all features. Here, we show screenshots of the bar chart and visualizations


WANG & HAN ET AL.

17

for the three most important features. EBM visualizations are similar to those from Additive Stumps, in that each

feature’s contribution to the score can be displayed separately. However, EBM scores do not tend to be monotonically

increasing or decreasing in each feature.

F I G U R E 5 Visualizations from EBM on two-year general recidivism. Top left: overall importance of each feature,
ranked from the most important variable to least important. Remaining three: visualization for the contribution of the
feature to the overall score (top) and histograms of feature values to show the distribution (bottom). Features
contributions are visualized as bar charts if the feature takes binary value. The shaded grey area represents the
conﬁdence region. We see that as values get larger, there is more uncertainty in the predictions, which may be because
we have fewer data points for such large feature values.

7.4.2 | Additive Stumps

Additive Stumps models are constructed by thresholding the original features, such as age or criminal history, into binary

stumps, followed by running (cid:96)1-penalized logistic regression on the stumps. Choosing an appropriate regularization
value for (cid:96)1-penalized logistic regression can give us a model that is sparse in the number of original features—despite
the fact that the regularization is directly on the stumps, not on the original features. For the Kentucky two-year

general recidivism problem, the ﬁnal model contains 28 stumps plus an intercept. These stumps are rooted under
only 14 original features. Visualizations of the contributions for these 14 features are presented in Figure 6. Table 11,

containing a scoring table that includes all 28 stumps plus an intercept, is provided in the Appendix (Section 11).


18

WANG & HAN ET AL.

F I G U R E 6 Visualizations of the total contribution for each of the original features in the Additive Stumps model on
two-year general recidivism. The contribution from each stump feature is the estimated coefﬁcient from (cid:96)1-penalized
logistic regression.

7.4.3 | RiskSLIM

RiskSLIM produces scoring tables with coefﬁcients optimized to be integers (“points”), which makes the predictions

easier to calculate and interpret for users, such as judges. The total points are translated into probabilities using the

logistic function provided at the top of the table. By examining a RiskSLIM model, users can easily identify which

features contribute to the ﬁnal score and by how much. We provide scoring tables in Table 2 for two-year general
recidivism prediction on both Broward and Kentucky data sets. More tables are provided in the Appendix (Section 11).

We noticed that for each prediction problem, almost all ﬁve of the cross validation folds for the RiskSLIM algorithm

yielded the same model on the (larger) Kentucky data set. In more detail, for Kentucky two-year drug and violent
recidivism prediction problems, all ﬁve RiskSLIM models produced during cross validation were identical. For the rest of

the prediction labels, four out of ﬁve cross validation models were the same. For the six-month recidivism prediction

problems, the misdemeanor prediction problem resulted in ﬁve identical RiskSLIM models, and the violent recidivism


WANG & HAN ET AL.

19

prediction problem had four models that were the same. The fact that the Kentucky RiskSLIM models are often the

same, despite being trained on different (albeit overlapping) subsets of data, suggests that they are robust to the exact

subsample used for training.

TA B L E 2 Two-year general recidivism RiskSLIM models for Broward (left) and Kentucky (right). Each feature is
given an integer point. The ﬁnal predicted probability is calculated by inputting the total score to the logistic function
provided on the top of the tables.

Broward

Kentucky

Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))

Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))

age at current charge ≤31

1 points

+...

number of prior arrest≥ 2

number of prior misdemeanor charges ≥4

1 points

number of prior arrest≥ 3

had charge(s) within last three years = Yes

1 points

number of prior arrest≥ 5

...

...

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= ....

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

8 | RECIDIVISM PREDICTION MODELS DO NOT GENERALIZE WELL ACROSS

REGIONS

It is common practice for recidivism prediction systems to be applied across states, or even countries, with only minor

tuning on local populations. Implicit in this practice is the assumption that models trained on data from one collection of

locations will perform well when used in another collection of locations—i.e., that models generalize across locations. For

instance, the Arnold PSA, which was developed on 1.5 million cases from approximately 300 U.S. jurisdictions, has been

adopted in the states of Arizona, Kentucky, New Jersey, and many large cities including Chicago, Houston, Phoenix, etc.

[20]. These systems have remained in place for years without any updates.

However, based on our experimental results, we conjecture that different locations would beneﬁt from specialized

models that conform to the speciﬁc aspects of each location. For instance, let us brieﬂy compare the state of Kentucky

and Broward County in Florida. The demographics are completely different: Kentucky is not a diverse state (87.8%

white, 7.8% black, and 4.4% other groups in 2019 [70]), whereas Broward County is more racially diverse (62.3%, white;

17.1% Hispanic or Latino; 12.2% black or African American; 5.07% Asian and other groups [71]. The geographies of

the locations are drastically different as well: Kentucky is an interior state located in the Upland South with a humid

subtropical climate, whereas Broward County is at the eastern edge of Florida with a tropical climate. Several studies

have indicated an association between climate (temperature, humidity, and precipitation) and crime [72, 73, 74]. There

are many other factors that differ between the locations that might affect the generalization of the recidivism prediction

models, such as different local prosecution practices, laws and the way they are administered, social service programs,

local cultures, educational systems, and judges’ views.

Because models tend to be used broadly across locations, in this section we aim to investigate how well predictive

models generalize between the two locations for which we have data. We trained models on Kentucky and tested on

Broward (and vice versa). We looked more closely at age, and examined how the joint probability distribution of age

and recidivism differs between Broward and Kentucky. We focused on age because of its important relationship to

recidivism [67, 69, 75].

Major Findings: Our analysis shows that models do not generalize well across regions, and the joint probability

distribution of age and recidivism varies across states. Therefore, we suggest that different models be constructed in


20

WANG & HAN ET AL.

different regions, and be updated periodically.

8.1 | Training on One Region and Testing on the Other

In order to construct models on one region and test them on the other, we only used the shared features from both

data sets. Nested cross validation was used to train both the models that were trained in one region and tested in the

other, and the models that were trained and tested in the same region. More details about this procedure can be found

in Section 11.7 in the Appendix. Table 12 and Table 14 in the Appendix respectively show the performance of models

trained on Kentucky and tested on Broward, and models trained on Broward and tested on Kentucky. Table 13 and

Table 15 respectively show the performance of models trained and tested on Broward, and models trained and tested

on Kentucky.

Comparing Table 12 with Table 13, we observed that there is an overall decrease in model performance when

models were trained in Kentucky and tested on Broward. For instance, for the two-year general recidivism problem,
the performances drop between 3.5% to 6.0% on the baseline models. A similar pattern can be observed for the

interpretable models. Conversely, when we trained models on Broward and tested on Kentucky, we observed even

larger performance decreases from the models trained and tested on only Kentucky (compare Table 14 to Table 15). For

the two-year general prediction task, performance gaps from baseline models range between 5.1% and 8.6%, while the
gaps range from 4.6% to 12.0% for interpretable models.

Through this experimentation, we concluded that for at least the twelve prediction problems in our setup, models

do not generalize across states. This could be attributable to differences in the joint probability distribution of features

and outcomes between locations. To understand the difference in these distributions more closely, we examine the age

feature.

8.2 | Age-Recidivism Probability Distributions by Region

Age has traditionally been a highly predictive factor for recidivism [67, 69, 75]. Therefore, differences in the age

distributions between two regions could signiﬁcantly impact a model’s ability to generalize between regions.

Consider the general recidivism problem as an example. In Kentucky, the probability of general recidivism for
both six-month and two-year prediction periods peaks for individuals aged around the early to mid 30s and then

decreases as age increases. In Broward County, the age distribution for the corresponding general recidivism problem
is substantially different. From Figure 7, the probabilities seem to peak around ages 18-29, and then decrease after

age 29. There are less data for higher ages, causing greater variance in the probabilities. For the violent recidivism
problem, please refer to Figure 11 in the Appendix (Section 11).

Additionally, there is a large gap in the probability magnitudes between the two regions. For instance, the probabili
ties of general recidivism from the Broward data set can exceed 0.5, while the probabilities of general recidivism from
Kentucky data are all less than 0.4. Thus, the populations of individuals from Broward and Kentucky who recidivate are

different with respect to age.

This difference is directly manifested in the interpretable models presented in Section 7.4. We found that the

selection of features differs between interpretable models trained on Broward and Kentucky data. For instance,

referring to the simple RiskSLIM models listed in Section 11.8 in the Appendix, which show the most important features

in each prediction problem, we noticed that with Broward data, almost all prediction problems contain at least one

age feature, either “age at current charge” or “age at ﬁrst offense.” This suggests that age is important in predicting

recidivism across different problems trained on the Broward data. However, none of the RiskSLIM models trained


WANG & HAN ET AL.

21

F I G U R E 7 Probability of recidivism v. age at current charge—general recidivism

on the Kentucky data set use age features. Almost all the models use “prior arrest” features, reﬂecting the fact that

Kentucky recidivism prediction problems rely more on prior criminal history information than on age.

9 | FAIRNESS

In this section, we conduct a technical discussion of a small fraction of the various fairness deﬁnitions that have emerged

recently, and an evaluation of how well the interpretable models satisfy them on the Kentucky data set. We ﬁrst describe

our rationale for selecting fairness deﬁnitions (calibration, balance for positive/negative class, and balanced group AUC).

Next, we evaluate how well the Arnold PSA, COMPAS, EBM (the best-performing interpretable models) and RiskSLIM

(the most interpretable and most constrained models) satisfy these deﬁnitions on the two-year general recidivism and
two-year violent recidivism problems in Kentucky. Finally, we discuss how current fairness-enforcement procedures
interact with interpretability.

Major Findings: Empirically, we found no egregious violations of the three fairness deﬁnitions (group calibration,

BPC/BNC, and BG-AUC) for both interpretable machine learning models we assessed (EBM and RiskSLIM) for the

two-year general recidivism problem on the Kentucky data set. We found that the Arnold NCA raw score violated one
of the fairness deﬁnitions (BPC/BNC). Overall, we observed a larger gap in fairness (for all three fairness measures we

examined) between the largest and smallest sensitive groups, than between black and white sensitive groups. We also

note that existing techniques to enforce fairness generally require non-interpretable transformations, and therefore do

not work well with interpretable models.

                      S U R E D E L O L W \ O R F D W L R Q     . < W Z R B \ H D U V L [ B P R Q W K                                                                                               D J H B D W B F X U U H Q W B F K D U J H                      S U R E D E L O L W \ O R F D W L R Q     ) / * H Q H U D O  5 H F L G L Y L V P
9.1 | Selection of Fairness Metrics: Calibration, Balance for Positive/Negative Class, Bal
anced Group AUC

As discussed in Section 5.2, we do not wish to consider binary risk scores in this study. This decision limits us to a much

smaller class of fairness deﬁnitions (e.g., statistical parity would not be relevant). Below, we summarize the deﬁnitions

that apply to regression that we do not consider and the reasons why:

WANG & HAN ET AL.

Fairness through unawareness states that a model should not use any sensitive features [55]. However, if there

are proxies for sensitive features present in the data set, the model can still learn an association between a sensitive

group and the outcome. Fairness through unawareness could be used if one decides that a proxy feature is

permissible to use (e.g., if one decided that age could be used, despite its correlation with race), but we do not

presume that this is what is desired for this application. Of course, if fairness through unawareness is desired, it is

easy to construct models that satisfy this deﬁnition.

Individual fairness intuitively requires that “similar” individuals are treated “similarly” by the model—individuals

with similar features should be given similar model scores. This type of fairness requires manually (and thus

subjectively) deﬁning a notion of similarity between individuals [76]. This type of subjective choice goes beyond the

scope of this paper.

Once we limited ourselves to real-valued outcomes and eliminated the above deﬁnitions, only a few deﬁnitions

remained. In a literature search for non-binary fairness deﬁnitions, we found the following: calibration, balance for

positive class/balance for negative class (BPC/BNC) and balanced group AUC (BG-AUC).

Below, G denotes a (categorical) sensitive attribute such as race, and gi denotes one of the sensitive groups in G (e.g.
African-American, Caucasian, and Hispanic, for the sensitive attribute of race). Y ∈ {0, 1} denotes the ground-truth
label (recidivism status) and S denotes the predicted score from a model.

Calibration: We consider two notions of calibration. The ﬁrst, group calibration, requires that for all predicted

scores, the fraction of positive labels is the same across all groups. Mathematically, group calibration over the

sensitive attribute G requires:

P (Y = 1|S = s, G = gi ) = P (Y = 1|S = s, G = gj ), (cid:91)i , j

where s is the given value of a risk score.10 In practice, it is common to bin the score S if there are many possible
values. The second, monotonic calibration, requires that if s1 < s2, then P (Y = 1|S = s1) < P (Y = 1|S = s2). 11
These types of calibration are of particular concern to designers of current recidivism risk models. Group calibration

means that a risk score holds the same “meaning” for each race. Monotonic calibration means that if the score

increases, the risk also increases. These notions are important because human decision-makers expect risk scores

to have these intuitive properties (but not all algorithms produce calibrated models) [77].

Balance for Positive Class (BPC) requires that for all individuals with a positive label, the expected values of the

22

•

•

•

•

10In the case where scores are binary, group calibration is equivalent to requiring conditional use accuracy equality.
11We note that a real-valued score S between 0 and 1 is well-calibrated if P (Y = 1|S = s) = s . Well-calibration says that the predicted probability of recidivism should be the same as the true probability of recidivism [55]. Although well-calibration is the deﬁnition of calibration that is standard in the statistics

community, we consider monotonic-calibration here because any score that is monotonically-calibrated can be transformed to be well-calibrated.


WANG & HAN ET AL.

23

predicted scores are the same across groups. Mathematically, a risk score S satisﬁes BPC if:

E [S |Y = 1, G = gi ] = E [S |Y = 1, G = gj ], (cid:91)i , j .

Similarly, a risk score S satisﬁes Balance for Negative Class (BNC) if:

E [S |Y = 0, G = gi ] = E [S |Y = 0, G = gj ], (cid:91)i , j .

BPC and BNC differ only in the labelY .12 Intuitively, BPC means that the average score for recidivists is the same in
each group, while BNC means that the average score for non-recidivists is the same in each sensitive group.

BPC/BNC is an intuitive notion of fairness, which says that it is permissible to give consistently higher (respectively

lower) scores to individuals who truly belong to the positive (respectively negative) class. However, BPC/BNC

limits the set of attributes where it is permissible to “discriminate” between individuals, to the label Y . Suppose
the count of prior offenses is an important feature for a recidivism prediction model—higher prior counts lead

to higher scores. This is a reasonable model assumption because a higher prior count is correlated with higher

recidivism rates. If on average, African-Americans have higher prior counts than Caucasians, the model will not

satisfy BPC/BNC. For a model to satisfy BPC/BNC, it must give the same average score to individuals from a certain

race and with a certain recidivism label, regardless of distributional differences in prior counts. Those who believe

that prior counts and arrests are racially biased against African-Americans might ﬁnd this a desirable property of

a fairness deﬁnition. On the other hand, those who ﬁnd this undesirable can ﬁx this by conditioning on the prior

counts attribute as well.

•

Balanced Group AUC (BG-AUC) requires that the AUC of the risk score is the same for each sensitive group. This

deﬁnition is our adaptation of overall accuracy equality [56], which asks that the score’s accuracy is the same for

each sensitive group. Our risk scores are not binary so we do not assess accuracy in this work, but assessing the

AUC for each group is the natural analog.

Sensitive attributes: The two sensitive attributes that are available in the Kentucky data sets are race and gender.

In the Kentucky data set, all individuals are partitioned into Caucasian, African-American, Indian, Asian, and
Other, but we group the Indian and Asian attributes into Other because there are very few individuals with these
attributes. See Table 19 for the distribution of sensitive attributes in Kentucky. The Kentucky data set also partitions

individuals into the genders Female and Male. To summarize,

races in Kentucky = {Caucasian, African-American, Other}

sexes in Kentucky = {Female, Male}.

We remark that the binary versions of calibration and BPC/BNC deﬁnitions conﬂicted during the COMPAS scandal.

Investigative journalists from ProPublica found that COMPAS had a higher false negative rate for Caucasians and a
higher false positive rate for African-Americans.13 In response, however, Northpointe claimed that COMPAS scores

were calibrated.

Kleinberg et al.’s [52] impossibility theorem demonstrated that the conﬂict between calibration and BPC/BNC holds

in general. In particular, they show that if a model does not satisfy either of the two trivial cases—a model that always

12In the binary case, BPC/BNC is equivalent to equalized odds [50], which requires that false positive rates and false negative rates are equal for each group.
13To determine false negative/positive rates, ProPublica binned COMPAS scores into binary scores,


24

WANG & HAN ET AL.

makes perfect predictions, or a data set where the base rates of recidivism are equal for each sensitive group—then the

model cannot satisfy all three fairness deﬁnitions simultaneously. However, a relaxed version of the theorem states

that, if either of the two conditions approximately hold (approximately perfect predictions, or approximately equal base

rates), then the three fairness deﬁnitions can be approximately satisﬁed at the same time.

Figure 10 in the Appendix shows that the base rates for all sensitive attributes under each prediction problem on

the Kentucky data. We noticed that for the two-year general and violent recidivism problems, the base rates are
similar to each other (less than 3% in differences) across gender and race categories (except for “Other”). Given the

relaxed version of the impossibility theorem, together with the relaxed criteria of the 3% difference we considered, we

expect that the three fairness deﬁnitions can all be approximately satisﬁed.

9.2 | Fairness Results

We assessed model fairness only on the Kentucky data because the Broward data has a limited sample size, potentially

making the fairness results unreliable. (We attempted the evaluation on Broward data, but conditioning on race/gender

and the true label/score in the Broward data led to subgroups that were too small, and therefore noisy results.) We

compared the interpretable models, EBM and RiskSLIM, to the Arnold PSA on Kentucky. EBM has the best performance

on most of the prediction problems on the Kentucky data set. RiskSLIM performs relatively worse, but is considerably

simpler as there are no more than ﬁve features in each model, coefﬁcients are integers, and the model is linear.

We evaluated the two-year general and two-year violent problems, as they are the primary problems that the
Arnold PSA is used for. For the two-year general problem, we evaluated the unscaled Arnold New Criminal Activity
(NCA) score; for the two-year violent problem, we assessed the unscaled Arnold New Violent Criminal Activity (NVCA)
score. Although Arnold Ventures provides a table to scale the Arnold scores, in Kentucky, judges are presented with the

unscaled scores along with a categorization of the scores as low, medium, and high risk. Results for two-year general
recidivism are presented directly in this section; results for two-year violent recidivism can be found in the Appendix.

Note that each of the fairness conditions implicitly has a threshold parameter. For instance, the fairness condition

BPC is strictly satisﬁed if the mean scores between multiple groups are “equal” to each other. However, whether two

numbers are approximately equal is subjective and requires a threshold. So one must always issue a disclaimer when

stating that any of these fairness conditions are satisﬁed. Hence we remark that subjective thresholds were used to

determine whether fairness conditions were approximately satisﬁed in what follows.

| Calibration

As Figure 8 shows, the Arnold NCA raw score does not satisfy monotonic calibration for race or gender groups. The

score approximately satisﬁes group calibration for race (excluding the “Other” group) for all score values except for

13, and approximately satisﬁes group calibration for gender for all score values less than 11. The reason why higher

Arnold NCA raw scores fail the calibration deﬁnitions may be that there are few individuals with higher scores in

the data set , thus making the results less stable. Interestingly, we found that the scaled version of Arnold NCA fully

satisﬁed monotonic and group calibration, but had slightly worse predictive performance. EBM and RiskSLIM both

satisfy monotonic calibration and group calibration for all gender and race groups (excluding the “Other” group).


WANG & HAN ET AL.

25

(a) For the Arnold NCA raw score, none of the curves are mono
tonically increasing—violating monotonic calibration. Cali
bration curves for the Caucasian and African-American race

groups lie close to each other (except for the score 13), ap
proximately satisfying group calibration. Curves for the male

and female groups lie close to each other, but diverge for

scores greater than 10, indicating that the score satisﬁes

group calibration for gender for scores less than or equal to

10.

(b) For EBM, except for the “Other” group, the calibration

curves are monotonically increasing and approximately

equal to each other (satisfying monotonic calibration and

group calibration).

(c) For RiskSLIM, the domain of the graph goes up to only 0.3 −
0.4 (unlike the other graphs). The curves are monotonically
increasing and overlap with each other with the “Other” cat
egory being lower than all the other ones. Thus, RiskSLIM

is approximately group calibrated and monotonically cali
brated.

F I G U R E 8 Calibration results for the Arnold NCA raw, EBM and RiskSLIM for two-year general recidivism on
Kentucky.

0.02.55.07.510.012.5Arnold NCA Raw Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of Arnold NCA Raw on general_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale0.0-0.10.1-0.20.2-0.30.3-0.40.4-0.50.5-0.60.6-0.70.7-0.80.8-0.90.9-1.0EBM Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of EBM on general_two_year in Kentucky0.0-0.10.1-0.20.2-0.30.3-0.40.4-0.50.5-0.60.6-0.70.7-0.80.8-0.90.9-1.0RiskSLIM Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of RiskSLIM on general_two_year in Kentucky
26

WANG & HAN ET AL.

| Balance for Positive/Negative Class (BPC/BNC)

For models that provide risk probabilities as output (namely EBM and RiskSLIM models), we apply a 3% rule to determine

whether BPC and BNC conditions are satisﬁed. The unscaled Arnold NCA produces scores between 0 and 13 rather

than probabilities, so we use a 0.4 difference threshold to determine whether BPC and BNC are satisﬁed. That is, if the

difference in scores between the two groups is greater than the threshold, then we conclude that the model violates

BPC/BNC. All conclusions we present below exclude the “Other” race group, because of its small sample size.

Figure 9(a) displays the BPC/BNC results for the Arnold NCA raw, and shows that Arnold NCA satisﬁes neither

BNC nor BPC on gender or race groups. Figures 9(b) shows that EBM satisﬁes both BPC and BNC on race groups. EBM

also satisﬁes BNC, but not BPC, on gender groups. Figure 9(c) displays the results for RiskSLIM, which satisﬁes both

BPC and BNC on race and gender groups.

| Balanced Group AUC (BG-AUC)

We determine whether the models satisfy BG-AUC using a 3% rule. In Kentucky, AUC values are stable across sensitive

attributes for all models, satisfying BG-AUC for both gender and race. The discrepancies in AUC between African
Americans and Caucasians range from 0.3% (RiskSLIM) to 2.1% (Arnold NCA raw). The range gets smaller for gender

groups, lying between 0.5% (Arnold NCA) to 1.3% (RiskSLIM). Hence, we found that the Arnold NCA raw, EBM and

RiskSLIM all satisfy Balanced Group AUC for the race (excluding the “Other” group) and gender groups.

TA B L E 3 AUCs of the Arnold NCA Raw, EBM and RiskSLIM on Kentucky, conditioned on sensitive attributes. AUC
ranges are given for each sensitive attribute.

Kentucky

Race

Sex

Model

Label

Afr-Am.

Cauc.

Other Race

race_range

Female

Male

sex_range

Arnold NCA Raw

general_two_year

0.692

0.713

0.653

0.059

0.714

0.709

0.005

EBM

general_two_year

0.742

0.751

0.696

0.055

0.745

0.753

0.008

RiskSLIM

general_two_year

0.705

0.708

0.620

0.088

0.699

0.712

0.013

Summary of Fairness Results: For the two-year general recidivism problem on the Kentucky data set, we found
no egregious violations of the three fairness deﬁnitions (group calibration, BPC/BNC, and BG-AUC) for either of the

interpretable machine learning models we assessed (EBM and RiskSLIM), but we did ﬁnd small violations. We found the

Arnold NCA raw score violated one of the fairness deﬁnitions (BPC/BNC).

In more detail, we found that balanced group AUC were approximately satisﬁed for all three models with respect

to both gender and race groups (except for “Other”). With respect to calibration, both EBM and RiskSLIM satisﬁed

monotonic and group calibration on both gender and race groups (except for the “Other”). Arnold PSA approximately

satisﬁed group calibration on race (excluding risk score 13) and gender groups for scores less than 11. Additionally, EBM

satisﬁed both BPC and BNC on race categories, while it only satisﬁed BNC on gender categories. RiskSLIM satisﬁed

both deﬁnitions on both sensitive attributes. The Arnold NCA satisﬁed neither BPC nor BNC on race and gender groups.

A caveat is that we limited the discussion of the race groups to Caucasians and African-Americans—otherwise the

“Other” group would have caused all models to fail all deﬁnitions of fairness (calibration curves for the “Other” group are

signiﬁcantly beneath curves for other groups, average predicted scores vary substantially from the other groups, and

prediction AUC is signiﬁcantly lower for the “Other” group). This may be because we have the least data for the “Other”


WANG & HAN ET AL.

27

(a) Differences in expected scores for African-Americans

and Caucasians are greater than the threshold (0.4):

0.79 (race, negative class), 0.61 (race, positive class).

Differences in expected scores for gender are also

greater than the threshold: 0.7 (gender, negative

class) and 0.84 (gender, positive class).

(b) Differences in expected scores for African-Americans

(c) Difference in expected scores for African-Americans and

and Caucasians are less than 0.03: 0.01 (race, negative

Caucasians are less than .03: 0.01 (race, negative class),

class), 0.01 (race, positive class). Differences in expected

0 (race, positive class). Differences in expected prob
scores for gender satisfy the threshold in negative class

abilities for the male and female groups are less than

but not positive class: 0.01 (gender, negative class), 0.04

0.03: 0.00 (gender, negative class), 0.02 (gender, positive

(gender, positive class).

class).

F I G U R E 9 Balance for Positive and Negative Class for the Arnold NCA raw score, EBM and RiskSLIM on the
two-year general prediction problem in Kentucky. Red line indicates the maximum value output by models.

general_bncgeneral_bpc0.02.55.07.510.012.5E(Arnold | Attr = attr, Y = i)3.745.682.955.071.833.392.574.573.275.41BPC/BNC for Arnold on general_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMalegeneral_bncgeneral_bpc0.00.20.40.60.81.0E(EBM | Attr = attr, Y = i)0.090.280.080.270.030.120.070.240.080.28BPC/BNC for EBM on general_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMalegeneral_bncgeneral_bpc0.00.20.40.60.81.0E(RiskSLIM | Attr = attr, Y = i)0.20.350.190.350.140.220.190.330.190.35BPC/BNC for RiskSLIM on general_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMale
28

WANG & HAN ET AL.

race group, which is only 2.49% of the total sample. To ensure fairness, it is important that comparable amounts of data

are gathered for each sensitive group when possible. However, in non-diverse states such as Kentucky, there may not

be enough individuals in minority groups to create a large enough statistical sample.

9.3 | A Discussion on the Interaction between Fairness and Interpretability

There are signiﬁcant hurdles to using current fairness techniques with interpretable models. Moreover, the vast

majority of the work on fairness has focused on the binary classiﬁcation case. Thus, few deﬁnitions of fairness (let alone

algorithms) work for problems where predictions are nonbinary.

We did not attempt to use fairness-enforcement techniques because many fairness techniques require a non
interpretable transformation (further discussed below). Once these transformations are made, there is no way to correct

them to produce an interpretable model afterwards. There are generally three approaches to fairness algorithms: pre
processing of features [78], altering the training loss function [79, 80], and post-processing of predictions [50, 51, 53].

The pre-processing steps are generally complicated transformations of the input features, which shreds the data’s

natural meaning. Similarly, post-processing approaches either transform the predictions in some way, performing

“fairness corrections” [53] (which are non-interpretable), or require threshold selection, which is contrary to our goals of

providing non-binary risk assessments [50]. The approaches to modify training loss functions are the most promising,

but model optimization for both fairness and interpretability constraints would require new algorithms and is beyond

the scope of this work.

probability estimation.

In problems where fairness is a signiﬁcant concern, machine learning outputs are likely to be used as decision tools

rather than decision-makers, so it is surprising that so little work has thoroughly examined fairness for regression or

10 | DISCUSSION AND FUTURE WORK

From this analysis, we conclude that the interpretable models can indeed perform approximately as well as the black-box

models in various recidivism prediction problems, and much can be gained in interpretability for small sacriﬁces in

accuracy. On the Broward data set, we found that RiskSLIM, EBM, and Additive Stumps perform as well or better than

the best black-box models. On the Kentucky data set, we observed that EBM and Additive Stumps have extremely close

performance to the best black-box models—Random Forest and XGBoost— with average AUC differences around 1%,

which is less than the uncertainty gap.

We observed that machine learning models for six-month outcomes generally outperform those for two-year

outcomes (conditioning on the recidivism type). This may be because treatment/rehabilitation programs have a greater

chance of taking effect over a two-year time span (as compared to the six-month time span), altering the probability of

recidivism. Future work could investigate this hypothesis, or pose other hypotheses to explain this observation.

We also observed that machine learning models do not generalize well across states, perhaps due to differences

in the feature distributions between regions—in particular, we observed that the age distributions for Kentucky and

Broward County are considerably different. One might easily imagine regional feature distributions shifting over time

as well, which is supported by several studies [17, 81, 82, 83]. Even though these studies focused on disparate crime

types, they consistently observed a drop in the rate of offending among younger people since the 1990s. Studies have

explicitly shown that the distributions of age versus arrest rate has changed over time as well. For instance, Kim et al.

[17] has reported that in the state of New York, the mean age of the total arrested population increased by two years


WANG & HAN ET AL.

29

between 1990 and 2010. They hypothesized that a decrease in arrests in younger people and an increase in arrests in

older people together contributed to the increase in mean age.

There are many reasons why data would change over time and over jurisdictions. Changing policies (e.g., the NYC

stop and frisk program) could potentially alter who would be arrested and for what types of crime. New cultural phe
nomena (e.g., in video games and media) could also inﬂuence people’s behavior at a large scale. The above observations

lead us to conclude that different recidivism prediction models could be constructed for different locations and should

be periodically updated. Machine learning models are well-suited for efﬁcient creation and updating of these kinds of

models. A possible future line of work is to separate the Kentucky data at the jurisdiction level, and perform a causal

analysis of the effects of different judicial and policing practices on the recidivism distribution.

Simple, transparent models have been used for criminal justice applications for almost a century [65, 84]. They

have the advantage that one can easily quantify the contributions of each feature to the predicted score. Judicial

actors without much statistics background can understand these scores, and use them to help solve societal issues.

Interpretable models are extremely valuable for current decision-making processes in criminal justice: they allow

error-checking, help ensure due process, and allow judges to incorporate information outside the database into their

decision-making process in a calibrated manner.

However, our work on interpretable risk prediction is only one step closer to what we view as the ultimate goal—

placing recidivism prediction into the framework of formal decision analysis. Decision-making in the context of decision

analysis involves the minimization of costs rather than risks. Towards this end, Lakkaraju and Rudin [85] considered

several costs related to pretrial release decisions; these include the societal cost of releasing an individual who might

commit a crime before their trial, the cost of assigning an ofﬁcer to an individual, and the cost to taxpayers of keeping an

individual incarcerated. The importance of risk predictions vary between decision-making problems (release, parole,

sentencing, etc.). In some cases, they play a minor role, yet in others, predictions may comprise the sole deciding factor.

Because of this, it would be useful to have a cost-beneﬁt analysis per decision that would help determine exactly when

and where risk scores should participate.

Hence, an important and necessary direction for the future work would be to incorporate the framework of

classical decision analysis into decision-making in the criminal justice system. Decision analysis tools would ideally

allow practitioners to strike a balance between relevant considerations (e.g., future risks to society, costs of treatment

programs to society, costs to families involved in the criminal justice system, costs to the individual, as well as more

traditional modelling objectives such as fairness, interpretability, transparency, and predictive performance). While

the full data measuring costs and risks to all stakeholders in the criminal justice process may never be available, it is

important to move in this direction, as this would bring us closer to more consistent and informed decision making.

A C K N O W L E D G E M E N T S

We acknowledge partial funding from Arnold Ventures, the Duke Computer Science Undergraduate Research Fellows

Program, the Lord Foundation of North Carolina and the Duke Department of Electrical and Computer Engineering.

This report represents the ﬁndings of the authors and does not represent the views of any of the funding agencies. We

thank the Broward County Sheriff’s ofﬁce and the Kentucky Department of Shared Services, Research and Statistics for

their assistance and provision of data. We would also like to thank Daniel Sturtevant from the Kentucky Department of

Shared Services, Research and Statistics for providing signiﬁcant insight into the Kentucky data set, and Berk Ustun for

his advice on training RiskSLIM. Finally, we thank Brandon Garrett from Duke, Stuart Buck and Kristin Bechtel from

Arnold Ventures, and Kathy Schiﬂett, Christy May, and Tara Blair from Kentucky Pretrial Services for their thoughtful

comments on the article.


30

C O D E

R E F E R E N C E S

Our code is here: https://github.com/BeanHam/interpretable-machine-learning

WANG & HAN ET AL.

[1] Berk R. An Impact Assessment of Machine Learning Risk Forecasts on Parole Board Decisions and Recidivism. Experi
mental Criminology 2017 April;13:193–216.

[2] Larson J, Mattu S, Kirchner L, Angwin J. How We Analyzed the COMPAS Recidivism Algorithm. ProPublica; 2016.

[3] Freeman K. Algorithmic Injustice: How the Wisconsin Supreme Court Failed to Protect Due Process Rights in State V.
Loomis. North Carolina Journal of Law & Technology 2016 December;18. http://ncjolt.org/wp-content/uploads/
2016/12/Freeman_Final.pdf.

[4] Rudin C, Wang C, Coker B. The age of secrecy and unfairness in recidivism prediction. arXiv:181100731 2019 Novem
ber;Accepted to Harvard Data Science Review.

[5] Flores AW, Lowenkamp CT, Bechtel K. False Positives, False Negatives, and False Analyses: A Rejoinder to “Machine Bias: There’s Software Used Across the Country to Predict Future Criminals". Federal probation 2016 September;80(2).

[6] Dieterich W, Mendoza C, Brennan T. COMPAS Risk Scales: Demonstrating Accuracy Equity and Predictive Parity: Per
formance of the COMPAS Risk Scales in Broward County; 2016.

[7] Barabas C, Dinakar K, Doyle C. The Problems With Risk Assessment Tools. The New York Times 2019 July;https:

//www.nytimes.com/2019/07/17/opinion/pretrial-ai.html.

[8] O’Neil C. Weapons of Math Destruction. Crown Books; 2016.

[9] Wexler R. When a Computer Program Keeps You in Jail: How Computers are Harming Criminal Justice. New York

Times 2017 June;p. 27. Section A.

[10] Zeng J, Ustun B, Rudin C. Interpretable classiﬁcation models for recidivism prediction. Journal of the Royal Statistical

Society: Series A (Statistics in Society) 2017;180(3):689–722.

[11] Angelino E, Larus-Stone N, Alabi D, Seltzer M, Rudin C. Certiﬁably optimal rule lists for categorical data. Journal of

Machine Learning Research 2018;19:1–79.

[12] Lou Y, Caruana R, Gehrke J, Hooker G. Accurate intelligible models with pairwise interactions.

In: 19th ACM
SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD); 2013. p. 623–631. DOI:
10.1145/2487575.2487579.

[13] Soares E, Angelov PP. Fair-by-design explainable models for prediction of recidivism. ArXiv 2019;abs/1910.02043.

[14] MHS Assessments. Level of Service/Case Management Inventory: An Offender Management System. MHS Public

Safety 2017;https://issuu.com/mhs-assessments/docs/ls-cmi.lsi-r.brochure_insequence.

[15] Northpointe. Practitioner’s Guide to COMPAS Core; 2013, http://www.northpointeinc.com/downloads/compas/

Practitioners-Guide-COMPAS-Core-_031915.pdf.

[16] Gelb A, Velazquez T, Trust PC, of America US. The Changing State of Recidivism: Fewer People Going Back to Prison.

The Pew Charitable Trusts 2018;.

[17] Kim J, Bushway S, Tsao H. Identifying Classes of Explanation for Crime Drop: Period and Cohort Effects for New York

State. Journal of Quantitative Criminology 2016;32:357–375.


WANG & HAN ET AL.

31

[18] Bureau of Justice Assistance; Bureau of Justice Assistance. History of Risk Assessment. Bureau of Justice Assistance

2020;https://psrac.bja.ojp.gov/basics/history.

[19] Kehl D, Guo P, Kessler S. Algorithms in the Criminal Justice System: Assessing the Use of Risk Assessments in Sentenc
ing. 2017 July;https://cyber.harvard.edu/publications/2017/07/Algorithms.

[20] Public Safety Assessment. Risk Factors and Formulas. Laura and John Arnold Foundation 2019 9;(https://www.

psapretrial.org/about/).

[21] Latessa E, Smith P, Lemke R, Makarios M, Lowenkamp C. Creation and Validation of the Ohio Risk Assessment System.

University of Cincinnati School of Criminal Justice Center for Criminal Justice Research; 2009.

[22] Electronic Privacy Information Center. Algorithms in the Criminal Justice System. Electronic Privacy Information

Center 2016 6;https://epic.org/algorithmic-transparency/crim-justice/.

[23] Hanson R, Thornton D. Notes on the development of Static-2002. Ottawa, Ontario: Department of the Solicitor Gen
eral of Canada 2003;.

[24] Tollenaar N, van der Heijden PGM. Which method predicts recidivism best?: a comparison of statistical, machine
learning and data mining predictive models. Journal of the Royal Statistical Society: Series A (Statistics in Society)
2013;176(2):565–584.

[25] Howard P, Francis B, Soothill K, Humphreys L. OGRS 3: The revised offender group reconviction scale. Ministry of

Justice; 2009.

[26] Dawes RM, Faust D, Meehl PE. Clinical versus actuarial judgment. Science 1989;243(4899):1668–1674.

[27] Grove WM, Meehl PE. Comparative efﬁciency of informal (subjective, impressionistic) and formal (mechanical, algorithmic) prediction procedures: The clinical–statistical controversy. Psychology, Public Policy, and Law 1996;2(2):293.

[28] Wolfgang ME. Delinquency in a birth cohort. University of Chicago Press; 1987.

[29] Sherman LW. The power few: experimental criminology and the reduction of harm. Journal of Experimental Criminol
ogy 2007;3(4):299–321.

[30] Milgram A, Milgram A, editor, Why smart statistics are the key to ﬁghting crime. Ted Talk; 2014.

[31] James N. Risk and Needs Assessment in the Federal Prison System. Congressional Research Service; 2018.

[32] Zweig J.

Extraordinary Conditions Of Release Under The Bail Reform Act. Harvard Journal On Legislation

2010;47:555–585.

[33] Desmarais S, Garrett B, Rudin C. Risk Assessment Tools Are Not A Failed ’Minority Report’.

Law360 2019
July;https://www.law360.com/access-to-justice/articles/1180373/risk-assessment-tools-are-not-a-failedminority-report-.

[34] The Leadership Conference on Civil and Human Rights. The Use of Pretrial "Risk Assessment" Instrument: A Shared
Statement of Civil Rights Concerns. 2018 August;http://civilrightsdocs.info/pdf/criminal-justice/PretrialRisk-Assessment-Full.pdf.

[35] Pretrial Justice Institute. Updated Position on Pretrial Risk Assessment Tools. Pretrial Justice Institute 2020;https:

//www.pretrial.org/wp-content/uploads/Risk-Statement-PJI-2020.pdf.

[36] Angwin J, Larson J, Mattu S, Kirchner L. Machine Bias. ProPublica; 2016.

[37] Stevenson M. Assessing Risk Assessment in Action. Minnesota Law Review 2018;http://www.minnesotalawreview.

org/wp-content/uploads/2019/01/13Stevenson_MLR.pdf.


32

WANG & HAN ET AL.

[38] Skeem J, Lin Z, Jung J, Goel S. The limits of human predictions of recidivism. Science Advances 2020;6.

[39] Garrett B, Stevenson M. Open Risk Assessments. Behavioral Science & Law 2020;https://sites.law.duke.edu/
justsciencelab/2019/09/15/comment-on-pattern-by-brandon-l-garrett-megan-t-stevenson/, forthcoming.

[40] Roberts J, von Hirsch A. Previous Convictions at Sentening - Theoretical and Applied Perspective. Bloomsbury Publish
ing; 2010.

[41] Frase RS, Roberts J, Hester R, Mitchell KL, of Criminal Law RI, Justice C, editors, Robina Institute of Criminal Law and
Criminal Justice, Criminal History Enhancements Sourcebook. Robina Institute of Criminal Law and Criminal Justice;
2015. https://robinainstitute.umn.edu/publications/criminal-history-enhancements-sourcebook.

[42] Starr SB. The Risk Assessment Era: An Overdue Debate. Federal Sentencing Reporter 2015 April;27:205–206.

[43] American Law Institute, Model Penal Code; 2017. https://www.ali.org/projects/show/sentencing/.

[44] Neuilly MA, Zgoba KM, Tita GE, Lee SS. Predicting recidivism in homicide offenders using classiﬁcation tree analysis.

Homicide studies 2011;15(2):154–176.

[45] Friedman JH. Stochastic gradient boosting. Computational Statistics &amp; Data Analysis 2002;38(4):367–378.

[46] Palocsay SW, PingWang, Brookshire RG. Predicting criminal recidivism using neural networks. Socio-Economic Plan
ning Sciences 2000 December;34:271–284.

[47] Berk RA, He Y, Sorenson SB. Developing a practical forecasting screener for domestic violence incidents. Evaluation

Review 2005;29(4):358–383.

[48] Goel S, Rao JM, Shroff R. Precinct or Prejudice? Understanding Racial Disparities in New York City’s Stop-And-Frisk

Policy. Institute of Mathematical Statistics 2016;10(1):365–394.

[49] Rudin C. Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models

Instead. Nature Machine Intelligence 2019 May;1:206–215.

[50] Hardt M, Price E, Srebro N. Equality of opportunity in supervised learning. In: Advances in neural information process
ing systems; 2016. p. 3315–3323.

arXiv:180302453 2018;.

arXiv:160905807 2016 November;.

January;81:1–11.

2018. p. 1–7.

[51] Agarwal A, Beygelzimer A, Dudík M, Langford J, Wallach H. A reductions approach to fair classiﬁcation. arXiv preprint

[52] Kleinberg J, Mullainathan S, Raghavan M.

Inherent Trade-Offs in the Fair Determination of Risk Scores.

[53] Pleiss G, Raghavan M, Wu F, Kleinberg J, Weinberger K. On fairness and calibration. In: Advances in Neural Information

Processing Systems; 2017. p. 5680–5689.

[54] Binns R. Fairness in Machine Learning: Lessons from Political Philosophy. Journal of Machine Learning Research 2018

[55] Verma S, Rubin J. Fairness Deﬁnitions Explained. In: ACM/IEEE International Workshop on Software Fairness ACM;

[56] Berk R, Heidari H, Jabbari S, Kearns M, Roth A. Fairness in Criminal Justice Risk Assessments: The State of the Art.

Sociological Methods & Research 2017 03;.

[57] Berk R. Accuracy and Fairness for Juvenile Justice Risk Assessments.

Journal of Empirical Legal Studies 2019

March;16(1):174–194.


WANG & HAN ET AL.

33

[58] Corbett-Davies S, Pierson E, Feller A, Goel S, Huq A. Algorithmic decision making and the cost of fairness. In: In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining; 2017. p. 797–806.

[59] Barocas S, Selbst AD. Big Data’s Disparate Impact. California Law Review 2016;104:671–732.

[60] Corbett-Davies S, Goel S. The Measure and Mismeasure of Fairness: A Critical Review of Fair Machine Learning.

arXiv:180800023v2 2018 August;.

[61] Vapnik V, Chervonenkis A. A note on one class of perceptrons. Automation and Remote Control 1964;25.

[62] Breiman L, Friedman J, Stone CJ, Olshen RA. Classiﬁcation and regression trees. CRC press; 1984.

[63] Freund Y, Schapire RE. A decision-theoretic generalization of on-line learning and an application to boosting. Journal

of computer and system sciences 1997;55(1):119–139.

[64] Chen T, Guestrin C. Xgboost: A scalable tree boosting system. In: Proceedings of the 22nd acm sigkdd international

conference on knowledge discovery and data mining; 2016. p. 785–794.

[65] Burgess EW, on Indeterminate-Sentence Law IC, Parole Springﬁeld I, editors, Factors determining success or failure on

parole. Illinois Committee on Indeterminate-Sentence Law and Parole Springﬁeld, IL; 1928.

[66] Ustun B, Rudin C. Optimized Risk Scores.

In: Proceedings of the 23rd ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining KDD ’17, New York, NY, USA: ACM; 2017. p. 1125–1134. http://doi.acm.
org/10.1145/3097983.3098161.

[67] Stevenson MT, Slobogin C. Algorithmic Risk Assessments and the Double-Edged Sword of Youth. Washington University Law Review 2018;96(Vanderbilt Law Research Paper No. 18-36). http://dx.doi.org/10.2139/ssrn.3225350.

[68] Bindler A, Hjalmarsson R. How punishment severity affects jury verdicts: Evidence from two natural experiments.

American Economic Journal: Economic Policy 2018;10.

[69] Bushway SD, Piehl AM. The inextricable link between age and criminal history in sentencing. Crime & Delinquency

2007;53(1):156–183.

table/KY,US/PST045219.

[70] United States Census Bureau. QuickFacts: Kentucy; United States. 2019;https://www.census.gov/quickfacts/fact/

[71] United States Census Bureau. Hispanic or Latino Origin By Race 2011-2015 American Community Survey 5-Year Estimates. 2015;https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?pid=ACS_15_
5YR_B03002&prodType=table.

[72] Mishra A. Climate and Crime. Global Journal of Science Frontier Research: H, Environment & Earth Science 2014;14.

[73] Ranson M. Crime, weather, and climate change. Journal of Environmental Economics and Management 2014;67.

[74] Defronzo J. Climate and Crime: Tests of an FBI Assumption. Environment and Behavior 1984;16.

[75] Kleiman M, Ostrom BJ, Cheesman FL. Using risk assessment to inform sentencing decisions for nonviolent offenders

in Virginia. Crime & Delinquency 2007;53(1):106–132.

[76] Dwork C, Hardt M, Pitassi T, Reingold O, Zemel R. Fairness Through Awareness. In: Proceedings of the 3rd Innovations
in Theoretical Computer Science Conference ITCS ’12, New York, NY, USA: ACM; 2012. p. 214–226. http://doi.acm.
org/10.1145/2090236.2090255.

[77] Chouldechova A. Fair prediction with disparate impact: A study of bias in recidivism prediction instruments. Big data

2017;5(2):153–163.


34

WANG & HAN ET AL.

[78] Zemel R, Wu Y, Swersky K, Pitassi T, Dwork C. Learning fair representations. In: International Conference on Machine

Learning; 2013. p. 325–333.

preprint arXiv:170602409 2017;.

arXiv:190512843 2019;.

37.

[79] Berk R, Heidari H, Jabbari S, Joseph M, Kearns M, Morgenstern J, et al. A convex framework for fair regression. arXiv

[80] Agarwal A, Dudík M, Wu ZS. Fair Regression: Quantitative Deﬁnitions and Reduction-based Algorithms. arXiv preprint

[81] Cook P, Laub J. After the Epidemic Recent Trends in Youth Violence in the United States. Crime and Justice 2002;29:1–

[82] Alfred B. The Crime Drop in America: An Explanation of Some Recent Crime Trends. Journal of Scandinavian Studies

in Criminology and Crime Prevention 2006;7:17–35.

[83] Matthews B, Minton J. Rethinking one of the criminology’s ’brute facts’: The age-crime curve and the crime drop in

Scotland. European Journal of Criminology 2017;15(3):296–320.

[84] Hart H. Predicting Parole Success. Journal of Criminal Law and Criminology 1924;14.

[85] Lakkaraju H, Rudin C. Learning Cost-Effective and Interpretable Treatment Regimes. In: Singh A, Zhu J, editors. Proceedings of the 20th International Conference on Artiﬁcial Intelligence and Statistics, vol. 54 of Proceedings of Machine Learning Research Fort Lauderdale, FL, USA: PMLR; 2017. p. 166–175. http://proceedings.mlr.press/v54/
lakkaraju17a.html.

[86] Brennan T, Dieterich W, Ehret B. Evaluating the Predictive Validity of the COMPAS Risk and Needs Assessment System.

Criminal Justice and Behavior 2009 January;36(1):21–40.

[87] Northpointe Inc . Measurement & Treatment Implications of COMPAS Core Scales; 2009.

[88] Carollo J, Hedlund J, Hines M. Expanded Validation of a Decision Aid for Pretrial Conditional Release; 2007.

[89] The Colorado Pretrial Assessment Tool (CPAT): Administration, Scoring, and Reporting Manual. Colorado Association of Pretrial Services; 2015, https://university.pretrial.org/HigherLogic/System/DownloadDocumentFile.
ashx?DocumentFileKey=47e978bb-3945-9591-7a4f-77755959c5f5.

[90] Turner S, Hess J, Jannetta J. Development of the California Static Risk Assessment Instrument (CSRA). CEBC Working

Papers 2009;.

2011;75(2).

[91] Cadigan TP, Lowenkamp CT. Implementing Risk Assessment in the Federal Pretrial Services System. Federal Probation

[92] Hoffman PB, Adelberg S. The Salient Factor Score: A Nontechnical Overview. Fed Probation 1980;44:44.

[93] Nafekh M, Motiuk LL. The Statistical Information on Recidivism, Revised 1 (SIR-R1) Scale: A Psychometric Examination.

Correctional Service of Canada. Research Branch; 2002.

[94] Orbis, Orbis, editor, Service Planning Instrument: An Innovative Assessment and Case Planning Tool. Orbis; 2014.

https://orbispartners.com/wp-content/uploads/2014/07/SPIn-Brochure.pdf.

[95] Lazarsfeld PF. An Evaluation of the Pretrial Services Agency of the Vera Institute of Justice. New York: Vera Institute

1974;.

[96] Harris GT, Rice ME. Violence Risk Appraisal Guide (VRAG). In: Cutler BL, editor. Encyclopedia of Psychology and Law
SAGE Publications, Inc.; 2008. p. 848. https://sk.sagepub.com/reference/download/psychologylaw/n345.pdf.


WANG & HAN ET AL.

35

[97] Virginia Pretrial Risk Assessment Instrument - (VPRAI). Virginia Department of Criminal Justice Services; 2018,

https://www.dcjs.virginia.gov/sites/dcjs.virginia.gov/files/publications/corrections/virginia-pretrialrisk-assessment-instrument-vprai_0.pdf.

[98] Fan RE, Chang KW, Hsieh CJ, Wang XR, Lin CJ. LIBLINEAR: A Library for Large Linear Classiﬁcation. J Mach Learn Res

2008 Jun;9:1871–1874.

[99] Smith B. Auditing Deep Neural Networks to Understand Recidivism Predictions. PhD thesis, Haverford College; 2016.

[100] Ustun B, Rudin C. Supersparse linear integer models for optimized medical scoring systems. Machine Learning 2015;p.

1–43. http://dx.doi.org/10.1007/s10994-015-5528-6.

11 | APPENDIX

11.1 | Broward Data Processing

The Broward County data set consists of publicly available criminal history, court data and COMPAS scores from

Broward County, Florida. The criminal history and demographic information were computed from raw data released by

ProPublica [36]. The probational history was computed from public criminal records released by the Broward Clerk’s

Ofﬁce.

The screening date is the date on which the COMPAS score was calculated. The features and labels were computed

for an individual with respect to a particular screening date. For individuals who have multiple screening dates, we

compute the features for each screening date, such that the set of events for calculating features for earlier screening

dates is included in the set of events for later screening dates. On occasion, an individual will have multiple COMPAS

scores calculated on the same date. There appears to be no information distinguishing these scores other than their

identiﬁcation number, so we take the scores with the larger identiﬁcation number.

The recidivism labels were computed for the timescales of six months and two years. Some individuals were

sentenced to prison as a result of their offense(s). We used only observations for which we have six months/two years

of data subsequent to the individual’s release date.

Below, we describe details of the feature and label generation process.

•

•

•

• Degree “(0)” charges seem to be very minor offenses, so we exclude these charges. We infer whether a charge is a

felony, misdemeanor, or trafﬁc charge based off the charge degree.

Some of our features rely on classifying the type of each offense (e.g., whether or not it is a violent offense). We

infer this from the statute number, most of which correspond to statute numbers from the Florida state crime code.

The raw Propublica data includes arrest data as well as charge data. Because the arrest data does not include the

statute, which is necessary for us to determine offense type, we use the charge data to compute features that

require the offense type. We use both charge and arrest data to predict recidivism.

For each person on each COMPAS screening date, we identify the offense—which we call the current offense—that

most likely triggered the COMPAS screening. The current offense date is the date of the most recent charge that

occurred on or before the COMPAS screening date. Any charge that occurred on the current offense date is part

of the current offense. In some cases, there is no prior charge that occurred near the COMPAS screening date,

suggesting charges may be missing from the data set. For this reason we consider charges that occurred within

30 days of the screening date for computing the current offense. If there are no charges in this range, we say the

current offense is missing. We exclude observations with missing current offenses. We used some of the COMPAS


36

•

•

•

•

•

WANG & HAN ET AL.

subscale items as features for our machine learning models. All such components of the COMPAS subscales that

we compute are based on data that occurred prior to (not including) the current offense date.

The events/documents data includes a number of events (e.g., “File Afﬁdavit Of Defense” or “File Order Dismissing

Appeal”) related to each case, and thus to each person. To determine how many prior offenses occurred while on

probation, or if the current offense occurred while on probation, we deﬁne a list of event descriptions indicating

that an individual was taken on or off probation. Unfortunately, there appear to be missing events, as individuals

often have consecutive “On” or consecutive “Off” events (e.g., two “On” events in a row, without an “Off” in between).
In these cases, or if the ﬁrst event is an “Off” event or the last event is an “On” event, we deﬁne two thresholds, t on
and t of f . If an offense occurred within t on days after an “On” event or t of f days before an “Off” event, we count the
offense as occurring while on probation. We set t on to 365 and t of f to 30. On the other hand, the “number of times
on probation” feature is just the count of “On” events and the “number of times the probation was revoked” feature

is just the count of “File order of Revocation of Probation” event descriptions (i.e., we do not infer missing probation

events for these two features).

• Current age is deﬁned as the age in years, rounded down to the nearest integer, on the COMPAS screening date.
• A juvenile charge is deﬁned as an offense that occurred prior to the defendant’s 18th birthday.

Labels and features were computed using charge data.

The ﬁnal data set contains 1,954 records and 41 features.

11.2 | Kentucky Data Processing

The Kentucky pretrial and criminal court data was provided by the Department of Shared Services, Research and

Statistics in Kentucky. The Pretrial Services Information Management System (PRIM) data contains records regarding

defendants, interviews, PRIM cases, bonds etc., that are connected with the pretrial services’ interviews conducted

between July 1, 2009 and June 30, 2018. The cases were restricted to have misdemeanor, felony, and other level charges.

The data from another system, CourtNet, provided further information about cases, charges, sentences, dispositions

etc. for CourtNet cases matched in the PRIM system. The Kentucky data can be accessed through a special data request

to the Kentucky Department of Shared Services, Research and Statistics.

CourtNet and PRIM data were processed separately and then combined together. We describe the details below:

For the CourtNet data, we ﬁltered out cases with ﬁling date prior to Jan. 1st, 1996, which were claimed to be less

reliable records by the Kentucky Department of Shared Services, Research and Statistics (which provided the

data). To investigate what types of crimes the individuals were involved in for each charge, such as drug, property,

trafﬁc-related crime, we used the Kentucky Uniform Crime Reporting Code (UOR Code), as well as detecting

keywords in the UOR description.

From the PRIM system data, we extracted the probation, failure to appear, case pending, and violent charge

information at the PRIM case level, as well as the Arnold PSA risk scores computed at the time of each pretrial

services’ interview. Since Kentucky did not use Arnold PSA until July 1st, 2013, we ﬁltered out records before the

this date. We omitted records without risk scores since we want to compare the performance of the PSA with other

models. Only 33 records are missing PSA scores; therefore we do not worry about missing records impacting the

results. Additionally, some cases in the PRIM system have “indictment” for the arrest type, along with an “original”

arrest case ID, indicating that those cases were not new arrests. We matched these cases with the records that

correspond to the original arrests to avoid overcounting the number of prior arrests. Then we inner-joined the data

from the two systems using person-id and prim-case-id.


WANG & HAN ET AL.

37

•

•

•

For each individual, we used the date that is two years before the latest charge date in the Kentucky data, as a

cutoff date. The data before the cutoff are used as criminal history information to compute features. The data

after the cutoff are used to compute labels and check recidivism. In the data before the cutoff, the latest charge is

treated as the current charge (i.e., the charge that would trigger a risk-assessment) for each individual. We compute

features and construct labels using only convicted charges. However, the current charge can be either convicted or

non-convicted. This ensures that our analysis includes all individuals that would receive a risk assessment, even

if they were later found innocent of the current charge that triggered the risk assessment. It also ensures that

criminal history features use only convicted charges, so that our risk assessments are not inﬂuenced by charges for

crimes that the person may not have committed.

In order to compute the labels, we must ensure that there are at least two years of data following an individual’s

current charge date. For individuals who are sentenced to prison due to their current charge, we consider their

release date instead of the current charge date. We omitted individuals for whom there were less than two years of

data between their current charge date or release date, and the last date recorded in the data set.

To get the age at current charge information, we ﬁrst calculated the date of birth (DOB) for each individual, using

CourtNet case ﬁling date and age at the CourtNet case ﬁling date. Then we calculated “age at current charge” using

the DOB and charge date (the charge date sometimes differs from the case ﬁling date). Notice that there are many

errors in age records in the data. For instance, some people have age recorded over 150, which is certainly wrong

but there is no way to correct it. To ensure the quality of our data, we limited the ﬁnal current age feature to be

inclusively between 18 and 70. This is also consistent with the range from Broward analysis. If the person was

not sentenced to prison, we deﬁne current age as the age at current charge date. If the person was sentenced to

prison, we compute current age by adding the sentence time to the age at the current charge date. Note that this

differs from the way risk scores are computed in practice—usually risk scores are computed prior to the sentencing

decision. This helps to handle distributional shift between the individuals with no prison sentence (for whom a

2-year evaluation can be handled directly) and the full population (some of whom may have been sentenced to

prison and cannot commit a crime during their sentence).

• We computed features using the data before the current charge date. The CourtNet data is organized by CourtNet
cases, and each CourtNet case has charge level data. The PRIM data is organized by PRIM cases. Each CourtNet
case can connect to multiple PRIM cases.14 Therefore, to compute the criminal history information, we ﬁrst grouped

on PRIM case level to summarize the charge information. Next, we grouped on CourtNet case level to summarize

PRIM case level information. Last, we grouped on the individual level to summarize the criminal histories.

• On computing the ADE feature: The ADE feature means number of times the individual was assigned to alcohol
and drug education classes. Note that by Kentucky state law, any individual convicted for a DUI is assigned to ADE

classes. This does not indicate whether the individual successfully completed ADE classes.

• We compute labels using the two years of data after the current charge date/release date. We constructed the
general recidivism labels by checking whether a “convicted charge” occurred within two years or six months
from the current charge (or release date). Then, using the charge types of the convicted charge, other recidivism

prediction labels were generated, such as drug or property-related recidivism. The ﬁnal data set contains 250,778

Note: there are degrees of experimenter freedom in some of these data processing choices; exploring all the possible choices

records and 40 features.

here is left for future studies.

The Arnold PSA features that were included in the Kentucky data set (e.g., prior convictions, prior felony convictions

14This occurs because a new PRIM case is logged when an update occurs in the defendant’s CourtNet case (for example, if the defendant fails to appear in court).


38

WANG & HAN ET AL.

etc.) were computed by pretrial ofﬁcers who had access to criminal history data from both inside and outside of Kentucky.

However, the Kentucky data set we received contained criminal history information from within Kentucky only. Thus,

the Arnold PSA features for Kentucky (which are included in our models as well) use both in-state and out-of-state

information, but the remaining features (which we compute directly from the Kentucky criminal history data) are limited

to in-state criminal history.

Additionally, we were informed by Kentucky Pretrial Services team that the data set ’s sentencing information

may not be reliable due to unmeasured confounding, including shock probation and early releases that would allow

a prisoner to be released much earlier than the end date of the sentence. Because the sentence could be anywhere

from zero days to the full length, we conducted a sensitivity analysis by excluding the sentence information in the data

processing, which is equivalent to the assumption that no prison sentence was served. For that analysis, the current age

of each individual was calculated to be the age at the current charge, and the prediction labels were generated from

new charges within six months (or two years) from the current charge. The sensitivity analysis yielded predictive results

that were almost exactly the same as the results in the main text, when the sentence information was used to determine

age and prediction interval.

11.3 | Why We Compare Only Against COMPAS and the PSA

The variables included in risk assessments are often categorized into static and dynamic factors. Static factors are deﬁned

as factors that cannot be reduced over time (e.g. criminal history, gender, and age-at-ﬁrst-arrest). Dynamic factors

are deﬁned as variables that can change over time to decrease the risk of recidivism; they allow insight into whether a

high-risk individual can lower their risk through rehabilitation, and sometimes improve prediction accuracy. Examples

of dynamic factors include current age, treatment for substance abuse, and mental health status [19]. Dynamic factors

are often included in risk-and-needs-assessments (RNAs), which in addition to identifying risk of recidivism, recommend

interventions to practitioners (e.g., treatment programs, social services, diversion of individuals from jail).

With the exception of current age, our features all fall under the “static” classiﬁcation. This renders us unable to

compare against the risk assessment tools that use dynamic factors, whose formulas are public. The risk assessments

that we examined are listed in Table 4. Since we have only criminal history and age variables, the only model we could

compute from our data was the Arnold PSA.

However, as we demonstrated in the main body of the paper, the fact that we do not possess dynamic factors is

not necessarily harmful to the predictive performance of our models. The goal behind including dynamic factors in

models is to improve prediction accuracy as well as be able to recommend interventions that reduce the probability of

recidivism. While an admirable goal, the inclusion of dynamic factors does not come at zero cost and may not actually

produce performance gains for recidivism prediction. In Sections 6 and 7, we show that standard machine learning

techniques (using only the static factors) and interpretable machine learning models (using only static factors) are

able to outperform a criminal justice model that utilizes both static and dynamic factors (COMPAS). Furthermore, the

inclusion of additional, unnecessary factors increases the risk of data entry errors, or exposes models to additional

feature bias [60]. As Rudin et al. [4] reveals, data entry errors appear to be common in COMPAS score calculations and

could lead to scores that are either too high or too low.

Although the COMPAS suite is a proprietary (and thus black-box) risk-and-needs assessment, we were still able

to compare against its risk assessments thanks to the Florida’s strong open-records laws. Created by Northpointe (a

subsidiary company of Equivant), COMPAS is a recidivism prediction suite which is used in criminal justice systems

throughout the United States. It is comprised of three scores: Risk of General Recidivism, Risk of Violent Recidivism,

and Risk of Failure to Appear. In this work, we examine the two risk scores relating to violent recidivism and general


WANG & HAN ET AL.

39

recidivism. Each risk score is an integer from one to ten [86].

As COMPAS scores are proprietary instruments, the precise forms of its models are not publicly available. How
ever, it is known that the COMPAS scores are computed from a subset of 137 input variables that include voca
tional/educational status, substance abuse, and probational history, in addition to the standard criminal history vari
ables [86]. As such, we cannot directly compute these risk scores, and instead utilize the COMPAS scores released by

ProPublica in the Broward County recidivism data set. We do not compare against COMPAS on the Kentucky data set,

as our data set does not include COMPAS scores.

The PSA was created by Arnold Ventures, and is a publicly available risk assessment tool. Similar to the COMPAS

suite, it is comprised of three risk scores: Failure to Appear, New Criminal Activity, and New Violent Criminal Activity.

Again, we compare against latter two scores. Both are additive integer models which take nine factors as input, relating

to age, current charge, and criminal history. The New Criminal Activity model outputs a score from 1 to 6, while the New

Violent Criminal Activity model outputs a binary score [20]. The PSA is an interpretable model.

TA B L E 4 Variable comparison for currently-utilized actuarial risk assessments. We only have criminal history and
age variables, but most models include many other variables. Abbreviations are: Correctional Offender Management
Proﬁling for Alternative Sanctions (COMPAS); Connecticut Risk Assessment for Pretrial Decision Making
(Connecticut); Colorado Pretrial Risk Assessment Tool (CPAT); California Static Risk Assessment (CSRA); Ohio Risk
Assessment System (ORAS); Level-of-Service Case Management Inventory (LSI-CMR); Public Service Assessment(PSA);
(Federal) Pretrial Risk Assessment (PTRA); Statistical Information on Recidivism Score (SIRS); Service Planning
Instruments (SPIn); Vera Point Scale (VERA); Violence Risk Appraisal Guide (VRAG); Virginia Pretrial Risk Assessment
Instrument (VPRAI).

Models

Criminal History Age

Finance Residential Info

Edu/Emp

Peer/Family Mental Health Alc/Subs Abuse Other

COMPAS [87]

Connecticut [88]

CPAT [89]

CSRA [90]

ORAS [21]

LSI-CMI [14]

PSA [20]

PTRA [91]

SIRS [93]

SPIn [94]

VERA [95]

VRAG [96]

VPRAI [97]

Salient Factor [92]

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X

X


40

WANG & HAN ET AL.

11.4 | Hyperparameters

| Baseline Models, CART, EBM

We applied nested cross validation to tune the hyperparameters. Please refer to Table 5 for parameter details.

TA B L E 5 Hyperparameters for (cid:96)1 and (cid:96)2 Penalized Logistic Regression, Linear SVM, CART, Random Forest,
XGBoost, and EBM. RiskSLIM and Additive Stumps are discussed separately.

Models

Kentucky

Broward

(cid:96)2 Logistic Regression class_weight: balanced

class_weight: balanced

solver: liblinear[98]

solver: liblinear

penalty: (cid:96)2
C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]

penalty: (cid:96)2
C ∈ 100 values in [1e-5, 1e-2]

(cid:96)1 Logistic Regression class_weight: balanced

solver: liblinear

class_weight: balanced

solver: liblinear

penalty: (cid:96)1
C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]

penalty: (cid:96)1
C ∈ 100 values in [1e-5, 1e-2]

LinearSVM

C ∈ [1e-4, 1e-3, 1e-2, 1e-1, 1]

C ∈ 100 values in [1e-5, 1e-2]

CART

max_depth ∈ [5,6,7,8,9,10]

Random Forest

n_estimator ∈ [100,150,200]
max_depth ∈ [7,8,9]

max_depth ∈ [1,2,3,4,5]
min_impurity_decrease ∈ [1e-3, 2e-3, . . . 5e-3]

n_estimator ∈ [50,100,200,400,600]
max_depth ∈ [1,2,3]
min_impurity_decrease ∈ [1e-3, 2e-3, . . . , 1e-2]

XGBoost

learning_rate ∈ [0.1]
n_estimator ∈ [100,150]
max_depth ∈ [4,5,6]

EBM 15

n_estimator ∈ [60]
max_tree_splits ∈ [2]
learning_rate ∈ [0.1]

learning_rate ∈ [0.05]
n_estimator ∈ [50,100,200,400,600]
max_depth ∈ [1,2,3]
gamma ∈ [6,8,10,12]
min_child_weight ∈ [6,8,10,12]
subsample ∈ [0.5]

n_estimator ∈ [40,60,80,100]
max_tree_splits ∈ [1,2,3]
learning_rate ∈ [0.01]
holdout_split ∈ [0.7, 0.9]

| Additive Stumps

Stumps were created for each feature as detailed in Section 7.1. An additive model was created from the stumps

using (cid:96)1-penalized logistic regression, and no more than 15 original features were involved in the additive models. But
multiple stumps corresponding to each feature could be used in the models. We chose to limit the size of the model to

15 original features because then at most 15 plots would be generated to visualize the full model, which is a reasonable

number of visualizations for users to digest.

We started with the smallest regularization parameter on (cid:96)1 penalty that provides at most 15 original features from
the model. This will be our lower bound for nested cross validation. From there, we perform nested cross validation over

a grid of regularization parameters, all of which are greater than or equal to the minimum value of the regularization

parameter found above. Please refer to Table 6 for more details.

15The training procedure is slow for EBM, due to the size of Kentucky data, the nested cross validation we applied, and the cross-validation within the algorithm

to choose number of pairwise interactions. Therefore, we tested only one set of parameters, which gave reliable results.


WANG & HAN ET AL.

41

TA B L E 6 Hyperparameters for Additive Stumps

Models

Two Year

Six Month

Two Year

Six Month

Kentucky

Broward

General

C ∈ [1e-3, 2e-3]

C ∈ [1e-3, 1.5e-3]

C ∈ [1e-2, 2e-2. . . 1e-1]

C ∈ [1e-2, 2e-2. . . 1e-1]

Violent

C ∈ [6e-4, 8e-4, 1e-3]

C ∈ [5e-4, 7e-4]

C ∈ [1e-2, 2e-2 . . . 7e-2]

C ∈ [1e-2, 2e-2 . . . 7e-2]

Drug

C ∈ [1e-3, 2e-3, 2.5e-3]

C ∈ [1e-3, 2e-3]

C ∈ [1e-2, 2e-2 . . . 9e-2]

C ∈ [1e-2, 2e-2 . . . 6e-2]

Property

C ∈ [1e-3, 1.5e-3]

C ∈ [1e-3, 1.5e-3]

C ∈ [1e-2, 2e-2 . . . 8e-2]

C ∈ [1e-2, 2e-2 . . . 6e-2]

Felony

C ∈ [1e-3, 1.5e-3]

Misdemeanor C ∈ [1e-3, 1.5e-3]

C ∈ [5e-4, 8e-4]

C ∈ [5e-4, 1e-3]

C ∈ [1e-2, 2e-2 . . . 8e-2]

C ∈ [1e-2, 2e-2 . . . 8e-2]

C ∈ [1e-2, 2e-2 . . . 7e-2]

C ∈ [1e-2, 2e-2 . . . 7e-2]

All the models use "balanced" for the class_weight, "liblinear" for the solver, and (cid:96)1 for the penalty.

| RiskSLIM

RiskSLIM is challenging to train, because it uses the CPLEX optimization software, which can be difﬁcult to install and

requires a license. Moreover, since RiskSLIM solves a very difﬁcult mixed-integer nonlinear optimization problem, it

can be slow to prove optimality, which makes it difﬁcult to perform nested cross validation as nested cross validation

requires many solutions of the optimization problem. A previous study [99] also noted similar problems with algorithms

that use CPLEX (this study trained on SLIM [100], which is similar to the training process of RiskSLIM in that they both

require CPLEX). Here we provide details of how we trained RiskSLIM to help others use the algorithm more efﬁciently.

• We ran (cid:96)1-penalized logistic regression on the stumps training data with a relatively large regularization parameter
to obtain a small subset of features (that is, we used (cid:96)1-penalized logistic regression for feature selection). Then we
trained RiskSLIM using nested cross validation with this small subset of features. The maximum run-time, maximum

offset, and penalty value were set to 1,000 seconds, 100, and 1e-6 respectively. The coefﬁcient range was set to [-5,

5], which would give us small coefﬁcients that are easy to add/subtract.

•

If the model converged to optimality (optimality gap less than 5%) within 1,000 seconds, we then ran (cid:96)1-penalized
logistic regression again with a smaller regularization parameter to obtain a slightly larger subset of features to work

with. We then trained RiskSLIM with nested cross validation again on this larger subset of features. If RiskSLIM

also generated an optimality gap less than 5% within 1,000 seconds and had better validation performance, we

• Once either RiskSLIM could not converge to a 5% optimality gap within 1,000 seconds, or the validation performance did not improve by adding more stumps, we stopped there, using the previously obtained RiskSLIM model as

repeated this procedure.

the ﬁnal model.

•

This procedure generally stopped with between 12 and 20 stumps from (cid:96)1-penalized logistic regression. Beyond
this number of stumps, we did not observe improvements in performance in validation.


42

11.5 | Tables

WANG & HAN ET AL.

TA B L E 7 Broward baseline models. Results are the average value of test AUCs from ﬁve-fold nested cross
validation, with standard deviation listed in parentheses.

Labels

Logistic ((cid:96)2)

Logistic((cid:96)1)

Linear SVM

RF

XGBoost

Performance Range

Baseline Models

Two Year

0.670 (0.021)

0.650 (0.021)

0.670 (0.020)

0.658 (0.027)

0.655 (0.022)

0.675 (0.037)

0.663 (0.039)

0.659 (0.032)

0.671 (0.036)

0.676 (0.048)

0.711 (0.048)

0.733 (0.035)

0.695 (0.037)

0.703 (0.040)

0.722 (0.039)

0.717 (0.052)

0.730 (0.057)

0.683 (0.048)

0.712 (0.027)

0.733 (0.034)

0.646 (0.041)

0.648 (0.050)

0.621 (0.036)

0.647 (0.046)

0.644 (0.037)

Misdemeanor

0.630 (0.019)

0.597 (0.013)

0.628 (0.018)

0.629 (0.027)

0.627 (0.024)

Six Month

0.625 (0.022)

0.608 (0.022)

0.618 (0.028)

0.615 (0.026)

0.623 (0.014)

0.685 (0.024)

0.651 (0.038)

0.619 (0.036)

0.668 (0.045)

0.685 (0.033)

0.673 (0.084)

0.696 (0.022)

0.640 (0.081)

0.675 (0.055)

0.698 (0.038)

0.727 (0.047)

0.725 (0.053)

0.659 (0.069)

0.687 (0.047)

0.725 (0.048)

0.611 (0.050)

0.613 (0.054)

0.580 (0.086)

0.591 (0.061)

0.585 (0.066)

Misdemeanor

0.612 (0.038)

0.586 (0.040)

0.586 (0.016)

0.593 (0.039)

0.608 (0.031)

TA B L E 8 Kentucky baseline models. Results are the average value of test AUCs from ﬁve-fold nested cross
validation, with standard deviation listed in parentheses.

Labels

Logistic ((cid:96)2)

Logistic((cid:96)1)

Linear SVM

RF

XGBoost

Performance Range

Baseline Models

Two Year

0.745 (0.004)

0.745 (0.004)

0.746 (0.004)

0.753 (0.003)

0.759 (0.003)

0.768 (0.002)

0.769 (0.003)

0.769 (0.003)

0.777 (0.005)

0.784 (0.004)

0.730 (0.003)

0.730 (0.003)

0.733 (0.003)

0.743 (0.002)

0.749 (0.002)

0.785 (0.005)

0.785 (0.005)

0.787 (0.005)

0.801 (0.004)

0.806 (0.004)

0.765 (0.001)

0.765 (0.001)

0.768 (0.002)

0.779 (0.002)

0.784 (0.001)

Misdemeanor

0.729 (0.005)

0.729 (0.005)

0.730 (0.006)

0.738 (0.005)

0.744 (0.005)

Six Month

0.761 (0.004)

0.761 (0.004)

0.764 (0.005)

0.779 (0.003)

0.785 (0.004)

0.833 (0.007)

0.834 (0.006)

0.833 (0.007)

0.843 (0.006)

0.847 (0.005)

0.782 (0.003)

0.782 (0.003)

0.785 (0.003)

0.803 (0.003)

0.811 (0.002)

0.834 (0.012)

0.834 (0.013)

0.831 (0.014)

0.857 (0.011)

0.860 (0.011)

0.799 (0.002)

0.800 (0.002)

0.804 (0.003)

0.824 (0.003)

0.831 (0.002)

Misdemeanor

0.746 (0.007)

0.746 (0.007)

0.748 (0.007)

0.765 (0.006)

0.774 (0.006)

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

0.020

0.017

0.038

0.051

0.027

0.033

0.017

0.066

0.058

0.068

0.034

0.027

0.014

0.016

0.019

0.021

0.019

0.016

0.024

0.014

0.029

0.029

0.032

0.028


WANG & HAN ET AL.

43

TA B L E 9 AUCs of intepretable models on Broward data. For the violence problem, we use the Arnold New Violent
Criminal Activity score. For the general problem, we use the Arnold New Criminal Activity score.

Labels

CART

EBM

Additive Stumps

RiskSLIM

Performance Range

Arnold PSA

COMPAS

Interpretable Models

Existing Risk Models

0.613 (0.025) 0.664 (0.027)

0.651 (0.020)

0.624 (0.022)

0.605 (0.022) 0.631 (0.019)

0.613 (0.045) 0.673 (0.045)

0.665 (0.034)

0.655 (0.055)

0.649 (0.028)

0.666 (0.026) 0.685 (0.043)

0.716 (0.037)

0.697 (0.027)

0.686 (0.059) 0.736 (0.034)

0.736 (0.033)

0.717 (0.020)

0.596 (0.033) 0.655 (0.050)

0.631 (0.028)

0.590 (0.036)

Misdemeanor 0.577 (0.036) 0.636 (0.029)

0.609 (0.020)

0.579 (0.015)

Two Year

Six Month

0.569 (0.074) 0.672 (0.043)

0.656 (0.068)

0.650 (0.068)

0.637 (0.052) 0.725 (0.031)

0.725 (0.036)

0.703 (0.023)

0.513 (0.014) 0.606 (0.049)

0.574 (0.036)

0.561 (0.045)

Misdemeanor 0.535 (0.021) 0.608 (0.042)

0.582 (0.036)

0.576 (0.024)

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

0.051

0.059

0.049

0.052

0.065

0.059

0.074

0.049

0.102

0.089

0.093

0.073



















0.549 (0.021) 0.622 (0.022)

0.620 (0.019)

0.585 (0.021)

0.577 (0.018) 0.609 (0.019)

0.631 (0.050) 0.680 (0.040)

0.676 (0.029)

0.671 (0.039)

0.675 (0.038)

TA B L E 1 0 AUCs of interpretable models on Kentucky data. For the violence problem, we use the Arnold New
Violent Criminal Activity score. For the general problem, we use the Arnold New Criminal Activity score.

Labels

CART

EBM

Additive Stumps

RiskSLIM

Performance Range

Arnold PSA

Interpretable Models

Existing Risk Models

0.746 (0.003)

0.751 (0.004)

0.748 (0.004)

0.708 (0.003)

0.763 (0.007)

0.777 (0.004)

0.770 (0.005)

0.744 (0.008)

0.736 (0.002)

0.740 (0.001)

0.738 (0.002)

0.708 (0.005)

0.790 (0.003)

0.798 (0.006)

0.796 (0.005)

0.761 (0.003)

0.771 (0.002)

0.776 (0.001)

0.773 (0.002)

0.757 (0.007)

Misdemeanor

0.730 (0.005)

0.735 (0.005)

0.729 (0.006)

0.701 (0.002)

Two Year

Six Month

0.772 (0.005)

0.773 (0.004)

0.771 (0.004)

0.737 (0.002)

0.822 (0.011)

0.843 (0.006)

0.836 (0.004)

0.810 (0.009)

0.794 (0.003)

0.793 (0.004)

0.796 (0.004)

0.763 (0.004)

0.839 (0.014)

0.850 (0.012)

0.851 (0.010)

0.832 (0.010)

0.811 (0.003)

0.820 (0.003)

0.813 (0.003)

0.790 (0.006)

Misdemeanor

0.760 (0.006)

0.757 (0.006)

0.751 (0.006)

0.705 (0.005)

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

0.042

0.032

0.032

0.037

0.019

0.033

0.037

0.033

0.033

0.019

0.030

0.055

0.711 (0.004)

0.743 (0.003)

0.718 (0.004)

0.794 (0.011)










44

WANG & HAN ET AL.

TA B L E 1 1 Additive Stumps on two-year general recidivism. The model consists of twenty-eight stumps with an
intercept. These binary features represent ﬁfteen original features; coefﬁcients were rounded for display purposes
only.

1. age at current charge ≤ 20

2. age at current charge ≤ 21

3. age at current charge ≤ 24

4. age at current charge ≤ 27

5. age at current charge ≤ 35

6. age at current charge ≤ 39

7. age at current charge ≤ 43

8. age at current charge ≤ 47

9. prior arrest ≥ 2

10. prior arrest ≥ 3

11. prior arrest ≥ 4

12. prior arrest ≥ 5

13. prior charges ≥ 2

14. prior charges ≥ 2 3

15. prior violence ≥ 1

16. prior felony ≥ 1

17. prior misdemeanor ≥ 2

18. prior misdemeanor ≥ 3

19. prior misdemeanor ≥ 4

20. prior trafﬁc ≥ 1

21. ADE ≥ 1

22. prior fta two year ≥ 1

23. prior fta two year ≥ 2

24. prior pending charge ≥ 1

25. prior probation ≥ 1

26. prior incarceration ≥ 1

27. six month ≥ 1

28. three year ≥ 1

29. Intercept

0.0082

0.0053

0.0322

0.0270

0.0108

0.1223

0.0311

0.0686

0.6762

0.3489

0.2339

0.1226

0.0124

0.0065

0.0474

0.1721

0.0162

0.0764

0.0733

0.0394

0.1583

0.3398

0.0617

0.3874

0.2265

0.3577

0.0148

0.0005

-1.1500

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

-...

+...

+...

+...

+...

+...

-...

+...

+...

ADD POINTS FROM ROWS 1 TO 29

SCORE

= .....

Probability: Pr(Y = 1) = exp(score) / (1 + exp(score))


WANG & HAN ET AL.

45

TA B L E 1 2 Training baseline models and interpretable models on the Kentucky data set using ﬁve-fold nested cross
validation and testing the best-performing model on the Broward data set.

Labels

Logistic ((cid:96)2)

Logistic ((cid:96)1)

Linear SVM Random Forest

XGBoost

CART

EBM

Additive Stumps

RiskSLIM

Baseline Models

Interpretable Models

0.615 (0.001) 0.614 (0.001) 0.610 (0.000) 0.619 (0.001) 0.617 (0.003) 0.595 (0.009)

0.612 (0.002)

0.608 (0.001)

0.568 (0.000)

0.655 (0.001) 0.653 (0.002) 0.630 (0.000) 0.652 (0.000) 0.652 (0.004) 0.622 (0.030) 0.640 (0.0100)

0.652 (0.002)

0.629 (0.018)

0.629 (0.001) 0.629 (0.001) 0.618 (0.000) 0.614 (0.002) 0.637 (0.002) 0.621 (0.010)

0.629 (0.003)

0.631 (0.001)

0.625 (0.000)

0.664 (0.001) 0.672 (0.001) 0.649 (0.000) 0.668 (0.002) 0.674 (0.008) 0.649 (0.017)

0.665 (0.011)

0.659 (0.001)

0.639 (0.021)

0.630 (0.001) 0.630 (0.001) 0.624 (0.000) 0.631 (0.001) 0.627 (0.005) 0.611 (0.003)

0.623 (0.005)

0.624 (0.000)

0.614 (0.000)

Misdemeanor 0.558 (0.000) 0.558 (0.000) 0.551 (0.000) 0.561 (0.001) 0.576 (0.002) 0.555 (0.004)

0.571 (0.003)

0.557 (0.000)

0.539 (0.002)

0.577 (0.002) 0.576 (0.001) 0.569 (0.000) 0.577 (0.001) 0.581 (0.002) 0.562 (0.007)

0.571 (0.004)

0.562 (0.001)

0.553 (0.000)

0.641 (0.002) 0.644 (0.001) 0.614 (0.000) 0.643 (0.001) 0.626 (0.004) 0.611 (0.013)

0.622 (0.009)

0.650 (0.001)

0.637 (0.002)

0.607 (0.004) 0.604 (0.003) 0.589 (0.000) 0.567 (0.005) 0.593 (0.007) 0.580 (0.018)

0.618 (0.006)

0.576 (0.001)

0.566 (0.020)

0.662 (0.001) 0.665 (0.002) 0.635 (0.000) 0.652 (0.002) 0.656 (0.013) 0.634 (0.016)

0.657 (0.008)

0.640 (0.004)

0.619 (0.000)

0.586 (0.001) 0.584 (0.002) 0.575 (0.000) 0.589 (0.002) 0.58 (0.002)

0.563 (0.003)

0.571 (0.005)

0.574 (0.001)

0.550 (0.001)

Misdemeanor 0.558 (0.002) 0.558 (0.000) 0.550 (0.000) 0.552 (0.002) 0.563 (0.004) 0.554 (0.012)

0.559 (0.002)

0.542 (0.001)

0.526 (0.003)

TA B L E 1 3 Training baseline models and interpretable models on the Broward County data set using ﬁve-fold
nested cross validation and testing the resulting best-performing model on a held out portion of the Broward data set.

Labels

Logistic ((cid:96)2)

Logistic ((cid:96)1)

Linear SVM Random Forest

XGBoost

CART

EBM

Additive Stumps

RiskSLIM

Baseline Models

Interpretable Models

0.669 (0.020) 0.649 (0.021) 0.670 (0.020) 0.657 (0.034) 0.659 (0.019) 0.629 (0.028) 0.663 (0.031)

0.644 (0.027)

0.622 (0.021)

0.679 (0.038) 0.662 (0.035) 0.662 (0.034) 0.675 (0.037) 0.677 (0.05)

0.600 (0.037) 0.675 (0.049)

0.673 (0.035)

0.670 (0.032)

0.716 (0.047) 0.734 (0.034) 0.702 (0.043) 0.688 (0.044) 0.720 (0.034) 0.672 (0.041) 0.690 (0.054)

0.709 (0.044)

0.706 (0.027)

0.721 (0.057) 0.731 (0.057) 0.687 (0.052) 0.725 (0.039) 0.729 (0.04)

0.685 (0.058) 0.738 (0.031)

0.733 (0.039)

0.703 (0.036)

0.651 (0.040) 0.652 (0.053) 0.622 (0.036) 0.649 (0.045) 0.647 (0.039) 0.598 (0.034) 0.656 (0.050) 0.6400 (0.031) 0.603 (0.042)

Misdemeanor 0.634 (0.017) 0.602 (0.012) 0.632 (0.017) 0.629 (0.022) 0.624 (0.020) 0.585 (0.041) 0.633 (0.025)

0.603 (0.016)

0.558 (0.026)

0.624 (0.024) 0.607 (0.019) 0.619 (0.026) 0.620 (0.025) 0.621 (0.019) 0.553 (0.014) 0.620 (0.027)

0.617 (0.035)

0.600 (0.021)

0.680 (0.027) 0.650 (0.038) 0.614 (0.039) 0.670 (0.039) 0.689 (0.031) 0.623 (0.043) 0.683 (0.040)

0.683 (0.032)

0.691 (0.032)

0.672 (0.082) 0.696 (0.025) 0.649 (0.080) 0.687 (0.065) 0.686 (0.044) 0.569 (0.074) 0.655 (0.035)

0.704 (0.054)

0.719 (0.039)

0.726 (0.049) 0.725 (0.053) 0.648 (0.058) 0.698 (0.046) 0.720 (0.052) 0.637 (0.052) 0.723 (0.030)

0.699 (0.038)

0.663 (0.048)

0.620 (0.058) 0.613 (0.054) 0.587 (0.086) 0.611 (0.076) 0.601 (0.047) 0.524 (0.015) 0.605 (0.052)

0.584 (0.034)

0.557 (0.043)

Misdemeanor 0.616 (0.030) 0.583 (0.039) 0.590 (0.022) 0.601 (0.049) 0.620 (0.044) 0.543 (0.033) 0.612 (0.050)

0.576 (0.037)

0.556 (0.040)

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

Two Year

Six Month

Two Year

Six Month


46

WANG & HAN ET AL.

TA B L E 1 4 Training baseline and interpretable models on the Broward County data set using ﬁve-fold nested cross
validation and testing the resulting best-performing model on the Kentucky data set.

Labels

Logistic ((cid:96)2)

Logistic ((cid:96)1)

Linear SVM Random Forest

XGBoost

CART

EBM

Additive Stumps

RiskSLIM

Baseline Models

Interpretable Models

0.664 (0.007) 0.653 (0.001) 0.658 (0.007) 0.701 (0.005) 0.689 (0.006) 0.626 (0.025) 0.704 (0.003)

0.653 (0.009)

0.649 (0.037)

0.674 (0.005) 0.650 (0.007) 0.611 (0.013) 0.729 (0.005) 0.724 (0.005) 0.589 (0.053) 0.720 (0.005)

0.657 (0.018)

0.663 (0.025)

0.649 (0.008) 0.632 (0.003) 0.554 (0.005) 0.655 (0.022) 0.650 (0.006) 0.613 (0.013) 0.656 (0.008)

0.626 (0.009)

0.634 (0.012)

0.628 (0.022) 0.663 (0.014) 0.556 (0.017) 0.695 (0.018) 0.669 (0.023) 0.548 (0.018) 0.687 (0.011)

0.590 (0.014)

0.593 (0.052)

0.671 (0.006) 0.661 (0.002) 0.592 (0.014) 0.724 (0.003) 0.706 (0.014) 0.592 (0.042) 0.725 (0.006)

0.676 (0.023)

0.631 (0.059)

Misdemeanor 0.638 (0.007) 0.619 (0.026) 0.579 (0.01)

0.665 (0.011) 0.645 (0.014) 0.574 (0.053) 0.669 (0.007)

0.621 (0.017)

0.631 (0.025)

0.676 (0.006) 0.665 (0.004) 0.601 (0.011) 0.698 (0.009) 0.685 (0.010) 0.613 (0.018) 0.709 (0.005)

0.663 (0.012)

0.602 (0.046)

0.653 (0.015) 0.662 (0.021) 0.533 (0.011) 0.762 (0.047) 0.773 (0.007) 0.625 (0.059) 0.757 (0.004)

0.728 (0.026)

0.723 (0.004)

0.663 (0.031) 0.678 (0.008) 0.521 (0.006) 0.682 (0.009) 0.658 (0.027) 0.600 (0.082) 0.609 (0.037)

0.619 (0.025)

0.635 (0.017)

0.681 (0.012) 0.708 (0.009) 0.529 (0.012) 0.719 (0.053) 0.718 (0.010) 0.555 (0.007) 0.715 (0.018)

0.643 (0.022)

0.696 (0.053)

0.685 (0.008) 0.679 (0.008) 0.556 (0.011) 0.719 (0.018) 0.683 (0.025) 0.552 (0.049) 0.724 (0.010)

0.652 (0.039)

0.621 (0.036)

Misdemeanor 0.664 (0.003) 0.658 (0.008) 0.558 (0.016) 0.670 (0.004) 0.662 (0.006) 0.604 (0.019) 0.676 (0.006)

0.615 (0.019)

0.583 (0.070)

TA B L E 1 5 Training baseline models and interpretable models on the Kentucky data set using ﬁve-fold nested cross
validation and testing the resulting best-performing model on a held out portion of the Kentucky data set.

Labels

Logistic ((cid:96)2)

Logistic ((cid:96)1)

Linear SVM Random Forest

XGBoost

CART

EBM

Additive Stumps

RiskSLIM

Baseline Models

Interpretable Models

0.739 (0.003) 0.739 (0.003) 0.740 (0.004) 0.752 (0.004) 0.757 (0.003) 0.746 (0.003) 0.750 (0.004)

0.747 (0.004)

0.704 (0.004)

0.765 (0.001) 0.766 (0.002) 0.767 (0.002) 0.776 (0.004) 0.783 (0.004) 0.763 (0.007) 0.776 (0.004)

0.771 (0.005)

0.741 (0.010)

0.723 (0.002) 0.723 (0.002) 0.727 (0.002) 0.739 (0.002) 0.745 (0.002) 0.733 (0.002) 0.737 (0.002)

0.734 (0.003)

0.708 (0.002)

0.78 (0.004)

0.779 (0.004) 0.784 (0.004) 0.801 (0.004) 0.805 (0.004) 0.79 (0.004)

0.797 (0.005)

0.796 (0.005)

0.764 (0.009)

0.758 (0.002) 0.758 (0.002) 0.763 (0.002) 0.778 (0.002) 0.783 (0.001) 0.771 (0.002) 0.775 (0.001)

0.773 (0.001)

0.765 (0.001)

Misdemeanor 0.722 (0.005) 0.722 (0.005) 0.724 (0.006) 0.736 (0.006) 0.742 (0.005) 0.729 (0.005) 0.733 (0.006)

0.729 (0.006)

0.693 (0.010)

0.752 (0.004) 0.752 (0.004) 0.757 (0.004) 0.775 (0.003) 0.780 (0.003) 0.769 (0.005) 0.770 (0.004)

0.768 (0.004)

0.736 (0.004)

0.828 (0.006) 0.830 (0.005) 0.834 (0.005) 0.843 (0.005) 0.846 (0.005) 0.821 (0.011) 0.842 (0.005)

0.837 (0.004)

0.809 (0.005)

0.770 (0.003) 0.771 (0.003) 0.777 (0.004) 0.794 (0.004) 0.799 (0.002) 0.783 (0.005) 0.785 (0.004)

0.786 (0.004)

0.752 (0.006)

0.830 (0.010) 0.829 (0.011) 0.830 (0.013) 0.856 (0.009) 0.860 (0.011) 0.839 (0.014) 0.849 (0.011)

0.851 (0.010)

0.835 (0.009)

0.790 (0.002) 0.791 (0.002) 0.798 (0.003) 0.823 (0.003) 0.829 (0.003) 0.811 (0.005) 0.818 (0.004)

0.812 (0.004)

0.790 (0.005)

Misdemeanor 0.735 (0.006) 0.735 (0.006) 0.740 (0.007) 0.760 (0.005) 0.766 (0.005) 0.754 (0.005) 0.753 (0.006)

0.750 (0.006)

0.705 (0.005)

Two Year

Six Month

Two Year

Six Month

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony

General

Violent

Drug

Property

Felony


WANG & HAN ET AL.

47

TA B L E 1 6 Arnold Public Safety Assessment (PSA): New Criminal Activity (NCA)

New Criminal Activity (NCA)

Risk Factor

Value

Points

Age at Current Arrest

23 or older

Total NCA Points NCA Scaled Score

Point Scaling

Pending Charge at Time of Offense

22 or younger

0

2

0

3

0

1

0

1

0

1

1

2

0

1

2

0

2

No

Yes

No

Yes

No

Yes

0

1

2

0

1

No

Yes

3 or more

2 or more

Prior Misdemeanor Conviction

Prior Felony Conviction

Prior Violent Conviction

Prior FTA in Past 2 Years

Prior Sentence to Incarceration

0

1

2

3

4

5

6

7

8

9

10

11

12

13

1

2

2

3

3

4

4

5

5

6

6

6

6

6

TA B L E 1 7 Arnold Public Safety Assessment (PSA): New Violent Criminal Activity (NVCA)

New Violent Criminal Activity (NVCA)

Risk Factor

Value

Points

Current Violent Offense

Point Scaling

Total NVCA Points NVCA Scaled Score

Current Violent Offense and 20 Years or Younger

Pending Charge at Time of Offense

Prior Conviction (Misdemeanor or Felony)

Prior Violent Conviction

No

Yes

No

Yes

No

Yes

No

Yes

0

1

2

3 or more

0

2

0

1

0

1

0

1

0

1

1

2

0

1

2

3

4

5

6

7

No

No

No

No

Yes

Yes

Yes

Yes


48

WANG & HAN ET AL.

TA B L E 1 8 AUCs of the Arnold NVCA Raw, EBM and RiskSLIM on Kentucky for two-year violent recidivism,
conditioned on sensitive attributes. AUC ranges are also given for each sensitive attribute class

Kentucky

Race

Sex

Model

Label

Afr-Am.

Cauc.

Other Race

race_range

Female

Male

sex_range

Arnold NVCA Raw

violent_two_year

0.728

0.740

0.767

0.039

0.728

0.734

0.006

EBM

violent_two_year

0.775

0.770

0.766

0.009

0.744

0.766

0.022

RiskSLIM

violent_two_year

0.744

0.736

0.680

0.063

0.706

0.730

0.024

TA B L E 1 9 Race and gender distributions for Kentucky. Due to the low percentage of the Asians and Indians in
Kentucky, we included them in the "Other" category in the fairness analysis.

Kentucky

Attribute

Attribute Value

num_inds % total

African-American

42197

16.83

race

race

race

race

race

sex

sex

Asian

843

0.34

Caucasian

202341

80.69

Indian

Other

195

5202

0.08

2.07

female

79207

31.58

male

171571

68.42


WANG & HAN ET AL.

11.6 | Figures

49

F I G U R E 1 0 Base rates of all twelve types of recidivism on Kentucky data, conditioned (separately) on race and
gender.

F I G U R E 1 1 Probabilities of two-year and six-month violent recidivism, given the age at current charge.

drug_six_monthdrug_two_yearfelony_six_monthfelony_two_yeargeneral_six_monthgeneral_two_yearmisdemeanor_six_monthmisdemeanor_two_yearproperty_six_monthproperty_two_yearviolent_six_monthviolent_two_yearPrediction Problem0.000.050.100.150.200.250.30P(Y = 1 | Attr = attr)Cond. prob. of recidivism for all prediction problems on KentuckyAfrican-AmericanCaucasianOtherfemalemale                      S U R E D E L O L W \ O R F D W L R Q     . < W Z R B \ H D U V L [ B P R Q W K                                                                                               D J H B D W B F X U U H Q W B F K D U J H                      S U R E D E L O L W \ O R F D W L R Q     ) / 9 L R O H Q W  5 H F L G L Y L V P
50

WANG & HAN ET AL.

F I G U R E 1 2 Calibration of the Arnold NVCA Raw, EBM and RiskSLIM for two-year violent recidivism on
Kentucky.

(a) For the Arnold NVCA raw score, the curves satisfy mono
tonic calibration until the score value of 7, where the prob
abilities drop to 0. This may be because there are few

individuals with an Arnold NVCA raw score equal to 7 in

the data. The curves for African-Americans/Caucasians and

males/females are close enough to satisfy group calibration

(but we note that the African-American (respectively, male)

curve is consistently higher than the Caucasian (respectively,

female) curve), especially for larger raw NVCA scores.

(b) For EBM, the calibration curves for both gender and race

(c) For RiskSLIM, the curves are monotonically increasing and

groups are irregular, demonstrating that EBM satisﬁed nei
roughly overlap with each other. The calibration curve for

ther group calibration nor monotonic calibration, on race and

African-Americans is slightly higher than for the Caucasian

gender groups.

and the “Other” race groups. For the two gender groups, the

curves are close to each other. We conclude that both race

and gender approximately satisfy group calibration.

0246Arnold NVCA Raw Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of Arnold NVCA Raw on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale0.0-0.10.1-0.20.2-0.30.3-0.40.4-0.50.5-0.60.6-0.70.7-0.80.8-0.90.9-1.0EBM Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of EBM on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale0.0-0.10.1-0.20.2-0.30.3-0.40.4-0.50.5-0.60.6-0.70.7-0.80.8-0.90.9-1.0RiskSLIM Score0.00.20.40.60.81.0P(Y = 1 | Score = score, Attr = attr)Calib. of RiskSLIM on violent_two_year in KentuckyAll individualsAfrican-AmericanCaucasianOtherfemalemale
WANG & HAN ET AL.

51

F I G U R E 1 3 Balance for Positive and Negative Class for the Arnold NVCA Raw, EBM and RiskSLIM on the two-year
violent prediction problem in Kentucky. Red line indicates the maximum value output by models.

(a) Differences in expected scores for African-Americans

and Caucasians are greater than the threshold (0.2):

0.29 (race, negative class), 0.29 (race, positive class).

Differences in expected scores for gender are also

greater than the threshold: 0.38 (gender, negative

class) and 0.50 (gender, positive class).

(b) Differences in expected scores for African-Americans

(c) Differences in expected scores for African-Americans

and Caucasians are less than 0.03: 0.01 (race, negative

and Caucasians are less than 0.03: 0.01 (race, negative

class), 0.01 (race, positive class). Differences in expected

class), 0.02 (race, positive class). Differences in expected

scores for gender also satisfy the threshold: 0.00 (gender,

scores for gender satisfy the threshold for the negative

negative class) and 0.02 (gender, positive class).

class, but not for the positive class: 0.03 (gender, negative

class) and 0.06 (gender, positive class).

violent_bncviolent_bpc02468E(Arnold | Attr = attr, Y = i)1.863.131.572.841.152.551.352.491.732.99BPC/BNC for Arnold on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMaleviolent_bncviolent_bpc0.00.20.40.60.81.0E(EBM | Attr = attr, Y = i)0.010.030.00.020.00.010.00.010.00.03BPC/BNC for EBM on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMaleviolent_bncviolent_bpc0.00.20.40.60.81.0E(RiskSLIM | Attr = attr, Y = i)0.040.080.030.060.010.030.010.020.040.08BPC/BNC for RiskSLIM on violent_two_year in KentuckyAfr-Am.Cauc.Other RaceFemaleMale
52

WANG & HAN ET AL.

11.7 | Nested Cross Validation Procedure

We applied ﬁve-fold nested cross validation to tune parameters. We split the entire data set into ﬁve equally-sized folds

for the outer cross validation step. One fold was used as the holdout test set and the other four folds were used as the
training set (call it “outer training set”). The inner loop deals only with the outer training set ( 45 ths of the data). On this
outer training set, we conducted ﬁve-fold cross validation and grid-searched hyperparameter values. After this point,

each hyperparameter value had ﬁve validation results. We selected the parameter values with the highest average

validation results and then trained the model with this best set of parameters on the entire outer training set and tested

We repeated the process above until each one of the original ﬁve folds was used as the holdout test set. Ultimately,

we had ﬁve holdout test results, with which we were able to calculate the average and standard deviation of the

it on the holdout test set.

performance.

We applied a variant of the nested cross validation procedure described above to perform the analysis discussed

in Section 8—where we trained models on one region and tested on the other region. For instance, when we trained

models on Broward and tested them on Kentucky, the Kentucky data was treated as the holdout test set. We split

the Broward data into ﬁve folds and used four folds to do cross validation and constructed the ﬁnal model using the

best parameters. We then tested the ﬁnal model on the entire Kentucky data set, as well as the holdout test set from

Broward. We rotated the four folds and repeated the above process ﬁve times.


WANG & HAN ET AL.

11.8 | RiskSLIM Tables

53

TA B L E 2 0 Two Year Prediction Problems—Kentucky. Here, counts of prior arrests indicate the counts of arrests
with at least one convicted charge. All charges mentioned are convicted charges. ADE indicates assignment to alcohol
and drug education classes.

Two Year General Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-6 + score)))

Two Year Violent Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))

sex = Male

number of prior arrests≥2

number of prior arrests≥3

number of prior arrests≥5

1 points

1 points

1 points

+...

+...

+...

age at current charge ≤ 27

number of prior arrests≥2

number of prior violent charges≥1

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

sentenced to incarceration before = Yes

1 points

1 points

1 points

1 points

1 points

+...

+...

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....

Two Year Drug Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

number of prior arrests≥2

number of prior drug related

charges≥1

1 points

1 points

+...

+...

charges≥1

number of times charged with

1 points

+...

a new offense when there is a pending case≥1

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

Two Year Property Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

number of prior property related

1 points

+...

number of prior arrests≥3

number of times charged with

1 points

1 points

+...

+...

a new offense when there is a pending case≥1

number of prior ADE ≥1

-1 points

+...

ADD POINTS FROM ROWS 1 TO 4

SCORE

= .....

Two Year Felony Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

Two Year Misdemeanor Recidivism

age at current charge ≤ 43

number of prior arrests≥2

number of prior felony level charges≥1

number of times charged with

a new offense when there is a pending case≥1

1 points

1 points

1 points

1 points

+...

+...

+...

+...

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

number of prior arrests≥2

number of times charged with

a new offense when there is a pending case≥1

1 points

1 points

+...

+...

sentenced to incarceration before = Yes

1 points

+...

sentenced to incarceration before = Yes

1 points

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....


54

WANG & HAN ET AL.

TA B L E 2 1 Six Month Prediction Problems—Kentucky. Here, counts of prior arrests indicate the counts of arrests
with at least one convicted charge. All charges mentioned are convicted charges. ADE means assignment to alcohol and
drug education classes.

Six Month General Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-7 + score)))

Six Month Violent Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

number of prior arrests≥2

number of prior arrests≥4

number of times charged with

a new offense when there is a pending case≥1

1 points

1 points

1 points

+...

+...

+...

number of prior violent charges≥1

number of prior arrests≥3

number of prior felony level charges≥1

current violent charge = Yes

number of times charged with

1 points

1 points

1 points

1 points

1 points

+...

+...

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

a new offense when there is a pending case≥1

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....

Six Month Drug Recidivism

Six Month Property Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

Pr(Y = +1) = 1 / (1 + exp(-(-7 + score)))

number of prior drug related charges≥1

number of prior property related charges≥1

number of prior drug related charges≥3

number of prior felony level charges≥1

1 points

1 points

1 points

+...

+...

+...

number of times charged with

a new offense when there is a pending case≥1

number of prior FTA within last two years ≥1

1 points

number of times charged with

1 points

number of prior ADE≥1

-1 points

+...

a new offense when there is a pending case≥1

2 points

1 points

+...

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 4

SCORE

= .....

ADD POINTS FROM ROWS 1 TO 4

SCORE

= .....

Six Month Felony Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

number of prior arrests≥3

number of prior felony level charges≥1

number of times charged with

a new offense when there is a pending case≥1

Six Month Misdemeanor Recidivism

1 points

1 points

1 points

+...

+...

+...

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

number of prior arrests≥2

number of prior arrests≥4

1 points

1 points

+...

+...

ADD POINTS FROM ROWS 1 TO 2

SCORE

= .....

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....


WANG & HAN ET AL.

55

TA B L E 2 2 Two Year Prediction Problems—Broward. Here, counts of prior arrests indicate the counts of arrests
with at least one non-convicted or convicted charge. All charges mentioned are non-convicted charges.

Two Year Violent Recidivism

Two Year General Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))

age at current charge≤30

age at current charge ≤31

1 points

number of prior violent charges≥4

number of prior misdemeanor level charges ≥4

1 points

number of prior arrests≥7

had charge(s) within last three years = Yes

1 points

current violent charge=Yes

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

had charge(s) within last three year = Yes

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....

1 points

1 points

1 points

1 points

1 points

1 points

1 points

1 points

1 points

1 points

+...

+...

+...

+...

+...

+...

+...

+...

+...

+...

Two Year Property Recidivism

Two Year Drug Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

age at current charge≤33

age at current charge ≤18

age at current charge ≤23

number of prior drug related charges≥1

number of prior property related charges≥1

number of prior drug related charges≥4

number of prior property related charges≥5

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

number of prior violent charges≥4

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 5

SCORE

= .....

Two Year Felony Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

age at current charge ≤33

number of prior misdemeanor

level charges≥4

1 points

1 points

+...

+...

Two Year Misdemeanor Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-2 + score)))

age at ﬁrst charge≤30

number of FTA within last two years≥1

1 points

1 points

+...

+...

number of prior property related charges≥4

1 points

+...

ADD POINTS FROM ROWS 1 TO 2

SCORE

= .....

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....


56

WANG & HAN ET AL.

TA B L E 2 3 Six Month Prediction Problems—Broward. Here, counts of prior arrests indicate the counts of arrests
with at least one non-convicted or convicted charge. All charges mentioned are non-convicted charges.

Six Month General Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

age at ﬁrst charge≤28

had charge(s) within last three years = Yes

1 points

1 points

+...

+...

ADD POINTS FROM ROWS 1 TO 2

SCORE

= .....

Six Month Violent Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-4 + score)))

current violent charge = Yes

number of prior violent charges ≥4

had charge(s) within last three years = Yes

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

Six Month Drug Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

age at ﬁrst charge≤21

number of prior drug charges≥2

had charge(s) within last year = Yes

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....

Six Month Property Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-5 + score)))

age at current charge≤29

1 points

+ ...

number of prior misdemeanor level charges≥5

1 points

number of prior property related charges≥1

number of prior property related charges≥4

+...

+...

+...

1 points

1 points

ADD POINTS FROM ROWS 1 TO 4

SCORE

= .....

Six Month Felony Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

age at current charge≤29

number of prior property related charges≥4

1 points

1 points

+...

+...

ADD POINTS FROM ROWS 1 TO 2

SCORE

= .....

Six Month Misdemeanor Recidivism

Pr(Y = +1) = 1 / (1 + exp(-(-3 + score)))

age at current charge≤19

number of prior weapon related charges≥1

had charge(s) within last three years = Yes

1 points

1 points

1 points

+...

+...

+...

ADD POINTS FROM ROWS 1 TO 3

SCORE

= .....


WANG & HAN ET AL.

11.9 | Features

57

TA B L E 2 4 Features from Broward data set. Recall that charges can be convicted or non-convicted.

person_id

unique personal identiﬁer

sex

race

biological sex of the person

race of the person

screening_date

date that triggered the COMPAS screening

age_at_current_charge age at the person’s current charge

age_at_ﬁrst_charge

age at the person’s ﬁrst charge

p_arrest

count of prior arrests

p_charges

count of prior charges

p_violence

count of prior violent charges

p_felony

count of prior felony-level charges

p_misdemeanor

count of prior misdemeanor-level charges

p_juv_fel_count

count of prior felony-level and juvenile charges

p_property

count of prior property-related charges

p_murder

count of prior murder charges

p_famviol

count of prior family violence charges

p_sex_offenses

count of prior sex offense charges

p_weapon

count of prior weapon-related charges

p_felprop_viol

count of prior felony-level, property-related, and violent charges

p_felassault

count of prior felony-level assault charges

p_misdeassault

count of prior misdemeanor-level assault charges

p_trafﬁc

count of prior trafﬁc-related charges

p_drug

p_dui

count of prior drug-related charges

count of prior DUI charges

p_stalking

count of prior stalking charges

p_voyeurism

count of prior voyeurism charges

p_fraud

count of prior fraud charges

p_stealing

count of prior stealing/theft charges

p_domestic

count of prior domestic violence charges

p_trespass

count of prior trespass charges

p_fta_two_year

count of prior failures to appear in court within last two years (≤ 2 years)

p_fta_two_year_plus

count of prior failures to appear in court beyond last two years (> 2 years)

p_pending_charge

count of times charged with a new offense when there was a pending case

p_probation

count of times charged with a new offense when the person was on probation

p_incarceration

whether or not the person was formerly sentenced to incarceration

six_month

whether or not the person had charges within last six months (≤ 6 months)

one_year

whether or not the person had charges within last year (≤ 1 year)

three_year

whether or not the person had charges within last three years (≤ 3 years)

ﬁve_year

whether or not the person had charges within last ﬁve years (≤ 5 years)

current_violence

whether or not the current charge is violent

current_violence20 whether or not the current charge is violent and the person is ≤ 20 years old

total_convictions

total count of convictions


58

WANG & HAN ET AL.

TA B L E 2 5 Features from Kentucky data set. The charges are convicted. ADE means assignment to alcohol and drug
education classes.

current_date

current charge date or the release date if there was a sentence on the current charge.

age_at_current_charge

age at the person’s current charge, or the age at current charge plus the sentence time if there was

person_id

unique personal identiﬁer

sex

race

biological sex of the person

race of the person

a sentence on the current charge

p_arrest

count of prior arrests with convicted charges

p_charges

count of prior convicted charges

p_violence

count of prior violent charges

p_felony

count of prior felony-level charges

p_misdemeanor

count of prior misdemeanor-level charges

p_property

count of prior property-related charges

p_murder

count of prior murder charges

p_assault

count of prior assault charges

p_sex_offenses

count of prior sex offense charges

p_weapon

count of prior weapon-related charges

p_felprop_viol

count of prior felony-level, property-related, and violent charges

p_felassault

count of prior felony-level assault charges

p_misdeassault

count of prior misdemeanor-level assault charges

p_trafﬁc

count of prior trafﬁc-related charges

p_drug

p_dui

count of prior drug-related charges

count of prior DUI charges

p_stalking

count of prior stalking charges

p_voyeurism

count of prior voyeurism charges

p_fraud

count of prior fraud charges

p_stealing

count of prior stealing/theft charges

p_trespass

count of prior trespass charges

ADE

count of times the person was assigned to alcohol/drug education classes

treatment

count of times the person received treatment along with the sentence

p_fta_two_year

count of prior failures to appear in court within last two years (≤ 2 years)

p_fta_two_year_plus

count of prior failures to appear in court beyond last two years (> 2 years)

p_pending_charge

count of times charged with a new offense when there was a pending case

p_probation

count of times charged with a new offense when the person was on probation

p_incarceration

whether or not the person was formerly sentenced to incarceration

six_month

whether or not the person had charges within last six months (≤ 6 months)

one_year

whether or not the person had charges within last year (≤ 1 year)

three_year

whether or not the person had charges within last three years (≤ 3 years)

ﬁve_year

whether or not the person had charges within last ﬁve years (≤ 5 years)

current_violence

whether or not the current charge was violent

current_violence20

whether or not the current charge was violent and the person was ≤ 20 years old

current_pending_charge whether or not the person had a pending case during the current charge


