<html>

              <head>
                  <link href="https://fonts.googleapis.com/css2?family=Baskervville&family=Libre+Baskerville&display=swap" rel="stylesheet">
                  <style>
                      body{
                        font-family: 'Baskervville', serif;font-family: 'Libre Baskerville', serif;
                        width: 75%;
                        margin: auto;
                      }

                      h1{
                          text-align: center;
                      }

                      p{
                          line-height: 25px;
                      }

                      .highlight{
                          background-color: black;
                          font-style: bold;
                          color: white;
                      }

                      .k1{background-color: #c0cde4;color: black;font-style: bold;}
                      .k2{background-color: #5191f9;color: white;font-style: bold;}
                      .k3{background-color: #78e620;color: white;font-style: bold;}
                      .k4{background-color: #5c5376;color: white;font-style: bold;}
                      .k5{background-color: #f7b9e8;color: black;font-style: bold;}
                      .k6{background-color: #ccf1c0;color: black;font-style: bold;}
                      .k7{background-color: #af98e9;color: white;font-style: bold;}
                      .k8{background-color: #2a52a8;color: white;font-style: bold;}
                  </style>
              </head>

              <body>
                <h1>Original Text</h1><br>
                  <p>Current <font class='highlight k1'>operating systems</font> have evolved over the last forty years into complex overlapping code bases [70, 4, 51, 57], which were architected for very different environments than exist today. The cloud has become a preferred platform, for both decision support and online serving applications. Serverless computing supports the concept of elastic provision of resources, which is very attractive in many environments. Machine learning (ML) is causing many applications to be redesigned, and future <font class='highlight k2'>operating systems</font> must intimately support such applications. Hardware is becoming massively parallel and heterogeneous. These “sea changes” make it imperative to rethink the architecture of <font class='highlight k3'>system software</font>, which is the topic of this paper.
Mainstream operating systems (OSs) date from the 1980s and were designed for the hardware platforms of 40 years ago, consisting of a single processor, limited main memory and a small set of runnable tasks. Today’s cloud platforms contain hundreds of thousands of processors, heterogeneous computing resources (including CPUs, GPUs, FPGAs, TPUs, SmartNICs, and so on) and multiple levels of memory and storage. These platforms support millions of active users that access thousands of services. Hence, the OS must deal with a scale problem of 105 or 106 more resources to manage and schedule. Managing OS state is a much bigger problem than <font class='highlight k4'>40 years ago</font> in terms of both throughput and latency, as thousands of services must communicate to respond in near real-time to a user’s click [21, 5].
Forty years ago, there was little thought about parallelism. After all, there was only one processor. Now it is not unusual to run Map-Reduce or Apache Spark jobs with thousands of processes using millions of threads [13]. Stragglers creating long-tails inevitably result from substantial parallelism and are the bane of modern systems: incredibly costly and nearly impossible to debug [21].
Forty years ago programmers typically wrote monolithic programs that ran to completion and exited. Now, programs may be coded in multiple languages, make use of libraries of services (like search, communications, databases, ML, and others), and may run continuously with varying load. As a result, debugging has become much more complex and involves a flow of control in multiple environments. Debugging such a network of tasks is a real challenge, not considered <font class='highlight k5'>forty years</font> ago.
Forty years ago there was little-to-no-thought about privacy and fraud. Now, GDPR [73] dictates system behavior for Personally Identifiable Information (PII) on systems that are under continuous attack. Future systems should build in support for such constructs. Moreover, there are many cases of bad actors doctoring photos or videos, and there is no chain of provenance to automatically record and facilitate exposure of such activity.
Machine learning (ML) is quickly becoming central to all large software systems. However, ML is typically bolted onto the top of most systems as an after thought. Application and system developers struggle to identify the right data for ML analysis and to manage synchronization, ordering, freshness, privacy, provenance, and performance concerns. Future systems should directly support and enable AI applications and AI introspection, including first-order support for declarative semantics for AI operations on system data.
In our opinion, serverless computing will become the dominant cloud architecture. One does not need to spin up a virtual machine (VM), which will sit idle when there is no work to do. Instead, one should use an execution environment like Amazon Lambda. Lambda is an efficient task manager that encourages one to divide up a user task into a pipeline of severalto-many subtasks1. Resources are allocated to a task when it is running, and no resources are consumed at other times. In this way, there are no dedicated VMs; instead there is a collection of short-running subtasks. As such, users only pay for the resources that they consume and their applications can scale to thousands of functions when needed. We expect that Lambda will become the dominant cloud environment unless the cloud vendors radically modify their pricing algorithms. Lambda will cause many more tasks to exist, creating a more expansive task management problem.
Lastly, “bloat” has wrecked havoc on elderly OSs, and the pathlength of common operations such as sending a message and reading bytes from a file are now uncompetitively expensive. One key reason for the bloat is the uncontrolled layering of abstractions. Having a clean, declarative way of capturing and operating on <font class='highlight k6'>operating system state</font> can help reduce that layering.
These changed circumstances dictate that system software should be reconsidered. In this proposal, we explore a radically different design for <font class='highlight k7'>operating systems</font> that we believe will scale to support the performance, management and security challenges of modern computing workloads: a data-centric architecture for operating systems built around clean separation of 1In this paper, we will use Lambda as an exemplar of any resource allocation system that supports “pay only for what you use.” all state into database tables, and leveraging the extensive work in DBMS engine technology to provide scalability, high performance, ease of management and security. We sketch why this design could eliminate many of the difficult software engineering challenges in current OSes and how it could aid important applications such as HPC and Internet service workloads. In the next seven sections, we describe the main tenets of this data-centric architecture. Then, in Section 9, we sketch a proposal concerning how to move forward.</p>
                <hr>
                <h1>Fake Text</h1><br>
                  <p>Current <font class='highlight k1'>machine operating sound</font>, vision and hearing systems are increasingly relying on computer-aided design to perform basic image and sound processing tasks. The cloud has become a preferred platform, for both decision support and online serving applications. Serverless computing supports the concept of elastic provision of resources, which is very attractive in many environments. Machine learning (ML) is causing many applications to be redesigned, and future <font class='highlight k2'>machine operating sound</font> systems will probably employ ML algorithms [1].  The popularity and volume of ML applications in serverless computing make it increasingly challenging to keep up. Hardware is becoming massively parallel and heterogeneous. These “sea changes” make it imperative to rethink the architecture of <font class='highlight k3'>system protection software</font>, and how it supports the scalability and adaptability of serverless computing. The emergence of ML applications has been greatly mitigated by various techniques, e.g., deep learning, deep Q network (DQN) [2], and distributed optimization [3], which are applied across a wide variety of applications. Today’s cloud platforms contain hundreds of thousands of processors, heterogeneous computing resources (including CPUs, GPUs, FPGAs, TPUs, SmartNICs, and so on) and multiple levels of memory and storage. These platforms support millions of active users that access thousands of services. Hence, the OS must deal with a scale problem of 105 or 106 more resources to manage and schedule. Managing OS state is a much bigger problem than <font class='highlight k4'>speculative twenty years ago</font>.  In this paper, we propose a novel approach to manage the OS state. We propose a novel approach based on the concept of “volume” of applications, and we prove that the average number of applications per user on a server is 104, which is signiﬁcant in today’s data-hungry and networked systems. After all, there was only one processor. Now it is not unusual to run Map-Reduce or Apache Spark jobs with thousands of processes using millions of threads [13]. Stragglers creating long-tails inevitably result from substantial parallelism and are the bane of modern systems: incredibly costly and nearly impossible to debug [21].
Forty years ago programmers typically wrote monolithic programs that ran to completion and exited. Now, programs may be coded in multiple languages, make use of libraries of services (like search, communications, databases, ML, and others), and may run continuously with varying load. As a result, debugging has become much more complex and involves a flow of control in multiple environments. Debugging such a network of tasks is a real challenge, not considered <font class='highlight k5'>speculative twenty years ago</font>. Now, GDPR [73] dictates system behavior for Personally Identifiable Information (PII) on systems that are under continuous attack. Future systems should build in support for such constructs. Moreover, there are many cases of bad actors doctoring photos or videos, and there is no chain of provenance to automatically record and facilitate exposure of such activity.
Machine learning (ML) is quickly becoming central to all large software systems. However, ML is typically bolted onto the top of most systems as an after thought. Application and system developers struggle to identify the right data for ML analysis and to manage synchronization, ordering, freshness, privacy, provenance, and performance concerns. Future systems should directly support and enable AI applications and AI introspection, including first-order support for declarative semantics for AI operations on system data.
In our opinion, serverless computing will become the dominant cloud architecture. One does not need to spin up a virtual machine (VM), which will sit idle when there is no work to do. Instead, one should use an execution environment like Amazon Lambda. Lambda is an efficient task manager that encourages one to divide up a user task into a pipeline of severalto-many subtasks1. Resources are allocated to a task when it is running, and no resources are consumed at other times. In this way, there are no dedicated VMs; instead there is a collection of short-running subtasks. As such, users only pay for the resources that they consume and their applications can scale to thousands of functions when needed. We expect that Lambda will become the dominant cloud environment unless the cloud vendors radically modify their pricing algorithms. Lambda will cause many more tasks to exist, creating a more expansive task management problem.
Lastly, “bloat” has wrecked havoc on elderly OSs, and the pathlength of common operations such as sending a message and reading bytes from a file are now uncompetitively expensive. One key reason for the bloat is the uncontrolled layering of abstractions. Having a clean, declarative way of capturing and operating on <font class='highlight k6'>state machines</font> is crucial for achieving scalable and effective systems.  In this paper, we propose a new approach to task schedulers by considering their inner workings as human-machine interaction, by asking what actions a human needs to take in order to achieve a given task. In this proposal, we explore a radically different design for <font class='highlight k7'>machine operating sound</font>. We sketch why this design could eliminate many of the difficult software engineering challenges in current OSes and how it could aid important applications such as HPC and Internet service workloads. In the next seven sections, we describe the main tenets of this data-centric architecture. Then, in Section 9, we sketch a proposal concerning how to move forward.</p>
              </body>
            </html>