<html>

              <head>
                  <link href="https://fonts.googleapis.com/css2?family=Baskervville&family=Libre+Baskerville&display=swap" rel="stylesheet">
                  <style>
                      body{
                        font-family: 'Baskervville', serif;font-family: 'Libre Baskerville', serif;
                        width: 75%;
                        margin: auto;
                      }

                      h1{
                          text-align: center;
                      }

                      p{
                          line-height: 25px;
                      }

                      .highlight{
                          background-color: black;
                          font-style: bold;
                          color: white;
                      }

                      .k1{background-color: #c0cde4;color: black;font-style: bold;}
                      .k2{background-color: #5191f9;color: white;font-style: bold;}
                      .k3{background-color: #78e620;color: white;font-style: bold;}
                      .k4{background-color: #5c5376;color: white;font-style: bold;}
                      .k5{background-color: #f7b9e8;color: black;font-style: bold;}
                      .k6{background-color: #ccf1c0;color: black;font-style: bold;}
                      .k7{background-color: #af98e9;color: white;font-style: bold;}
                      .k8{background-color: #2a52a8;color: white;font-style: bold;}
                  </style>
              </head>

              <body>
                <h1>Original Text</h1><br>
                  <p>Current <font id='orig-1' class='highlight k1'><a href='#fake-1'>operating systems</a></font> have evolved over the last forty years into complex overlapping code bases [70, 4, 51, 57], which were architected for very different environments than exist today. The cloud has become a preferred platform, for both decision support and online serving applications. Serverless computing supports the concept of elastic provision of resources, which is very attractive in many environments. Machine learning (ML) is causing many applications to be redesigned, and future <font id='orig-2' class='highlight k2'><a href='#fake-2'>operating systems</a></font> must intimately support such applications. Hardware is becoming massively parallel and heterogeneous. These “sea changes” make it imperative to rethink the architecture of <font id='orig-3' class='highlight k3'><a href='#fake-3'>system software</a></font>, which is the topic of this paper.
Mainstream operating systems (OSs) date from the 1980s and were designed for the hardware platforms of 40 years ago, consisting of a single processor, limited main memory and a small set of runnable tasks. Today’s cloud platforms contain hundreds of thousands of processors, heterogeneous computing resources (including CPUs, GPUs, FPGAs, TPUs, SmartNICs, and so on) and multiple levels of memory and storage. These platforms support millions of active users that access thousands of services. Hence, the OS must deal with a scale problem of 105 or 106 more resources to manage and schedule. Managing OS state is a much bigger problem than <font id='orig-4' class='highlight k4'><a href='#fake-4'>40 years ago</a></font> in terms of both throughput and latency, as thousands of services must communicate to respond in near real-time to a user’s click [21, 5].
Forty years ago, there was little thought about parallelism. After all, there was only one processor. Now it is not unusual to run Map-Reduce or Apache Spark jobs with thousands of processes using millions of threads [13]. Stragglers creating long-tails inevitably result from substantial parallelism and are the bane of modern systems: incredibly costly and nearly impossible to debug [21].
Forty years ago programmers typically wrote monolithic programs that ran to completion and exited. Now, programs may be coded in multiple languages, make use of libraries of services (like search, communications, databases, ML, and others), and may run continuously with varying load. As a result, debugging has become much more complex and involves a flow of control in multiple environments. Debugging such a network of tasks is a real challenge, not considered <font id='orig-5' class='highlight k5'><a href='#fake-5'>forty years</a></font> ago.
Forty years ago there was little-to-no-thought about privacy and fraud. Now, GDPR [73] dictates system behavior for Personally Identifiable Information (PII) on systems that are under continuous attack. Future systems should build in support for such constructs. Moreover, there are many cases of bad actors doctoring photos or videos, and there is no chain of provenance to automatically record and facilitate exposure of such activity.
Machine learning (ML) is quickly becoming central to all large software systems. However, ML is typically bolted onto the top of most systems as an after thought. Application and system developers struggle to identify the right data for ML analysis and to manage synchronization, ordering, freshness, privacy, provenance, and performance concerns. Future systems should directly support and enable AI applications and AI introspection, including first-order support for declarative semantics for AI operations on system data.
In our opinion, serverless computing will become the dominant cloud architecture. One does not need to spin up a virtual machine (VM), which will sit idle when there is no work to do. Instead, one should use an execution environment like Amazon Lambda. Lambda is an efficient task manager that encourages one to divide up a user task into a pipeline of severalto-many subtasks1. Resources are allocated to a task when it is running, and no resources are consumed at other times. In this way, there are no dedicated VMs; instead there is a collection of short-running subtasks. As such, users only pay for the resources that they consume and their applications can scale to thousands of functions when needed. We expect that Lambda will become the dominant cloud environment unless the cloud vendors radically modify their pricing algorithms. Lambda will cause many more tasks to exist, creating a more expansive task management problem.
Lastly, “bloat” has wrecked havoc on elderly OSs, and the pathlength of common operations such as sending a message and reading bytes from a file are now uncompetitively expensive. One key reason for the bloat is the uncontrolled layering of abstractions. Having a clean, declarative way of capturing and operating on <font id='orig-6' class='highlight k6'><a href='#fake-6'>operating system state</a></font> can help reduce that layering.
These changed circumstances dictate that system software should be reconsidered. In this proposal, we explore a radically different design for <font id='orig-7' class='highlight k7'><a href='#fake-7'>operating systems</a></font> that we believe will scale to support the performance, management and security challenges of modern computing workloads: a data-centric architecture for operating systems built around clean separation of 1In this paper, we will use Lambda as an exemplar of any resource allocation system that supports “pay only for what you use.” all state into database tables, and leveraging the extensive work in DBMS engine technology to provide scalability, high performance, ease of management and security. We sketch why this design could eliminate many of the difficult software engineering challenges in current OSes and how it could aid important applications such as HPC and Internet service workloads. In the next seven sections, we describe the main tenets of this data-centric architecture. Then, in Section 9, we sketch a proposal concerning how to move forward.</p>
                <hr>
                <h1>Fake Text</h1><br>
                  <p>Current <font id='fake-1' class='highlight k1'><a href='#orig-1'>machine operating sound</a></font> is governed by the International Electrotechnical Commission (IEC) standard Tsuchiya (1986), which sets strict performance requirements for various components of machine learning, including the training of neural networks. The cloud has become a preferred platform, for both decision support and online serving applications. Serverless computing supports the concept of elastic provision of resources, which is very attractive in many environments. Machine learning (ML) is causing many applications to be redesigned, and future <font id='fake-2' class='highlight k2'><a href='#orig-2'>machine operating sound</a></font> systems will be in need of fundamental sound system improvements. Hardware is becoming massively parallel and heterogeneous. These “sea changes” make it imperative to rethink the architecture of <font id='fake-3' class='highlight k3'><a href='#orig-3'>system protection software</a></font>.  In this paper, we review the state-of-the-art in various industrial applications to detect, de-identified, and to classify sound systems. Today’s cloud platforms contain hundreds of thousands of processors, heterogeneous computing resources (including CPUs, GPUs, FPGAs, TPUs, SmartNICs, and so on) and multiple levels of memory and storage. These platforms support millions of active users that access thousands of services. Hence, the OS must deal with a scale problem of 105 or 106 more resources to manage and schedule. Managing OS state is a much bigger problem than <font id='fake-4' class='highlight k4'><a href='#orig-4'>speculative twenty years ago</a></font>.  The most common and effective sound security solutions are based on the concept of intrusion detection systems or on the passive authentication techniques. After all, there was only one processor. Now it is not unusual to run Map-Reduce or Apache Spark jobs with thousands of processes using millions of threads [13]. Stragglers creating long-tails inevitably result from substantial parallelism and are the bane of modern systems: incredibly costly and nearly impossible to debug [21].
Forty years ago programmers typically wrote monolithic programs that ran to completion and exited. Now, programs may be coded in multiple languages, make use of libraries of services (like search, communications, databases, ML, and others), and may run continuously with varying load. As a result, debugging has become much more complex and involves a flow of control in multiple environments. Debugging such a network of tasks is a real challenge, not considered <font id='fake-5' class='highlight k5'><a href='#orig-5'>speculative twenty years ago</a></font>. Now, GDPR [73] dictates system behavior for Personally Identifiable Information (PII) on systems that are under continuous attack. Future systems should build in support for such constructs. Moreover, there are many cases of bad actors doctoring photos or videos, and there is no chain of provenance to automatically record and facilitate exposure of such activity.
Machine learning (ML) is quickly becoming central to all large software systems. However, ML is typically bolted onto the top of most systems as an after thought. Application and system developers struggle to identify the right data for ML analysis and to manage synchronization, ordering, freshness, privacy, provenance, and performance concerns. Future systems should directly support and enable AI applications and AI introspection, including first-order support for declarative semantics for AI operations on system data.
In our opinion, serverless computing will become the dominant cloud architecture. One does not need to spin up a virtual machine (VM), which will sit idle when there is no work to do. Instead, one should use an execution environment like Amazon Lambda. Lambda is an efficient task manager that encourages one to divide up a user task into a pipeline of severalto-many subtasks1. Resources are allocated to a task when it is running, and no resources are consumed at other times. In this way, there are no dedicated VMs; instead there is a collection of short-running subtasks. As such, users only pay for the resources that they consume and their applications can scale to thousands of functions when needed. We expect that Lambda will become the dominant cloud environment unless the cloud vendors radically modify their pricing algorithms. Lambda will cause many more tasks to exist, creating a more expansive task management problem.
Lastly, “bloat” has wrecked havoc on elderly OSs, and the pathlength of common operations such as sending a message and reading bytes from a file are now uncompetitively expensive. One key reason for the bloat is the uncontrolled layering of abstractions. Having a clean, declarative way of capturing and operating on <font id='fake-6' class='highlight k6'><a href='#orig-6'>state machines</a></font>, such as hashing and compression, is vital to achieving efﬁcient computation and security management.  In this paper, we propose a new approach to addressing the above problems by decomposing and automating some of the most common operations on machine data. In this proposal, we explore a radically different design for <font id='fake-7' class='highlight k7'><a href='#orig-7'>machine operating sound</a></font> in the absence of an operational system, by considering the evolution of mathematical functions in a hierarchical manner, and we derive a coherent mathematical formalism for these computations. We sketch why this design could eliminate many of the difficult software engineering challenges in current OSes and how it could aid important applications such as HPC and Internet service workloads. In the next seven sections, we describe the main tenets of this data-centric architecture. Then, in Section 9, we sketch a proposal concerning how to move forward.</p>
              </body>
            </html>