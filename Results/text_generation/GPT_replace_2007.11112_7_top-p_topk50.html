<html>

              <head>
                  <link href="https://fonts.googleapis.com/css2?family=Baskervville&family=Libre+Baskerville&display=swap" rel="stylesheet">
                  <style>
                      body{
                        font-family: 'Baskervville', serif;font-family: 'Libre Baskerville', serif;
                        width: 75%;
                        margin: auto;
                      }

                      h1{
                          text-align: center;
                      }

                      p{
                          line-height: 25px;
                      }

                      .highlight>a{
                        text-decoration: none;
                        outline: none;                        
                      }

                      .highlight{
                          background-color: black;
                          font-style: bold;
                          color: white;
                      }

                      a{
                        background-color: black;
                        color: white;
                        font-style: bold;
                      }

                      .k1>a{background-color: #c0cde4;color: black;font-style: bold;}
                      .k2>a{background-color: #5191f9;color: white;font-style: bold;}
                      .k3>a{background-color: #78e620;color: white;font-style: bold;}
                      .k4>a{background-color: #5c5376;color: white;font-style: bold;}
                      .k5>a{background-color: #f7b9e8;color: black;font-style: bold;}
                      .k6>a{background-color: #ccf1c0;color: black;font-style: bold;}
                      .k7>a{background-color: #af98e9;color: white;font-style: bold;}
                      .k8>a{background-color: #2a52a8;color: white;font-style: bold;}
                  </style>
              </head>

              <body>
                <h1>Original Text</h1><br>
                  <p>Current <font id='orig-1' class='highlight k1'><a href='#fake-1'>operating systems</a></font> have evolved over the last forty years into complex overlapping code bases [70, 4, 51, 57], which were architected for very different environments than exist today. The cloud has become a preferred platform, for both decision support and online serving applications. Serverless computing supports the concept of elastic provision of resources, which is very attractive in many environments. Machine learning (ML) is causing many applications to be redesigned, and future <font id='orig-2' class='highlight k2'><a href='#fake-2'>operating systems</a></font> must intimately support such applications. Hardware is becoming massively parallel and heterogeneous. These “sea changes” make it imperative to rethink the architecture of <font id='orig-3' class='highlight k3'><a href='#fake-3'>system software</a></font>, which is the topic of this paper.
Mainstream operating systems (OSs) date from the 1980s and were designed for the hardware platforms of 40 years ago, consisting of a single processor, limited main memory and a small set of runnable tasks. Today’s cloud platforms contain hundreds of thousands of processors, heterogeneous computing resources (including CPUs, GPUs, FPGAs, TPUs, SmartNICs, and so on) and multiple levels of memory and storage. These platforms support millions of active users that access thousands of services. Hence, the <font id='orig-4' class='highlight k4'><a href='#fake-4'>OS</a></font> must deal with a scale problem of 105 or 106 more resources to manage and schedule. Managing <font id='orig-5' class='highlight k5'><a href='#fake-5'>OS</a></font> state is a much bigger problem than 40 years ago in terms of both throughput and latency, as thousands of services must communicate to respond in near real-time to a user’s click [21, 5].
Forty years ago, there was little thought about parallelism. After all, there was only one processor. Now it is not unusual to run Map-Reduce or Apache Spark jobs with thousands of processes using millions of threads [13]. Stragglers creating long-tails inevitably result from substantial parallelism and are the bane of modern systems: incredibly costly and nearly impossible to debug [21].
Forty years ago programmers typically wrote monolithic programs that ran to completion and exited. Now, programs may be coded in multiple languages, make use of libraries of services (like search, communications, databases, ML, and others), and may run continuously with varying load. As a result, debugging has become much more complex and involves a flow of control in multiple environments. Debugging such a network of tasks is a real challenge, not <font id='orig-6' class='highlight k6'><a href='#fake-6'>considered forty years ago</a></font>.
Forty years ago there was little-to-no-thought about privacy and fraud. Now, GDPR [73] dictates system behavior for Personally Identifiable Information (PII) on systems that are under continuous attack. Future systems should build in support for such constructs. Moreover, there are many cases of bad actors doctoring photos or videos, and there is no chain of provenance to automatically record and facilitate exposure of such activity.
Machine learning (ML) is quickly becoming central to all large software systems. However, ML is typically bolted onto the top of most systems as an after thought. Application and system developers struggle to identify the right data for ML analysis and to manage synchronization, ordering, freshness, privacy, provenance, and performance concerns. Future systems should directly support and enable AI applications and AI introspection, including first-order support for declarative semantics for AI operations on system data.
In our opinion, serverless computing will become the dominant cloud architecture. One does not need to spin up a virtual machine (VM), which will sit idle when there is no work to do. Instead, one should use an execution environment like Amazon Lambda. Lambda is an efficient task manager that encourages one to divide up a user task into a pipeline of severalto-many subtasks1. Resources are allocated to a task when it is running, and no resources are consumed at other times. In this way, there are no dedicated VMs; instead there is a collection of short-running subtasks. As such, users only pay for the resources that they consume and their applications can scale to thousands of functions when needed. We expect that Lambda will become the dominant cloud environment unless the cloud vendors radically modify their pricing algorithms. Lambda will cause many more tasks to exist, creating a more expansive task management problem.
Lastly, “bloat” has wrecked havoc on elderly <font id='orig-7' class='highlight k7'><a href='#fake-7'>OS</a></font>s, and the pathlength of common operations such as sending a message and reading bytes from a file are now uncompetitively expensive. One key reason for the bloat is the uncontrolled layering of abstractions. Having a clean, declarative way of capturing and operating on <font id='orig-8' class='highlight k8'><a href='#fake-8'>operating system state</a></font> can help reduce that layering.
These changed circumstances dictate that system software should be reconsidered. In this proposal, we explore a radically different design for <font id='orig-9' class='highlight k9'><a href='#fake-9'>operating systems</a></font> that we believe will scale to support the performance, management and security challenges of modern computing workloads: a data-centric architecture for operating systems built around clean separation of 1In this paper, we will use Lambda as an exemplar of any resource allocation system that supports “pay only for what you use.” all state into database tables, and leveraging the extensive work in DBMS engine technology to provide scalability, high performance, ease of management and security. We sketch why this design could eliminate many of the <font id='orig-10' class='highlight k10'><a href='#fake-10'>difficult software engineering challenges</a></font> in current OSes and how it could aid important applications such as HPC and Internet service workloads. In the next seven sections, we describe the main tenets of this data-centric architecture. Then, in Section 9, we sketch a proposal concerning how to move forward.</p>
                <hr>
                <h1>Fake Text</h1><br>
                  <p>Current <font id='fake-1' class='highlight k1'><a href='#orig-1'>operating systems</a></font> are based on a core set of platform specifications, and thus the selection of a “main operating system” is a combination of platform specifications, security requirements, and other considerations that must be taken into consideration. The cloud has become a preferred platform, for both decision support and online serving applications. Serverless computing supports the concept of elastic provision of resources, which is very attractive in many environments. Machine learning (ML) is causing many applications to be redesigned, and future <font id='fake-2' class='highlight k2'><a href='#orig-2'>operating systems</a></font> will also benefit from the new techniques. Hardware is becoming massively parallel and heterogeneous. These “sea changes” make it imperative to rethink the architecture of <font id='fake-3' class='highlight k3'><a href='#orig-3'>system software</a></font>. Today’s cloud platforms contain hundreds of thousands of processors, heterogeneous computing resources (including CPUs, GPUs, FPGAs, TPUs, SmartNICs, and so on) and multiple levels of memory and storage. These platforms support millions of active users that access thousands of services. Hence, the <font id='fake-4' class='highlight k4'><a href='#orig-4'>OS</a></font>I model is a powerful tool for designing system scaling solutions. Managing <font id='fake-5' class='highlight k5'><a href='#orig-5'>OS</a></font>I complexity and ensuring that necessary complexity is captured by a system’s design is one of the most challenging aspects of operating systems. After all, there was only one processor. Now it is not unusual to run Map-Reduce or Apache Spark jobs with thousands of processes using millions of threads [13]. Stragglers creating long-tails inevitably result from substantial parallelism and are the bane of modern systems: incredibly costly and nearly impossible to debug [21].
Forty years ago programmers typically wrote monolithic programs that ran to completion and exited. Now, programs may be coded in multiple languages, make use of libraries of services (like search, communications, databases, ML, and others), and may run continuously with varying load. As a result, debugging has become much more complex and involves a flow of control in multiple environments. Debugging such a network of tasks is a real challenge, not <font id='fake-6' class='highlight k6'><a href='#orig-6'>considered forty years ago</a></font>. Now, GDPR [73] dictates system behavior for Personally Identifiable Information (PII) on systems that are under continuous attack. Future systems should build in support for such constructs. Moreover, there are many cases of bad actors doctoring photos or videos, and there is no chain of provenance to automatically record and facilitate exposure of such activity.
Machine learning (ML) is quickly becoming central to all large software systems. However, ML is typically bolted onto the top of most systems as an after thought. Application and system developers struggle to identify the right data for ML analysis and to manage synchronization, ordering, freshness, privacy, provenance, and performance concerns. Future systems should directly support and enable AI applications and AI introspection, including first-order support for declarative semantics for AI operations on system data.
In our opinion, serverless computing will become the dominant cloud architecture. One does not need to spin up a virtual machine (VM), which will sit idle when there is no work to do. Instead, one should use an execution environment like Amazon Lambda. Lambda is an efficient task manager that encourages one to divide up a user task into a pipeline of severalto-many subtasks1. Resources are allocated to a task when it is running, and no resources are consumed at other times. In this way, there are no dedicated VMs; instead there is a collection of short-running subtasks. As such, users only pay for the resources that they consume and their applications can scale to thousands of functions when needed. We expect that Lambda will become the dominant cloud environment unless the cloud vendors radically modify their pricing algorithms. Lambda will cause many more tasks to exist, creating a more expansive task management problem.
Lastly, “bloat” has wrecked havoc on elderly <font id='fake-7' class='highlight k7'><a href='#orig-7'>OS</a></font>Gi clusters. One key reason for the bloat is the uncontrolled layering of abstractions. Having a clean, declarative way of capturing and operating on <font id='fake-8' class='highlight k8'><a href='#orig-8'>operating system state</a></font> is crucial to supporting real-world workloads. In this proposal, we explore a radically different design for <font id='fake-9' class='highlight k9'><a href='#orig-9'>operating systems</a></font> and data that are intended to scale to petabytes of storage. We sketch why this design could eliminate many of the <font id='fake-10' class='highlight k10'><a href='#orig-10'>difficult software engineering challenges</a></font> and provide significant advantages for data-driven enterprises. In the next seven sections, we describe the main tenets of this data-centric architecture. Then, in Section 9, we sketch a proposal concerning how to move forward.</p>
              </body>
            </html>