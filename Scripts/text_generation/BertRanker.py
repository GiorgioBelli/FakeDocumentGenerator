import re
import torch
import numpy as np
from transformers import AutoTokenizer, AutoModel,BertForMaskedLM
from fitbert import FitBert

class Span():
    def __init__(self,start,end):
        self.start = start
        self.end = end

    def __str__(self):
        return "Span({},{})".format(self.start,self.end)

    def __iter__(self):
        yield self.start
        yield self.end

class ReplacementConcept():
    def __init__(self,concept,frequency,alternatives):
        self.alternatives = alternatives
        self.concept = concept
        self.frequency = frequency

class ConceptsUtils():

    @staticmethod
    def get_concept_names(concepts):
        return [concept.concept for concept in concepts]

    @staticmethod
    def get_concept_dict(concepts):
        conc_dict = {}
        for concept in concepts:
            conc_dict[concept.concept] = concept
        return conc_dict


    @staticmethod
    def create_freq_dict(concepts):
        freq_dict = {}
        for concept in concepts:
            freq_dict[concept.concept] = concept.frequency
        return freq_dict

    @staticmethod
    def discard_by_frequency(concepts,threshold=2):
        concepts = [concept for concept in concepts if concept.frequency>=threshold]
        concepts.sort(key=lambda concept: len(concept.concept))
        return concepts
    

class BertRanker():  
    def __init__(self,bert_args,sentence_separator=r"(\. [a-zA-Z])",context_window=1):
        self.sentence_separator = sentence_separator
        self.context_window = context_window
        
        self.model = FitBert(**bert_args)


    def rank_concept(self,sentence,context, span, alternatives):
        
        masked_sentence, masked = self.model.mask(sentence, tuple(span))
        contexted_text = ". ".join(context.get("pre-context"))+masked_sentence+". ".join(context.get("fol-context"))
        print("\nRANKING:",masked,"|")
        print("\nMASKED SENTENCE:",masked_sentence)

        ranks, probs = self.model.rank(masked_sentence, alternatives, with_prob=True)

        sorted_idexes = np.argsort(ranks)


        print("ranks:",ranks)


        ret = [conc_prob for conc_prob in sorted(list(zip(ranks,probs)),key=lambda x: x[1],reverse=True)]
        print("\nRANKED OPTIONS:",ret)
        print("\n\n")

        return ret

    def get_context(self,sentences,sentence_idx):

        num_sentences = len(sentences)

        prev_sentence_idx = sentence_idx-self.context_window if sentence_idx-self.context_window >= self.context_window else None  
        next_sentence_idx = sentence_idx+self.context_window if sentence_idx+self.context_window < num_sentences-1 else None

        print(sentence_idx,prev_sentence_idx,next_sentence_idx,{"pre-context": sentences[prev_sentence_idx:sentence_idx],"fol-context": sentences[sentence_idx+1:next_sentence_idx]},"","",sep="\n\n")

        return {"pre-context": sentences[prev_sentence_idx:sentence_idx],"fol-context": sentences[sentence_idx+1:next_sentence_idx]}

    def __split_sentences(self,whole_text):
        sentences = re.split(self.sentence_separator,whole_text)
        if(len(sentences)>1):
            for idx in range(2,len(sentences),2):
                first_char = sentences[idx-1][-1]
                sentences[idx] = first_char+sentences[idx]
                sentences[idx-2] += sentences[idx-1][0]
            sentences = sentences[::2]
        else: sentences = [whole_text]

        return sentences

    def genSubstitutions(self,text,concepts,concept_discard_func=(ConceptsUtils.discard_by_frequency,{"threshold":0})):
        
        sentences = self.__split_sentences(text)

        concepts = concept_discard_func[0](concepts,**concept_discard_func[1])

        concepts_regex = "(?<=\s)"+"|".join(ConceptsUtils.get_concept_names(concepts))+"(?=\s)"

        concepts_freq_dict = ConceptsUtils.create_freq_dict(concepts)
        concepts_objects = ConceptsUtils.get_concept_dict(concepts)

        new_sentences = sentences

        inc_len = 0
        
        ret = {}

        for sent_idx,sentence in enumerate(sentences):

            sentence_span = Span(inc_len,inc_len+len(sentence))
            
            matches = list(re.finditer(concepts_regex,sentence))

            if not matches:
                inc_len+=len(sentence)+2
                continue
            
            sentence_context = self.get_context(sentences,sent_idx)

            pre_context_len = len(sentence_context.get("pre-context"))
            fol_context_len = len(sentence_context.get("fol-context"))

            for match in matches:

                concept = concepts_objects[match.group(0)]

                print("match concept:",concept.concept)

                ranked_list = self.rank_concept(sentence,
                                                    sentence_context,
                                                    Span(pre_context_len+match.start()-1,pre_context_len+match.end()-1),
                                                    concept.alternatives)

                ret.setdefault(concept.concept,[]).append(((pre_context_len+match.start()-1,pre_context_len+match.end()),ranked_list))

            inc_len+=len(sentence)+2

        return ret
    
    def genFakeText(self,text,concepts,concept_discard_func=(ConceptsUtils.discard_by_frequency,{"threshold":0})):
        
        sentences = self.__split_sentences(text)

        concepts = concept_discard_func[0](concepts,**concept_discard_func[1])

        concepts_regex = "(?<=\s)"+"|".join(ConceptsUtils.get_concept_names(concepts))+"(?=\s)"

        concepts_freq_dict = ConceptsUtils.create_freq_dict(concepts)
        concepts_objects = ConceptsUtils.get_concept_dict(concepts)

        new_sentences = sentences

        inc_len = 0
        
        ret = {}

        for sent_idx,sentence in enumerate(sentences):

            sentence_span = Span(inc_len,inc_len+len(sentence))
            
            matches = list(re.finditer(concepts_regex,sentence))

            if not matches:
                inc_len+=len(sentence)+2
                continue
            
            sentence_context = self.get_context(sentences,sent_idx)

            pre_context_len = len(sentence_context.get("pre-context"))
            fol_context_len = len(sentence_context.get("fol-context"))

            for match in matches:

                concept = concepts_objects[match.group(0)]

                print("match concept:",concept.concept)

                # ranked_list = self.rank_concept(sentence,
                #                                     sentence_context,
                #                                     Span(pre_context_len+match.start()-1,pre_context_len+match.end()),
                #                                     concept.alternatives)
                ranked_list = ["XXX-XXX"]

                sentences[sent_idx] = sentence[:match.start()-1]+ranked_list[0]+sentence[match.end():]

                ret.setdefault(concept.concept,[]).append(((pre_context_len+match.start()-1,pre_context_len+match.end()),ranked_list))

            inc_len+=len(sentence)+2

        return ". ".join(sentences)
    
def main():

    scibert_tokenizer = AutoTokenizer.from_pretrained("allenai/scibert_scivocab_uncased")
    scibert_model = BertForMaskedLM.from_pretrained("allenai/scibert_scivocab_uncased")

    bert_args = {"model": scibert_model,"tokenizer": scibert_tokenizer}

    ranker = BertRanker(bert_args, sentence_separator=r"([^\d\)]\. {1,4}[a-zA-Z?-])", context_window=1)

    #     text = '''Current operating systems have evolved over the last forty years into complex overlapping code bases [70, 4, 51, 57], which were architected for very different environments than exist today. The cloud has become a preferred platform, for both decision support and online serving applications. Serverless computing supports the concept of elastic provision of resources, which is very attractive in many environments. Machine learning (ML) is causing many applications to be redesigned, and future operating systems must intimately support such applications. Hardware is becoming massively parallel and heterogeneous. These “sea changes” make it imperative to rethink the architecture of system software, which is the topic of this paper.
    # Mainstream operating systems (OSs) date from the 1980s and were designed for the hardware platforms of 40 years ago, consisting of a single processor, limited main memory and a small set of runnable tasks. Today’s cloud platforms contain hundreds of thousands of processors, heterogeneous computing resources (including CPUs, GPUs, FPGAs, TPUs, SmartNICs, and so on) and multiple levels of memory and storage. These platforms support millions of active users that access thousands of services. Hence, the OS must deal with a scale problem of 105 or 106 more resources to manage and schedule. Managing OS state is a much bigger problem than 40 years ago in terms of both throughput and latency, as thousands of services must communicate to respond in near real-time to a user’s click [21, 5].
    # Forty years ago, there was little thought about parallelism. After all, there was only one processor. Now it is not unusual to run Map-Reduce or Apache Spark jobs with thousands of processes using millions of threads [13]. Stragglers creating long-tails inevitably result from substantial parallelism and are the bane of modern systems: incredibly costly and nearly impossible to debug [21].
    # Forty years ago programmers typically wrote monolithic programs that ran to completion and exited. Now, programs may be coded in multiple languages, make use of libraries of services (like search, communications, databases, ML, and others), and may run continuously with varying load. As a result, debugging has become much more complex and involves a flow of control in multiple environments. Debugging such a network of tasks is a real challenge, not considered forty years ago.
    # Forty years ago there was little-to-no-thought about privacy and fraud. Now, GDPR [73] dictates system behavior for Personally Identifiable Information (PII) on systems that are under continuous attack. Future systems should build in support for such constructs. Moreover, there are many cases of bad actors doctoring photos or videos, and there is no chain of provenance to automatically record and facilitate exposure of such activity.
    # Machine learning (ML) is quickly becoming central to all large software systems. However, ML is typically bolted onto the top of most systems as an after thought. Application and system developers struggle to identify the right data for ML analysis and to manage synchronization, ordering, freshness, privacy, provenance, and performance concerns. Future systems should directly support and enable AI applications and AI introspection, including first-order support for declarative semantics for AI operations on system data.
    # In our opinion, serverless computing will become the dominant cloud architecture. One does not need to spin up a virtual machine (VM), which will sit idle when there is no work to do. Instead, one should use an execution environment like Amazon Lambda. Lambda is an efficient task manager that encourages one to divide up a user task into a pipeline of severalto-many subtasks1. Resources are allocated to a task when it is running, and no resources are consumed at other times. In this way, there are no dedicated VMs; instead there is a collection of short-running subtasks. As such, users only pay for the resources that they consume and their applications can scale to thousands of functions when needed. We expect that Lambda will become the dominant cloud environment unless the cloud vendors radically modify their pricing algorithms. Lambda will cause many more tasks to exist, creating a more expansive task management problem.
    # Lastly, “bloat” has wrecked havoc on elderly OSs, and the pathlength of common operations such as sending a message and reading bytes from a file are now uncompetitively expensive. One key reason for the bloat is the uncontrolled layering of abstractions. Having a clean, declarative way of capturing and operating on operating system state can help reduce that layering.
    # These changed circumstances dictate that system software should be reconsidered. In this proposal, we explore a radically different design for operating systems that we believe will scale to support the performance, management and security challenges of modern computing workloads: a data-centric architecture for operating systems built around clean separation of 1In this paper, we will use Lambda as an exemplar of any resource allocation system that supports “pay only for what you use.” all state into database tables, and leveraging the extensive work in DBMS engine technology to provide scalability, high performance, ease of management and security. We sketch why this design could eliminate many of the difficult software engineering challenges in current OSes and how it could aid important applications such as HPC and Internet service workloads. In the next seven sections, we describe the main tenets of this data-centric architecture. Then, in Section 9, we sketch a proposal concerning how to move forward.'''

    text =  '''Current operating systems have evolved over the last forty years into complex overlapping code bases [70, 4, 51, 57], which were architected for very different environments than exist today. The cloud has become a preferred platform, for both decision support and online serving applications. Serverless computing supports the concept of elastic provision of resources, which is very attractive in many environments. Machine learning (ML) is causing many applications to be redesigned, and future operating systems must intimately support such applications. Hardware is becoming massively parallel and heterogeneous. These “sea changes” make it imperative to rethink the architecture of system software, which is the topic of this paper. Mainstream operating systems (OSs) date from the 1980s and were designed for the hardware platforms of 40 years ago, consisting of a single processor, limited main memory and a small set of runnable tasks. Today’s cloud platforms contain hundreds of thousands of processors, heterogeneous computing resources (including CPUs, GPUs, FPGAs, TPUs, SmartNICs, and so on) and multiple levels of memory and storage. These platforms support millions of active users that access thousands of services. Hence, the OS must deal with a scale problem of 105 or 106 more resources to manage and schedule. Managing OS state is a much bigger problem than 40 years ago in terms of both throughput and latency, as thousands of services must communicate to respond in near real-time to a user’s click [21, 5]. Forty years ago, there was little thought about parallelism. After all, there was only one processor. Now it is not unusual to run Map-Reduce or Apache Spark jobs with thousands of processes using millions of threads [13]. Stragglers creating long-tails inevitably result from substantial parallelism and are the bane of modern systems: incredibly costly and nearly impossible to debug [21]. Forty years ago programmers typically wrote monolithic programs that ran to completion and exited. Now, programs may be coded in multiple languages, make use of libraries of services (like search, communications, databases, ML, and others), and may run continuously with varying load. As a result, debugging has become much more complex and involves a flow of control in multiple environments. Debugging such a network of tasks is a real challenge, not considered forty years ago. Forty years ago there was little-to-no-thought about privacy and fraud. Now, GDPR [73] dictates system behavior for Personally Identifiable Information (PII) on systems that are under continuous attack. Future systems should build in support for such constructs. Moreover, there are many cases of bad actors doctoring photos or videos, and there is no chain of provenance to automatically record and facilitate exposure of such activity. Machine learning (ML) is quickly becoming central to all large software systems. However, ML is typically bolted onto the top of most systems as an after thought. Application and system developers struggle to identify the right data for ML analysis and to manage synchronization, ordering, freshness, privacy, provenance, and performance concerns. Future systems should directly support and enable AI applications and AI introspection, including first-order support for declarative semantics for AI operations on system data. In our opinion, serverless computing will become the dominant cloud architecture. One does not need to spin up a virtual machine (VM), which will sit idle when there is no work to do. Instead, one should use an execution environment like Amazon Lambda. Lambda is an efficient task manager that encourages one to divide up a user task into a pipeline of severalto-many subtasks1. Resources are allocated to a task when it is running, and no resources are consumed at other times. In this way, there are no dedicated VMs; instead there is a collection of short-running subtasks. As such, users only pay for the resources that they consume and their applications can scale to thousands of functions when needed. We expect that Lambda will become the dominant cloud environment unless the cloud vendors radically modify their pricing algorithms. Lambda will cause many more tasks to exist, creating a more expansive task management problem. Lastly, “bloat” has wrecked havoc on elderly OSs, and the pathlength of common operations such as sending a message and reading bytes from a file are now uncompetitively expensive. One key reason for the bloat is the uncontrolled layering of abstractions. Having a clean, declarative way of capturing and operating on operating system state can help reduce that layering. These changed circumstances dictate that system software should be reconsidered. In this proposal, we explore a radically different design for operating systems that we believe will scale to support the performance, management and security challenges of modern computing workloads: a data-centric architecture for operating systems built around clean separation of 1In this paper, we will use Lambda as an exemplar of any resource allocation system that supports “pay only for what you use.” all state into database tables, and leveraging the extensive work in DBMS engine technology to provide scalability, high performance, ease of management and security. We sketch why this design could eliminate many of the difficult software engineering challenges in current OSes and how it could aid important applications such as HPC and Internet service workloads. In the next seven sections, we describe the main tenets of this data-centric architecture. Then, in Section 9, we sketch a proposal concerning how to move forward.",
        One of the main reasons that current operating systems are so hard to scale and secure is the lack of a single, centralized data model for OS state. For example, the Linux kernel contains dozens of different data structures to manage the different parts of the OS state, including a process table, scheduler, page cache, network packet queues, namespaces, filesystems, and many permissions tables. Moreover, each of the kernel components offers different interfaces for management, such as the dozens of APIs to monitor system state (/proc, perf, iostat, netstat, etc). This design means that any efforts to add capabilities to the system as a whole must be Herculean in scope. For example, there has been more than a decade of effort to make the Linux kernel more scalable on multicores by improving the scalability of one component at a time [11, 10, 50, 51], which is still not complete. Likewise, it took years to add uniform security management interfaces to Linux – AppArmor [6] and SELinux [64] – that have to be kept in sync with changes to the other kernel components. It similarly took years to enable DTrace [16], a heavily engineered and custom language for querying system state developed in Solaris, to run on other OSs. The OS research community has also proposed numerous extensions to add powerful capabilities to OSs, such as tracing facilities [23, 35], tools for undoing changes made by bad actors [45], and new security models [78, 66], but these remain academic prototypes due to the engineering cost of integrating them into a full OS. To improve the scalability, security and operability of OSes, we propose a data-centric architecture: designing the OS to explicitly separate data from computation, and centralize all state in the OS into a uniform data model. In particular, we propose using database tables, a simple data model that has been used and optimized for decades, to represent OS state. With the data-centric approach, the process table, scheduler state, flow tables, permissions tables, etc all become database tables in the OS kernel, allowing the system to offer a uniform interface for querying this state. Moreover, the work to scale or modify OS behavior can now be shared among components. For example, if the OS components access their state via table queries, then instead of reimplementing dozens of data structures to make them scalable on multicores, it is enough to scale the implementations of common table operations. Likewise, new debugging or security features can be implemented against the tabular data model once, instead of requiring separate integration work with each OS component. Finally, making the OS state explicitly isolated also enables radical changes in OS functionality, such as support for zero-downtime updates [3, 59], distributed scale-out [63, 7], rich monitoring [16, 2], and new security models [78, 66]. To manage the state in a data-centric operating system, we will require a scalable and reliable implementation of database tables. For this purpose, we simply recommend building the OS over a scale-out DBMS engine, leveraging the decades of engineering and operational experience running mission-critical applications. In other words, we suggest to build a database operating system (DBOS). While the DBMS engine will need some basic resource management functionality to bootstrap its execution, this could be done over a cluster of servers running current OSs, and eventually bootstrapped over the new DBOS. Today, DBMS engines already manage the most critical information in some of the largest computer systems on the planet (e.g. cloud provider control planes). Thus, we believe that they can handle the challenges in a next-generation OS. Moreover, recent trends such as support for polystores [68, 53] that combine multiple storage engines will enable the DBMS to use appropriate storage strategies for each of the wide range of data types in an OS, from process tables all the way to file systems. In more detail, this DBOS approach results in several prescriptive suggestions as discussed in the next section."
        All OS state should be stored in tables in the DBMS. Unix was developed with the mantra that “everything is a file”. This mantra should be updated to “everything is a table”, with first class support for high performance declarative semantics for query and AI operations on dense, sparse, and hypersparse tables [32, 28, 41, 37, 43, 15]. For example, there should be a task table with the state of every task known to the system, a flow table with ongoing network flows, a set of tables to represent the file system, etc [38]. All changes to OS state should be through DBMS transactions. The OS will need to include multiple routines in complex imperative code to implement APIs or complex resource management logic, but when these routines need to access OS state, we will require them to do so through DBMS transactions. This choice offers several benefits. First, parallelism and concurrency become easier to reason about because there is a transaction manager to identify conflicts. Second, computation threads in the OS can safely fail without corrupting system state, enabling a wide range of features including geographic distribution, improved reliability, and hot-swapping OS code. Third, transactions provide a natural point to enforce security and integrity constraints as is standard in DBMSs today. The DBMS should be leveraged to perform all functions of which it is capable. For example, files should be supported as blobs and tables in the DBMS. As a result, file operations are simply queries or updates to the DBMS. File protection should be implemented using DBMS security features such as view-based access controls for complex security policies. In other words, there should only be ONE extensible security system, which will hopefully be better at avoiding configuration errors and leaks than the sprawl of configuration tools today. Authentication should similarly be done only once using DBMS facilities. Finally, virtualization and containerization features can elegantly be implemented using database views: each container simply acts on a view of the OS state tables restricted to objects in that container. As a result, ALL system data should reside in the DBMS. To achieve very high performance, the DBMS must leverage sophisticated caching and parallelization strategies and compile repetitive queries into machine code [2], as is being done by multiple SQL DBMSs, including Redshift [3]. A DBMS supports transactions, so ALL OS objects should be transactional. As a result, transactions are implemented just once, and used by everybody. Decision support capabilities are facilitated. OSs currently perform many decision support and monitoring tasks. These include: • Choosing the next task to run • Discovering stragglers in a parallel computation • Finding over(under) loaded resources • Discovering utilization for the various resources • Predicting bottlenecks in real-time systems All of these can be queries to the DBMS."
        Performance optimization: OS kernel subsystems have often undergone extensive refactoring to improve performance by changing the data structures used to manage various state [52, 75, 31, 69]. If the OS had been designed around a DBMS instead, many of these updates would amount to changing indexes or changing operator implementations in the DBMS (e.g., adding parallel versions of operators). Moreover, the DBMS approach would enable further methods to improve performance that are not implemented in OSes today, such as cost-based optimization (switching access paths for an operation based on the current data statistics and expected size of the operation) or adaptive mid-query reoptimization. Security: DBMS access control tools such as view, attribute and role based ACLs [18, 74] can elegantly implement many of the security policies in SELinux, AppArmor and other OS security modules. Moreover, if these rules are implemented as view definitions or SQL statements within the DBMS, the security checking code can be compiled into the queries that regular OS operations run, instead of being isolated in a separate module that adds overhead to OS operations [48]. Virtualization and containerization: Tremendous engineering effort has gone into enabling virtualization and containerization in OSes over the past decade, i.e., enabling a single instance of the OS to host multiple applications that each get the abstraction of an isolated system environment. These changes have generally required modifying all data structures and a large amount of logic in the kernel to support different ”namespaces” of objects for each container. With DBOS, virtualization and containerization can elegantly be achieved using DBMS views: each container’s DBMS queries only have access to a view that restricts to objects with that container ID, whereas a root user can have access to all objects. We believe that many queries and logic in OS components would not have had to be modified at all to add virtualization with this approach, other than being made to run on these views instead of on the raw OS state tables. Geographic distributability: After all, nodes in a cloud vendor’s offering are geographically distributed. Transactional replication is a desired service of cloud offerings. This can be trivially provided by a geographically dispersed DBMS. This is in keeping with “implement any function only once; in the interest of simplicity”. More sophisticated file management: Since files are stored in the DBMS, as blobs and tables, and the directory structure is a collection of tables, and SQL access control is used for protection, the large amount of code that implements current file systems, essentially disappears. Also, we claim that current DBMSs which use aggressive compilation query and caching have gotten a great deal faster than the DBMSs of yesteryears. Also, multinode main memory DBMSs such as VoltDB and MemSQL are capable of tens of millions of simple transactions per second. Since a file read/write is just such a simple transaction, we believe that our proposed implementation can be performance competitive. In addition, more sophisticated file search becomes trivial to implement. For example, finding all files underneath a specific directory accessed in the last 24 hours that are more than 1GByte in size is merely a SQL query. The net result is additional features, much less code and (hopefully) competitive performance. Better scheduling: There will be task and resource tables in the DBMS capturing what tasks runs on cores, chips, nodes, and datacenters and what resources are available. Scheduling thousands of parallel tasks in such environments as Map-Reduce and Spark is mainly an exercise in finding available resources and stragglers, because running time is the time of the slowest parallel task. Finding outliers in a large task table is merely a decision support query that can be coded in SQL. Again, we believe that the additional functionality can be provided at a net savings in code. Enhanced state management: Using this approach it is straight-forward to divide application state into two portions. The first is transient and can be stored in data structures external to the DBMS. The second is persistent and must be stored in the DBMS transactionally. Since replication will be provided for all DBMS objects, application failures can merely failover to a new instance. This instance reads the persistent state from the DBMS and resumes the computation. This failover architecture was pioneered by Tandem Computers in the 1980’s and can be provided nearly for free using our architecture. Additional benefits accrue to this architecture by using a modern “server-less” application architecture, a topic which we defer to Section 8."
        Data communications can be readily expressed as operations on a geographically distributed DBMS. A pull-based system can be supported by the sender writing a record into the DBMS and the receiver reading it. A push-based system can be supported by the sender writing to the DBMS and setting a trigger to alert the receiver when he becomes active. This can be readily extended to multiple senders and recipients. In addition, DBMS transactions support exactly-once messages. Such an approach significantly simplifies programming allowing the programmer to easily implement non-blocking send programs that have been demonstrated comparable bandwidth to more complex messaging systems [36, 12] The CPU overhead of conventional TCP/IP communication is considered onerous by most, and new lighter-weight mechanisms, such as RDMA and kernel-bypass systems, are an order of magnitude faster [9, 56]. Hence, it seems reasonable to build special purpose lightweight communication systems whose only customer is the DBMS. This has already been shown to accelerate DBMS transactions by an order of magnitude, relative to TCP/IP in a local area networking environment [77], and it is possible that appropriate hardware could offer advantages of this approach in a wide area networking world. As such, it is an interesting exercise to see if a competitive messaging system can be done through the DBMS. It should also be noted that Amazon Lambda uses a storage-based communication system [72]. Of course, a performant implementation would use something much faster than S3, such as a multi-node main memory DBMS. If this approach is successful, this will lower the complexity of future system software by replacing a heavyweight general purpose system with a lightweight and optimized, special purpose one. It seems highly likely that the approach will work well in a hardware-assisted LAN environment. WAN utilization seems more speculative."
        It is clear that privacy will be a future requirement of all system software. GDPR [73] is the European law that mandates “the right to be forgotten”. In other words, Personally Identifiable Information (PII) that a service holds on an individual must be permanently removed upon a user request. In addition, data access must be based on the notion of “purposes”. Purposes are intended to capture the idea that performing aggregation for reporting purposes is a very different use case than performing targeted advertising based on PII data. In SQL DBMSs access control is based on the notion of individuals and their roles. These constructs have nothing to do with purposes, and a separate mechanism is required. Obviously, this is a DBMS service. As noted in [29], a clean DBMS design can facilitate locating and deleting PII data inside the DBMS. However, one must also deal with the case where data is copied to an application and then sent to a second application. Since all communication between applications goes through the DBMS, this message can be recorded by the DBMS, allowing the DBMS to track PII data even when it goes out to applications. Of course, this will not prevent a malicious human from writing PII data to the screen and copying it outside of the system. To deal with these kinds of leaks, applications must be “sandboxed” either virtually or cryptographically which can be readily incorporated into the database [25, 76, 60, 42, 58, 27]."
        Data provenance is key to addressing many of the ills of modern data-centric life. Consider the following problems: Data forging: Detecting whether a photograph is doctored has become impossible for the typical news consumer. Even if a news service wants to provide trustworthy authorship information about its articles and photos, it has no trustworthy way to do so. Simply signing a photograph at the time it was taken is not sufficient, since there are some data-mutating operations (such as cropping or color adjustment) that news organizations must perform before publication. Data debugging: Modern machine learning projects involve huge data pipelines, incorporating datasets and models from many different sources. Debugging pipeline output requires closely examining and testing these different inputs. Unfortunately, these inputs can come from partners with opaque engineering pipelines, or are incorporated in an entirely untracked manner, such as via a downloaded email attachment. As a result, simply enumerating the inputs to a data pipeline can be challenging, and fixing ”root cause data problems” is frequently impossible. Data spills: Today, an inadvertent data revelation is an irreversible mistake. There is no such thing as cleaning up after a database of social security numbers is mistakenly posted online. Although data handling practices must and can be improved, ensuring total data privacy today is a very difficult and brittle problem. Data consumption and understanding: Much of modern life (as a professional, a consumer, and a citizen) consists of consuming and acting on data. The data processes that produce humancomprehensible outputs, such as the plots in a scientific article, are so complicated that it is quite easy for there to be errors that are undetectable even to the producer. Consider the case of economists Carmen Reinhart and Kenneth Rogoff, who in 2010 wrote an enormously influential article on public finance, cited by Representative Paul Ryan to defend a 2013 budget proposal, that was later found to be based on simplistic errors in an Excel spreadsheet [71]. The authors did not acknowledge the error until three years after the paper was first written. Responsible data use means people must be able to quickly examine and understand the processes that yield the data artifacts all around us. Data policy compliance: Datasets and models often carry policies about how they can be used. For example, a predictive medical model might be appropriate for some age populations, but not others. Unfortunately, it is impossible for anyone, whether a data artifact producer or consumer, to have confidence about how data is being used. A strong data provenance system would help address all of the above problems. All data operations by a modern operating system, such as copying, mutating, transmitting, etc., should be tracked and stored for possible later examination. It should be impossible to perform operations on a modern OS that sidestep responsible data provenance tracking. Our proposed DBOS architecture effectively logs all such operations, allowing an authoritative chain of provenance to be recorded. (As with all the data the system collects, it will be stored in a DBMS.) This will support solutions to all of the above issues, requiring only log processing applications. Furthermore, first-class support for provenance throughout OS data structures will also simplify many system administration tasks, such as recovering from user errors or security breaches [19]."
        Designing an operating system requires making assumptions about its future workload and data. These assumptions then materialize themselves as default parameters, heuristics, and various compromises. Unfortunately, all these decisions can significantly impact performance, especially if the assumptions turn out to be wrong. For example, if we assume that the OS mainly runs very short Lambda-like functions, then reducing the overhead of starting a Lambda function may be more critical than optimal scheduling. However, if we assume the workload is dominated by long-running memory intensive services, we require a very different scheduling algorithm, fair resource allocation strategies, and service migration techniques, whereas the startup time will matter very little. Moreover, operating systems offer a variety of knobs to tune the system for a particular workload or hardware. While providing flexibility, all the options put a burden on the administrator to set the knobs correctly and to adjust them in the case the workload, data, or hardware changes. To overcome those challenges, we suggest that DBOS should be introspective, adaptable, and self-tuning through two design principles: Knob-free design: We believe that all parameters of the system should be designed to be self-tuning from the beginning. That is, DBOS will deploy techniques similar to SmartChoices [17] for all parameters and constants to make them automatically tuneable. The key challenge in globally optimizing all these parameters is then to gather and analyzing the state of the OS and the different components. Storing all this information in the OS database will significantly simplify the process and make true self-tuning possible. Learned components: To address a wide range of use cases, the system developer often has to make algorithmic compromises. For instance, every operating system requires a scheduling algorithm, but the chosen scheduling algorithm might not be optimal under all workloads or hardware types. In order to provide the best performance, we envision that the system is able to automatically switch the algorithm used, based on the workload and data. This would apply to scheduling, memory management, etc [22, 20]. In some cases it might be even possible to learn the entire component or parts of it. For example, recent results have shown that it is sometimes possible to learn a scheduling algorithm, which performs better than traditional more static heuristics [54, 55]. This learning of components would allow the system to more readily adapt to the workload and data, and perhaps provide unprecedented performance. To achieve a knob-free design and learned components, we suggest that the DBOS needs to be designed from the beginning to be Reinforcement Learning (RL)-enabled. RL is the leading technique to tune knobs and build components based on the observed behaviour in an online fashion. Today, RL is usually added as an afterthought. This leads to several problems including difficulty in finding the right award function or supporting the required RL exploration phase. In many cases this requires the extra work of building a simulator or a light-weight execution environment to try out new approaches. By making RL a first-class citizen in the system design, we believe that we can overcome these challenges. Moreover, managing all state data in a database and making it analyzable, will again be a key enabler for this effort. If successful, the resulting system would be able to quickly adapt itself to changing conditions and provide unprecedented performance for a wide range of workloads while making the administration of the system considerably easier."
        Managing compute, storage, and communication hardware is a primary function for an operating system. The key abstractions in existing operating systems were developed for the homogeneous hardware landscape of the last century. Kernel threads (processes), virtual memory, files, and sockets were sufficient to abstract and manage single-core computers with limited main memory backed by a slow hard disk, connected with low-bandwidth, high latency networking. Present-day hardware looks radically different. A single server machine contains tens to hundreds of cores in one or more chips, terabytes of main memory across a dozen channels, and multiple storage devices (SSDs and HDDs). The end of Dennard scaling [49] and the ascent of machine learning applications has led to the introduction of domain-specific accelerators like GPUs and TPUs, each with its own primitives for massively parallel computation and highbandwidth memory [33]. The end of scaling for DRAM technology is motivating multi-level main memory systems using storage-class memories (SCM) [34]. Network interfaces allow direct access to remote memory at speeds faster than local storage. Beyond the single node, concepts such as multi-cloud, edge cloud, globally replicated clouds, and hardware disaggregation introduce heterogeneity in the type and scale of hardware resources. Existing operating systems were not designed for such scales or heterogeneity. This shortcoming is a primary culprit for the software bloat in applications and operating systems, including kernel bypass subsystems. Solutions have limited portability and are difficult to understand, debug, and reuse. Placing the operating system state in a DBMS introduces two properties that are useful in managing heterogeneous hardware. First, it clearly separates compute from data access. The operating system can manage data placement, caching, replication, and synchronization separately from the accelerated functions that operate on it. Second, it clearly separates controlplane from data-plane actions. One can improve or customize control-plane operations, such as scheduling, independently of the compute implementation using the best available accelerators. To run efficiently on heterogeneous hardware, DBOS will be designed around two key prin- ciples. Accelerated interfaces to DBMS: DBOS will implement the interfaces that allow heterogeneous hardware to interact with the DBMS, hiding the overall system scale and complexity. For example, the interface to a compute accelerator like a TPU can be a query that applies a user-defined function (UDF). The accelerator implements the UDF, while DBOS implements the query that involves preparing inputs and outputs. This interface remains constant regardless if the accelerator is local, disaggregated, or in a remote datacenter. The accelerator state is stored in the DBMS to facilitate scheduling and introspection. DBOS will directly manage memory and storage layers, as part of the DBMS resources available for data sharing, replication, or caching. DBOS interfaces will leverage existing hardware mechanisms, such as virtual memory, as well as emerging mechanisms such as zero-copy/direct memory access networking interfaces or coherent fabrics (CXL). Over the time, hardware mechanisms will evolve to further accelerate the interactions between the DBMS and heterogeneous hardware. For example, SmartNICs will be optimized to accelerate DBMS interfaces, not just RDMA protocols, while GPUs and TPUs will directly support DBMS data operations. Accelerating the DBMS itself: The performance and scalability of DBOS itself relies heavily on the speed of DBMS operations. In addition to distributed execution and extensive caching, the DBMS will build upon modern hardware – accelerators, storage class memory, and fast SmartNICs. Since all communication, dataplane, and control plane operations interface with the DBMS, the deployment of specialized accelerators for common DB operations like joins, filters, and aggregations will likely become essential [1]."
        Historically, the programming model of choice was a single-threaded computation with execution interspersed with stalls for I/O or screen communication. This model effectively requires multitasking to fill in for the stalls. In turn, this requires interprocess protection and other complexity. Instead, we would recommend that everybody adopt the Lambda model, popularized by AWS [72]. In other words, computation is done in highly parallel “bursts,” and resources are relinquished between periods of computation [24]. This model allows one to give the CPU to one task at a time, eschewing multithreading and multiprogramming. In addition, parallel processing can be done with a collection of short-lived, stateless tasks that communicate through the DBMS.The DBMS optimizes the communication by locally caching and co-scheduling communicating tasks when possible. In effect, this is “server-less computing,” whereby one only pays for resources that are used and not for long-lived tasks. Hence, under current cloud billing practices, this will save significant dollars. That means DBOS should adopt the Lambda model as well. One should divide up a query plan into “steps” (operators). Each operator is executed (in parallel) and then dies. State is recorded in the DBMS. Sharding of the data allows operator parallelism. Each Lambda task is given a exclusive set of resources, e.g., one or more cores until it dies. In the interest of simplicity and security, multi-tenancy and multi-threading may be turned off. There is a sharded scheduling table in the DBMS. A task is runnable or waiting. The scheduler picks a runnable task — via a query — and executes it. When the task quits, the scheduler loops. This will work well as long as applications utilize the Lambda model. Dynamic optimization in the OS is gated by the time it takes stop, checkpoint, migrate, and restart applications/processes/threads. In the cloud, this is often minutes, which means that very little dynamic optimization is possible. Recent work has demonstrated that hand-coded fast launch (thousands of applications per second) is possible [61, 62]. This is all humancontrolled static optimization [14]. The optimizing scheduler in DBOS should be able to do this dynamically and launch millions of applications per second [38]."
        Obviously, DBOS is a huge undertaking. An actual commercial implementation will take tens of person-years. As such, we need to quickly validate the ideas in this document. Hence, we discuss demonstrating the validity of the ideas and then discuss convincing the systems community that DBOS is worth the effort involved."
        A key challenge is to show a DBMS capable of acceptable performance and scalability to form the foundation of DBOS. We believe that such a system should have the following characteristics: Multi-core, multi-node executor: Many DBMSs support this today. Server-less architecture: Commercial DBMSs are moving toward allocating CPU resources on a per-query basis. Snowflake has moved aggressively in this direction, based on a distributed file system (S3) aggressive caching and sharding only for CPU resources [65]. Polystore architecture: Clearly, DBOS will need to manage data from heterogenous sources such as process tables, schedulers, network tables, namespaces, and many permissions tables. It is likely that any single data management system will be able to efficiently manage the diversity and scale of the associated data structures. Different OS functionality will naturally fit into different types of storage engines and a polystore architecture [68, 53] can provide a single interface to these disparate and federated systems. A critical system characteristic would be to avoid developing a “one size fits all” [67, 26, 44] solution that is incapable of adapting as new types of data are collected and managed by DBOS. Open source code: Obviously any code in a DBOS prototype should be readily available. Lambda-style, serverless runtime system: This will facilitate optimizing resource allocation. Possible choices include SciDB, Presto, Accumulo, etc. We think the best option is to start with a prototype that comprises a DBMS built on an MIT Lambda-style system. We view the key design choices of AWS Lambda as reservation-free, fixed-resource service for short-lived functions and will embody those in our own system. Other choices in today’s commercial version of Lambda, such as S3 as the exclusive storage system, or the lack of direct communication between functions, seem like they should be rethought. It is unclear whether uniform resource constraints on the Lambda functions is a key design choice, or whether the system should offer heterogeneous resource constraints to enable a more flexible development environment. We would expect to replace S3 as the storage system with something much faster [46, 47], based on the discussion earlier. We expect in one person year, we could demonstrate a LANbased system along these lines. We would then expect to test the performance of this prototype in two contexts. The first goal is to provide file system performance comparable to today’s systems. In addition, we expect to show our communication implementation can be comparable or faster to traditional TCP/IP networking. To bootstrap running the DBMS itself, we plan to rely on minimal operating systems that have already been designed for cloud environments, such as unikernels, Dune or IX [8, 9], which are designed to run one application at a time and to give it high-performance access to the hardware. We will also make sure that the DBMS runs on Linux systems for easy development. The main facilities that the DBMS needs to bootstrap are a boot and configuration process, network access (which can also be used for logging), threads, and an interface to access storage. In the latter case, because the DBMS will manage all large data structures, raw block access may be sufficient. Today’s minimal OSes already support these facilities for hosting server applications as efficiently as possible in virtualized datacenters."
        As a first example of using DBOS to improve current OS functionality, we will implement a datacentric log processing and monitoring infrastructure in DBOS that can monitor applications using existing OSes such as Linux. OSes, Networks, Schedulers, and File Systems generate enormous amounts of logs and metadata which are mostly kept in raw files. Attempts to put these in databases (OS logs to Splunk; Network logs to NetAPP; Scheduler logs to MySQL; File System metadata to MySQL) barely meet minimal auditing requirements. A DBMS-based OS that organically stored these data in a high-performance database with first class support for dense, sparse, and hypersparse tables would be a huge win as it would make these data readily analyzable and actionable. It would also be able to execute streaming queries to compute complicated monitoring views in real time in order so simplify system management; simple metrics such as “how many files has each user created” can sometimes take hours to run with today’s file systems and OSes. Our team has conducted experiments showing the highperformance databases such as Apache Accumulo, SciDB, and RedisGraph can easily absorb this data while enabling analysis that are not currently possible [38, 15, 39, 40]. For example, ”All files touched by a user during a time window”, ”Largest 10 folders owned by a user”, ”Computing cycles consumed by an application during a time window”, ”Network traffic caused by a specific application”, ... These are very important questions for Cloud operators and very difficult to answer and require custom built tools to do so. A DBMS OS should be able to answer these questions by design."
        In Section 7, we discussed DBMS support for heterogeneous hardware, GPUs and FPGAs, based on user-defined DBMS functions. Our plan is to implement a prototype of this functionality to demonstrate its feasibility and performance. One of the defining features of modern datacenters is hardware heterogeneity. Far from being a uniform pool of machines, datacenters offer machines with different memory, storage, processing, and other capacities. Most notably, different machines offer vastly different accelerator capacities. Although GPUs for machine learning tasks comprise the most common class of accelerator, datacenters also contain FPGAs and other accelerators for video processing and encryption applications. These accelerators can be expensive: it is not feasible to outfit every machine in a large system with a top-flight GPU. Matching a heterogeneous workload to a heterogeneous pool of resources is a complicated and important task that is tailor-made for machine- rather than human-driven optimization. To address this challenge, we need to first design the DBMS-based API in DBOS allows for portability. The same user code can drive execution on a local or remote GPU. Next, we need to exploit the flexibility of Lambda-style task allocation and the visibility into system state through the DBMS in order implement scheduling algorithms that utilize better the datacenter resources that naive server-centric allocation schemes. We will demonstrate this functionality using by running a range of workloads on small clusters and by simulating larger, datacenter environments."
        Since DBOS is designed around a distributed DBMS, it is a natural fit for data mining applications like the log processing discussed in Section 9.2. However, it is not as obvious a match for online-serving applications, such as social networks, e-commerce sites, and media services, that consume large fractions on cloud systems. These applications consist of tens to thousands of microservices that must quickly communicate and respond to user actions within tight service level objectives (SLOs) [30]. Some microservices are simple tasks, such as looking up session information, while others are complicated functions such as recommendation systems based on neural networks or search functions using distributed indices. Microservice applications form the bulk of software-as-a-service products today and are the most critical operational applications for many organizations. We will prototype an end-to-end microservices workload, such as a Twitter-like social network, in order to evaluate DBOS’s feasibility for these applications. During this process, we will answer two key questions. First, can DBOS support the computation and communication patterns of such latency-critical applications in a performant manner? Second, can DBOS help address the challenges in developing, scaling, and evolving such applications over time? With DBOS, a social network will be implemented as a collection of serverless functions operating on multiple database tables. This presents multiple opportunities for performance optimization. For example, DBOS can colocate communication functions to avoid remote communication, or selectively introduce new caching layers and indexes. Accelerators are also now used in many components of microservice applications, such as recommendation engines for social network content and search result re-ranking, so we will use the accelerator management capabilities in Section 9.3 to automatically offload and optimize these tasks. Finally, because DBOS uses a serverless model, data management decisions such as sharding and replicating datasets or evolving schemas are separated from the application code. This makes it significantly easier for application developers to implement architectural changes that are very difficult in microservice applications today. We will show how to use DBOS to easily implement several such architectural changes: 1. Changing the partitioning and schema of data in the application to improve performance (a common type of change that requires large engineering efforts in today’s services). 2. Changing the partitioning of compute logic, e.g., moving from a “monolith” of co-located functions to separately scaling instances for different parts of the application logic. 3. Making the application GDPR-compliant, by storing each user’s data in their geographic region and using the data provenance features of DBOS to track which data was derived from each user or delete it on-demand. 4. Changing the security model (e.g., which users can see data from minors or from European citizens) without having to refactor the majority of application code'''


    # concepts = [
    #     ReplacementConcept('OSes', 53, ['major operating systems', 'machine operating sound', 'controlling energy storage systems', 'science user facility operated', 'machine operating sounds', 'controlled dynamical system', 'computer vision model operating', 'unknown time evolving system', 'biological natural systems', 'real robotic systems', 'crossed wires represent multiple systems', 'good concept representation learning system', 'standard recommender system metrics', 'human auditory system', 'general type-2 fuzzy systems', 'quantum linear system algorithm', 'efficient machine learning systems design', 'machine learning systems considers', 'actual intelligent maritime monitoring systems', 'submitted online learning systems', 'computational model system', 'trustworthy machine learning systems', 'traditional system', 'model complex systems consisting', 'visual system', 'automatic shape control system', 'expect broadly applicable intelligent systems', 'automated feedback system based', 'chaotic systems', 'economical power system operations', 'heterogeneous multi-agent systems', 'conscious systems', 'popular recommendation systems datasets', 'learn non-linear system evolutions', 'continuous dynamical systems', 'stochastic system', 'simple model systems showed', 'trained system', 'incremental classification systems', 'machine learning systems design', 'conventional federated systems', 'complex system', 'early expert systems', 'existing motion planning systems', 'engineering trustworthy systems', 'multiple classifier systems', 'flexible underlying learning system', 'artificial intelligence systems', 'construct mechanistic systems', 'actual physical systems']),
    #     ReplacementConcept('OSs', 53, ['major operating systems', 'machine operating sound', 'controlling energy storage systems', 'science user facility operated', 'machine operating sounds', 'controlled dynamical system', 'computer vision model operating', 'unknown time evolving system', 'biological natural systems', 'real robotic systems', 'crossed wires represent multiple systems', 'good concept representation learning system', 'standard recommender system metrics', 'human auditory system', 'general type-2 fuzzy systems', 'quantum linear system algorithm', 'efficient machine learning systems design', 'machine learning systems considers', 'actual intelligent maritime monitoring systems', 'submitted online learning systems', 'computational model system', 'trustworthy machine learning systems', 'traditional system', 'model complex systems consisting', 'visual system', 'automatic shape control system', 'expect broadly applicable intelligent systems', 'automated feedback system based', 'chaotic systems', 'economical power system operations', 'heterogeneous multi-agent systems', 'conscious systems', 'popular recommendation systems datasets', 'learn non-linear system evolutions', 'continuous dynamical systems', 'stochastic system', 'simple model systems showed', 'trained system', 'incremental classification systems', 'machine learning systems design', 'conventional federated systems', 'complex system', 'early expert systems', 'existing motion planning systems', 'engineering trustworthy systems', 'multiple classifier systems', 'flexible underlying learning system', 'artificial intelligence systems', 'construct mechanistic systems', 'actual physical systems']),
    #     ReplacementConcept('OS', 53, ['major operating systems', 'machine operating sound', 'controlling energy storage systems', 'science user facility operated', 'machine operating sounds', 'controlled dynamical system', 'computer vision model operating', 'unknown time evolving system', 'biological natural systems', 'real robotic systems', 'crossed wires represent multiple systems', 'good concept representation learning system', 'standard recommender system metrics', 'human auditory system', 'general type-2 fuzzy systems', 'quantum linear system algorithm', 'efficient machine learning systems design', 'machine learning systems considers', 'actual intelligent maritime monitoring systems', 'submitted online learning systems', 'computational model system', 'trustworthy machine learning systems', 'traditional system', 'model complex systems consisting', 'visual system', 'automatic shape control system', 'expect broadly applicable intelligent systems', 'automated feedback system based', 'chaotic systems', 'economical power system operations', 'heterogeneous multi-agent systems', 'conscious systems', 'popular recommendation systems datasets', 'learn non-linear system evolutions', 'continuous dynamical systems', 'stochastic system', 'simple model systems showed', 'trained system', 'incremental classification systems', 'machine learning systems design', 'conventional federated systems', 'complex system', 'early expert systems', 'existing motion planning systems', 'engineering trustworthy systems', 'multiple classifier systems', 'flexible underlying learning system', 'artificial intelligence systems', 'construct mechanistic systems', 'actual physical systems']),
    #     ReplacementConcept('operating systems', 13, ['major operating systems', 'machine operating sound', 'controlling energy storage systems', 'science user facility operated', 'machine operating sounds', 'controlled dynamical system', 'computer vision model operating', 'unknown time evolving system', 'biological natural systems', 'real robotic systems', 'crossed wires represent multiple systems', 'good concept representation learning system', 'standard recommender system metrics', 'human auditory system', 'general type-2 fuzzy systems', 'quantum linear system algorithm', 'efficient machine learning systems design', 'machine learning systems considers', 'actual intelligent maritime monitoring systems', 'submitted online learning systems', 'computational model system', 'trustworthy machine learning systems', 'traditional system', 'model complex systems consisting', 'visual system', 'automatic shape control system', 'expect broadly applicable intelligent systems', 'automated feedback system based', 'chaotic systems', 'economical power system operations', 'heterogeneous multi-agent systems', 'conscious systems', 'popular recommendation systems datasets', 'learn non-linear system evolutions', 'continuous dynamical systems', 'stochastic system', 'simple model systems showed', 'trained system', 'incremental classification systems', 'machine learning systems design', 'conventional federated systems', 'complex system', 'early expert systems', 'existing motion planning systems', 'engineering trustworthy systems', 'multiple classifier systems', 'flexible underlying learning system', 'artificial intelligence systems', 'construct mechanistic systems', 'actual physical systems']),
    #     ReplacementConcept('main memory', 6, ['main memory plays', 'called main memory', 'main memory stores 8', 'entire main memory', 'large-capacity main memory part', 'main underlying idea', 'main practical issues', 'main issues discussed', 'kth principal component ~u', 'principal components analysis', 'orthogonal principal components', 'main model achieves low loss', 'weakly trained main model', 'multi-scale local principal component analysis', 'principal component analysis', 'top 5 principal components', 'main model process', 'principal components', 'sparse principal component', 'main model', 'main model’s error', 'principal component', 'principal component vectors', 'main quantity examined', 'principal component eigenvectors', 'principal component scores', 'sparse principal component analysis problem', 'main movie types comedy', 'main types errors related', 'principal label space transformation', 'main discussed points', 'main geometric aspect', 'dataset’s main table', 'main performance metric', 'extracting main information', '= 5 main classes', 'main training process', 'main implementation focus', 'discover principal modes', 'principal angle condition', 'learning algorithm’s main objective function', 'main network achieve', 'main data structure', 'main descriptive statistics', 'main difference lies', 'main differences', 'main network', 'main comments arise', 'main mgr task', 'main task dataset']),
    #     ReplacementConcept('system software', 4, ['system protection software', 'simple software systems', 'software systems', 'software system', 'machine learning software stack', 'product management software developed', 'speech transcription systems classifying phonemes', 'distributed software architectures', 'common software platform', 'submit system description papers', 'document image understanding system', 'specialised software libraries', 'language processing system', 'open source software library', 'natural language processing systems', 'software engineering areas', 'system input', 'software engineers compare', 'system state information', 'existing motion planning systems', 'video analytics system', 'invited 14 software engineers', 'software engineers', 'music recommendation system', 'seamlessly integrate system initiative guidance', 'asked software engineers', 'system initiative guidance', 'open source software package designed', 'software evolution analysis', 'marker-based motion capture system', 'motion capture system', 'music recommender system', 'request routing system', 'neural information processing systems', 'software engineers provided', 'software engineers fare', 'support software agents', 'open source software', 'interactive music systems', 'traditional information technology systems', 'audio processing system capable', 'software engineer solve', 'system log information', 'robust aggregation system', 'prediction profile system', 'networked systems space', 'credit scoring system', 'news recommendation system', 'driver software running', 'database systems']),
    #     ReplacementConcept('social network', 4, ['social network company', 'popular social networks', 'generic social network scenario', 'popular social network', 'on-line social network', 'social network scenario', 'social network classification', 'social network disaster relevance', 'social network scenarios', 'social network graphs', 'social network graph', 'social networks', 'unequal social groups', 'analyze social data', 'big social data', 'social media data', 'social data', 'social media language', 'encodes societal gender biases', 'great societal relevance', 'social welfare functions', 'social media companies', 'social graph', 'social interaction mode', 'rich social graph', 'social media information', 'reify racialized social inequality', 'promoting social integration based', 'social inequality achieved', 'social media resources', 'users social fabric', 'social impact', 'social debates', 'social interaction', 'social science problems', 'social media experience', 'social scientists alike', 'social learning strategy', 'social theory helps', 'broader social impacts', 'social learning', 'social disparities', 'simulating social behavior', 'turn reinforce societal biases', 'social learning method', 'rapidly solve pressing social problems', 'social image annotation', 'internet social debate', 'existing societal biases', 'social pooling layer']),
    #     ReplacementConcept('operating system state', 4, ['system state information', 'full system state', 'system state variables', 'current system state', 'system state transition depends', 'phantom state blocks', 'structures called cell state', 'control-loop state machine', 'state machines', 'state block', 'finite state machine', 'juvenile resource building state', 'matrix product states', 'state partition', 'source object state', 'state feature extractor', 'product states', 'non-null state object', 'predict future object states', 'load state dict', 'checkerboard states', 'environment outputs random state', 'ground state configurations displays', 'rich ground state phase diagram', 'output state σ', 'end-to-end scene labeling systems', 'ground truth state', 'output state space', 'ground state', 'state encoder’s output', 'maps continuous states', 'sink state v3', 'ground state energy', 'maps states st', 'web system operators', 'pass state flag', 'car state includes', 'agent’s internal state representation interchangeably', 'state variables', 'steady state position', 'continuous state variable', 'raw state variables', 'triple rift system', 'agent’s state', 'raw pixel states', 'order book state', 'order book states', 'discrete hidden state variables', 'learner’s knowledge state', 'agent’s current sensed state']),
    #     ReplacementConcept('data provenance', 3, ['administrative sources data', 'explain arbitrary data sources', 'source data longer', 'related data sources', 'untrusted data sources', 'geo-distributed data sources revolve', 'labeled source data', 'data source', 'test data fault source', 'source domain data set', 'data fault sources', 'additional data sources', 'paired speech-translation data source', 'multiple data sources', 'source data center', 'source data set', 'complex data sources', 'data fault source', 'original labeled source data', 'data sources', 'source domain data', 'open source big data technology', 'distributed data sources', 'source code data', 'isolated data sources', 'source code edit data', 'data place bounds', 'ground truth data', 'data efficient machine learning workshop', 'structured web data', 'data dependent error bounds', 'data dependent generalization error bounds', 'data center control', 'hyperscale data centers', 'data center networks', 'data center', 'data centers', 'build data centers', 'entity shares data', 'data center control problem', 'data user aggregates', 'data center scale', 'distributed data centers', 'single data center', 'data processing methods', 'observation data trough', 'temporal data processing', 'fixed-size set data structure', 'sample-efficient data structure', 'distributed data processing']),
    #     ReplacementConcept('high performance', 3, ['high predictive performance', 'approach guarantees high performance', 'highest accuracy performance measures', 'high performance provided', 'achieve high performance', 'achieving high performance', 'high quality performances', 'desired high performance', 'reach high performance', 'high performance system', 'state-of-the-art high performance computing facilities', 'high performance computing', 'high predictive performance results', 'high probability events', 'highest scoring single episode', 'high dimensional case', 'high communication cost', 'common high dimensional cases', 'high dimensional action spaces', 'highest success rate', 'high training loss', 'high error rate', 'high error rates', 'high reconstruction error', 'high resource usages', 'high labeling effort', 'predicting renal failure remains high', 'high priority jobs', 'high performing models', 'highest execution time', 'upscaled versus high resolution noise', 'high resistance state', 'total end-use carbon emissions highest', 'high weight means', 'human attempt high dimensional visualization', 'high dimensional time series', 'high school education', 'high order tensor', 'high variance issues', 'high trait anxiety', 'high dimensional problem space', 'high pass filter fails', 'high level representations generated', 'high quality research', 'high level language', 'high resolution observations', 'highest conditional probability', 'high quality machine learning model', 'high dimensional design space', 'high pass filter correlates']),
    #     ReplacementConcept('debug system state', 2, ['system state information', 'full system state', 'system state variables', 'current system state', 'system state transition depends', 'phantom state blocks', 'structures called cell state', 'control-loop state machine', 'state machines', 'state block', 'finite state machine', 'juvenile resource building state', 'matrix product states', 'state partition', 'source object state', 'state feature extractor', 'product states', 'non-null state object', 'predict future object states', 'load state dict', 'checkerboard states', 'environment outputs random state', 'ground state configurations displays', 'rich ground state phase diagram', 'output state σ', 'end-to-end scene labeling systems', 'ground truth state', 'output state space', 'ground state', 'state encoder’s output', 'maps continuous states', 'sink state v3', 'ground state energy', 'maps states st', 'web system operators', 'pass state flag', 'car state includes', 'agent’s internal state representation interchangeably', 'state variables', 'steady state position', 'continuous state variable', 'raw state variables', 'triple rift system', 'agent’s state', 'raw pixel states', 'order book state', 'order book states', 'discrete hidden state variables', 'learner’s knowledge state', 'agent’s current sensed state']),
    #     ReplacementConcept('implement sophisticated security features', 2, ['add security features', 'sophisticated data visualization tool', 'sophisticated test generation tool', 'feature enhancing tools', 'sophisticated machine learning models', 'developing sophisticated concepts', 'sophisticated base model classes', 'sophisticated data structure', 'sophisticated portfolio strategies', 'commercial cyber security systems', 'sophisticated network model trained', 'network structure features', 'sophisticated classification models', 'sophisticated disentangled representation learning', 'sophisticated policy gradients', 'sophisticated auxiliary components', 'filter methods feature selection', 'sophisticated aggregation methods', 'feature layer', 'initial layers’ features', 'feature layers', 'implement entropic regularization', 'secondary structure features', 'layer learn label-specific features', 'attacker key features', 'machine learning security', 'feature extractor part', 'sophisticated domain specific similarity function', 'feature extractor network fext', 'auxiliary features describing objects', 'input feature extractor', 'kernel feature space', 'feature space equals', 'symmetry invariant feature maps', 'smaller feature map sizes', 'feature personal status', 'dependency parse features', 'frame level features', 'entity includes features', 'student feature extractor', 'implements training-time poisoning attacks', 'sophisticated methods', 'base graph features', 'student’s feature space', 'feature learning problem', 'feature extractor fθ', 'outer product features', 'current frameworks implements tools', 'basic feature extractor', 'private feature extractor']),
    #     ReplacementConcept('today’s computing environments', 2, ['complex environment’s increased simulation cost', 'agent’s environment consists', 'cloud computing environments', 'defending cloud computing environments', 'target agent’s environment', 'large distributed computing environments', 'agent’s computed motion template', 'explainee’s task domain knowledge', 'domain’s terminology axioms', 'patient’s primary condition group', 'computing equilibrium solutions', 'final search result’s quality', 'web conference’s challenges', 'adversary’s equilibrium distribution', 'continuous state space environments', 'patient’s medical history', 'node’s initial degree di', 'exceed human expert’s ability', 'original gradient’s magnitude', 'model’s discriminative power', 'model’s predictive power', 'adversary’s strategy space', 'standard deep learning packages today', 'space environments', 'simulated object pushing environment', 'today’s neural networks', 'deep neural networks today', 'learning curve’s usage', 'greatly increased user’s motivation', 'controllable object’s shape', 'today’s neural network architectures', 'weight reviewer’s recent reviews', 'synaptic connection’s modification', 'computed top-1 accuracy', 'massive computing power', 'limited computing power', 'computing power', 'average accuracy computed', 'advanced computing power', 'past environment states', 'controlled synthetic environment', 'previously learned environments', 'technical computing environment', 'handle large state environments', 'realistic simulated environment', 'open world production environment', 'directional path navigation environment', 'atari learning environment', 'continuous state-action environments', 'effective test environment']),
    #     ReplacementConcept('key design choice', 2, ['key design principles', 'key design features', 'design choices', 'important design choice', 'key machine learning task', 'central machine learning task', 'summarizing key approaches', 'describe fundamental processes', 'fundamental belief propagation algorithm', 'key research issues', 'fundamental construction block', 'made key contributions', 'fundamental research tasks', 'establish fundamental machine learning principles', 'fundamental networking task', 'fundamental statistical task', 'key machine learning models', 'uncovering key observations', 'key few-shot learning problem', 'learn fundamental imagery transformations', 'key insight motivating', 'key semantic patterns', 'fundamental algorithm framework', 'fundamental machine learning research', 'key analysis steps', 'key research elds', 'fundamental arithmetic operations', 'fundamental mathematical concepts', 'key user experience metrics', 'central preference order', '16 key roll call votes', 'registry key paths', 'key variable values', 'key missing detail', 'central machine estimates', 'primal form seeks', 'key words impact', 'foreign key relationships', 'key performance metrics', 'key studies pertaining', 'fundamental difficulties faced', 'key question left unanswered', 'fundamental theoretical questions', 'key modeling technique enabled', 'fundamental physical principles', 'key open question', 'key obstacles limiting', 'central open question', 'direct fundamental questions', 'address key questions']),
    #     ReplacementConcept('limited main memory', 2, ['main memory plays', 'called main memory', 'main memory stores 8', 'limited memory bundle method', 'entire main memory', 'limited memory capacity', 'limited memory variety', 'large-capacity main memory part', 'main underlying idea', 'main practical issues', 'main issues discussed', 'kth principal component ~u', 'principal components analysis', 'orthogonal principal components', 'main model achieves low loss', 'weakly trained main model', 'limited training samples', 'multi-scale local principal component analysis', 'one-step models offer limited merits', 'principal component analysis', 'limited sample sizes', 'top 5 principal components', 'main model process', 'limited learning capabilities', 'principal components', 'sparse principal component', 'main model', 'main model’s error', 'principal component', 'principal component vectors', 'limited sample diversity', 'main quantity examined', 'principal component eigenvectors', 'principal component scores', 'sparse principal component analysis problem', 'main movie types comedy', 'limited communication', 'main types errors related', 'principal label space transformation', 'main discussed points', 'limited contingency planning', 'main geometric aspect', 'limited probability assigned', 'limited algorithmic space', 'dataset’s main table', 'limited paired data context', 'limited observed data', 'limited label information', 'main performance metric', 'limited computation power']),
    #     ReplacementConcept('40 years ago', 2, ['speculative twenty years ago', '000 years ago', 'fifty years ago', 'experiment ten years ago', 'recent years learning-to-learn', 'recent years', 'recent years deep neural networks', 'years advanced malware', 'recent years achieved human-competitive', 'recent years proven', 'average schooling years', 'recent past years', 'study adults 85+ years', 'recent years convolutional neural networks', 'past thirty years', 'key research elds', 'recurrence period density entropy', 'subsequent time periods', 'recurrence period', 'time period bef', '1 year survival period', 'technologically advanced period', 'entire training period', 'possibly long periods', 'one-year look-back period', 'test reveal period', 'longer training period', 'output periods', 'temporal period ∆t', 'buffer period length', 'long time period', 'rate update period', 'multiple time periods', 'finite training period', 'biological critical period', 'regular sampling period', 'wave period', 'policy gains maturity', 'initial developmental period', 'fixed time period', 'entire 30-day period', 'missing phase', 'truck hauling duration', 'phase transition point', 'low-temperature ferromagnetic phase region', 'one-time training stage', 'circularly shifted 10 times', 'max epochs', 'parameter selection stage', 'supervisor crashed 54 times']),
    #     ReplacementConcept('operating system requires', 2, ['building human-like intelligent systems requires', 'systems budget needed', 'unknown time evolving system', 'biological natural systems', 'real robotic systems', 'crossed wires represent multiple systems', 'good concept representation learning system', 'standard recommender system metrics', 'human auditory system', 'general type-2 fuzzy systems', 'quantum linear system algorithm', 'efficient machine learning systems design', 'machine learning systems considers', 'actual intelligent maritime monitoring systems', 'submitted online learning systems', 'computational model system', 'trustworthy machine learning systems', 'traditional system', 'model complex systems consisting', 'visual system', 'automatic shape control system', 'expect broadly applicable intelligent systems', 'automated feedback system based', 'chaotic systems', 'economical power system operations', 'heterogeneous multi-agent systems', 'conscious systems', 'popular recommendation systems datasets', 'learn non-linear system evolutions', 'continuous dynamical systems', 'stochastic system', 'simple model systems showed', 'trained system', 'incremental classification systems', 'machine learning systems design', 'conventional federated systems', 'complex system', 'early expert systems', 'existing motion planning systems', 'engineering trustworthy systems', 'multiple classifier systems', 'flexible underlying learning system', 'artificial intelligence systems', 'construct mechanistic systems', 'actual physical systems', 'complex software-intensive systems', 'universal induction system', 'robust aggregation system', 'existing workflow systems', 'noisy continuous dynamical systems']),
    #     ReplacementConcept('data access', 2, ['access live streaming data', 'data access strategy', 'varying data size access', 'data access methods', 'data protection rights', 'data type abstraction', 'construct table-structured data representations', 'specific data quality characteristics', 'architecture models meta data', 'transforming feature data', 'entire model spectral data', 'data parallel framework', 'generates random data features', 'common feature and/or data space', 'data stream computational model', 'model spectral data', 'flipped data model', 'data’s internal features', 'target framework profile included data', 'data quality models', 'data generating models', 'big quantum data', 'distributed data processing frameworks', 'quantum data', 'data generating model', 'data mining process model', 'data driven model training', 'noise model data', 'relational data model', 'existing educational data mining models', 'data vector element', 'model highly heterogeneous data', 'feature’s data type', 'model performance data', 'quantum data structure', 'algorithms sort data', 'ensemble-based data assimilation framework', 'data driven models', 'expanded data features', 'data analysis framework', 'structured data representations', 'data representation learning methods', 'specific data type', 'single data point', 'data vectors', 'missing data points', 'closest data vectors', 'data points arrived', 'information access 2018 quantum theory', 'efficient data representation']),
    #     ReplacementConcept('hardware mechanisms', 2, ['machine learning mechanisms', 'reset mechanism', 'support hardware accelerated tensor processing', 'basic splicing mechanism', 'output perturbation mechanism', 'data release mechanisms', 'lock free mechanism', 'implemented encoder-decoder attention mechanism architecture', 'entity level attention mechanism', 'leverage hardware acceleration', 'transient hardware error', 'learner’s prediction mechanism', 'consumer hardware', 'underlying hardware layer', 'external objective feedback mechanism', 'hardware reverse engineering', 'graphics hardware', 'generation quantum hardware', 'relevance feedback mechanisms', 'specialized hardware', 'integrate attention mechanisms', 'top level attention mechanism', 'attention mechanism', 'generalization mechanism', 'peek mechanisms', 'packaging signal mechanism functions', 'learning mechanisms', 'existing attention mechanisms', 'early stop mechanism', 'certified removal mechanism', 'efficient hardware implementation', 'bias regulation mechanism', 'removal mechanism', 'combined attention mechanisms', 'true underlying mechanism', 'important mechanisms supporting', 'newly proposed learning mechanisms', '-differentially private mechanism', 'hard attention mechanism', 'custom hardware architectures', 'efficient hardware realization', 'detection mechanism', 'security mechanisms', 'edge hardware platforms', 'proposed mechanism', 'data generation mechanism', 'underlying missing data mechanism', 'specialized machine learning hardware', 'differentially private mechanism', 'hierarchical structuring mechanism']),
    #     ReplacementConcept('provide unprecedented performance', 2, ['produced unprecedented success', 'unprecedented volume', 'gain unprecedented insight', 'true performance distribution', 'human performance includes knowledge', 'valid performance estimations', 'poor performance', 'evaluate average performance', 'convergence performance', 'compare algorithm performance', 'competitive classification performance', 'hyperparameter tuning performance', 'high predictive performance', 'superior performance compared', 'model disentanglement performance increases', 'consistently poorer performance', 'performance drops significantly faster', 'performance issues', 'relative performance improvement', 'demonstrate performance benefits', 'important performance index', 'obtain classification performance', 'anatomical sites improves performance', 'strongly hurt performance', 'class performance gain', 'optimizer tests classification performance', 'achieve satisfactory performance', 'display performance metrics', 'good comparable performance', 'approach attains superior performance', 'resampled training performance', 'observe significant performance gain', 'performance metric', 'communications performance enhancement', 'imitation learning performance', 'rendering equal prediction performance', 'performance counter values', 'temporal loss performance', 'performance results reported', 'true performance variance', 'performance guarantees', 'dropout strategy boost performance', 'layer successively increases performance', 'compare model performance', 'obtain good performance', 'test performance', 'few-shot classification performance', 'demonstrated outstanding performance', 'remarkable performance enhancement', 'theoretical performance guaranties']),
    #     ReplacementConcept('forty years', 2, ['recent years learning-to-learn', 'recent years', 'recent years deep neural networks', 'years advanced malware', 'speculative twenty years ago', 'recent years achieved human-competitive', '000 years ago', 'recent years proven', 'average schooling years', 'recent past years', 'fifty years ago', 'study adults 85+ years', 'recent years convolutional neural networks', 'past thirty years', 'experiment ten years ago', 'key research elds', 'recurrence period density entropy', 'subsequent time periods', 'recurrence period', 'time period bef', '1 year survival period', 'technologically advanced period', 'entire training period', 'possibly long periods', 'one-year look-back period', 'test reveal period', 'longer training period', 'output periods', 'temporal period ∆t', 'buffer period length', 'long time period', 'rate update period', 'multiple time periods', 'finite training period', 'biological critical period', 'regular sampling period', 'wave period', 'policy gains maturity', 'initial developmental period', 'fixed time period', 'entire 30-day period', 'missing phase', 'truck hauling duration', 'phase transition point', 'low-temperature ferromagnetic phase region', 'one-time training stage', 'circularly shifted 10 times', 'max epochs', 'parameter selection stage', 'supervisor crashed 54 times']),
    #     ReplacementConcept('parallel computing environments', 2, ['16 parallel simulation environments', 'parallel computing stages', 'parallel computing platform', 'cloud computing environments', 'defending cloud computing environments', 'large distributed computing environments', 'employed parallel dither w/dropout', 'computing equilibrium solutions', 'parallel data streams', 'parallel data processing', 'parallel agents increases', 'out-of-domain parallel training data', 'parallel coordinates plots comparing', 'parallel coordinate plots', 'parallel belief propagation', 'parallel coordinates plot', 'parallel coordinate plot', 'parallel weak learners', 'parallel texts', 'parallel soft-max layers', 'create parallel classifications', 'efficient parallel implementation', 'parallel slow-weight path', 'parallel computation', 'fast parallel computations', 'parallel application', 'massively parallel models', 'parallel subgradient algorithms', 'parallel programming models', 'parallel subgradient algorithm', 'parallel algorithm', 'parallel dcd algorithm', 'highly parallel device', 'parallel parameter learning', 'massively parallel hardware', 'parallel stochastic optimization', 'parallel links `℘', 'past environment states', 'controlled synthetic environment', 'previously learned environments', 'technical computing environment', 'handle large state environments', 'realistic simulated environment', 'open world production environment', 'directional path navigation environment', 'atari learning environment', 'continuous state-action environments', 'effective test environment', 'simple dynamic learning environment', 'environments alongside human operators']),
    #     ReplacementConcept('ensuring total data privacy today', 1, ['entire model spectral data', 'entire training data set', 'entire training data', 'entire data set', 'preserving data privacy', 'privacy preserving data analysis', 'time preserving data privacy', 'improving data privacy', 'generate privacy preserving data', 'data privacy', 'preserve data privacy', 'protect data privacy', 'ensure data interpolation', 'ensure correct data organization', 'entire 4× 4 collection', 'entire group altogether', 'entire public test set', 'entire 75 image classes', 'entire problem set', 'entire covariate set', 'entire filter set', 'entire training set', 'entire unlabeled set learned', 'entire past information', 'entire feature space', 'total state space', 'entire state space', 'total sample space', 'entire design space', 'total observation pairs', 'entire sequence history', 'standard deep learning packages today', 'entire rewarding history', 'total communication complexity', 'total uncertainty reduction', 'total computational complexity', 'federated data presents', 'total accuracy lower', 'entire network results', 'entire deep neural network', 'entire network architecture', 'entire capsule network', 'entire network', 'entire network concurrently', 'total probability α', 'entire knowledge bases', 'entire event log', '50 total weak signals', 'entire probability distribution', 'entire parameter interval']),
    #     ReplacementConcept('difficult software engineering challenges', 1, ['software engineering life cycle stages', 'software engineering life cycle', 'general software engineering related words', 'software engineering research communities', 'software engineering practice', 'software engineering practices', 'software engineering work-flow', 'software engineering areas', 'software engineering applications', 'normal software engineering projects', 'software engineering projects', 'makes software engineering', 'practical software engineering applications identified', 'automate software engineering tasks', 'software engineering', 'industrial software applications', 'application poses interesting challenges', 'contributions address challenges', 'difficult relation extraction task', 'hard classification problem', 'difficult language semantics', 'difficult target task', 'difficult data problems', 'hard combinatorial optimization problem', 'notoriously computationally difficult tasks', 'hard coding shared', 'difficult task solvable', 'difficult mathematical tasks', 'hard exploration problems', 'increasingly difficult problems', 'difficult problems', 'algorithmically hard problems', 'computationally hard problems', 'solve difficult problems', 'solving hard problems', 'hard combinatorial problem', 'equally difficult problem', 'necessarily capture difficult', 'master difficult control policies', 'hard data mining', 'support software agents', 'system protection software', 'software development terms', 'software development process', 'improving software quality', 'iterative hard thresholding algorithm', 'hard decision combining', 'hard constraints imposed', 'hard constraints', 'handle hard constraints']),
    #     ReplacementConcept('basic resource management functionality', 1, ['basic functionalities', 'resource management problem', 'network resource management', 'network slicing resource management', 'resource management', 'wireless resource management', 'perform basic accuracy measuring experiments', 'basic set operations', 'included basic implementations', 'basic gradient descent', 'basic safety message', 'applies basic probability measures', 'small basic operations', 'basic arithmetic operations', 'facilitate basic operations', 'basic statistical functions', 'accomplish basic data analysis tasks', 'basic geometric case', 'basic command line interface', 'section highlights basic ideas', 'basic data analysis', 'basic search algorithm', 'basic differential privacy training workflow', 'basic interaction comprises', 'basic sample means', 'executing basic support services', 'basic procedure exist', 'provide basic matrix calculation', 'basic chemical representation', 'overestimate resource requirements', 'basic deep neural network architecture', 'understand basic health information', 'basic network structure', 'basic data assumption', 'basic feed-forward neural network', 'basic health data', 'show basic ideas', 'learn basic skills', 'basic idea', 'applications’ basic guarantees', 'basic image transformations', 'mobility management', 'exchanging basic machine learning metadata', 'basic machine learning analysis', 'basic programming concepts', '1 introduces basic notations', 'introduce basic notation', 'basic local sentences', 'briefly introduce basic notations', 'basic local sentence']),
    #     ReplacementConcept('mistakenly posted online', 1, ['mistakenly classi fied', 'amt job posting', 'posting unrealistic prices', 'preprocess comments posted', 'read status updates posted', 'warning sign attached', 'fully connected layer', 'fully connected penultimate layer', 'connected component', 'standard deep fully connected networks', 'densely connected convolutional networks', 'maximal connected components', 'hidden nodes connected', 'connected directed acyclic graphs', 'directly connected neighboring nodes', 'multiple fully connected layers', 'multi-class sequence tagging task', 'green lines connecting', 'identical connected neurons', 'simply fully connected', '3 fully connected layers', 'fully connected neural network', 'manually tagged samples', 'fully connected linear layers', 'tagging problem', '8 fully connected layers', 'fully connected learning space', 'final fully connected layer', 'final fully connected', 'identify connected components', 'fully connected neural networks', 'deep fully connected networks', '3 densely connected hidden layers', 'fluorescently tagged proteins26', 'remaining connected components', 'hundred recurrently connected neurons', 'largest connected component', 'fully connected single-head networks', 'locally connected regions', 'individual approaches harnessing', 'densely connected layer', 'input layer sparsely connected', 'sequence tagging model', 'full connected hidden layer', 'connected synapse belonging', 'actual goal appended samples', '2-layer fully connected network', 'wearable accelerometer mounted', 'larger outermost sectors connect', 'fully connected de ×']),
    #     ReplacementConcept('complex imperative code', 1, ['complex wavelet signals', 'consecutive complex signal values', 'literature presenting complex', 'complex sensory inputs', 'complex hypothesis spaces', 'manipulating complex spaces', 'complex systems space', 'complex analytic subsets', 'complex projective space', 'complex aggregation schemes', 'capture complex relations', 'complex item hierarchy', 'implement increasing complex convex functions', 'learn complex mappings', 'approximating complex functions', 'highly complex function', 'complex function based', 'complex cost functions', 'forming complex functions', 'complex function classes', 'complex relational functions', 'gain profile complex optimization problem', 'eventually learn complex programming idioms', 'inherently complex symbolic objects', 'complex neural network architectures', 'exploring complex dependencies', 'building complex network architectures', 'complex neural networks', 'high-dimensional complex data', 'recent complex neutral network models', 'complex sensor data', 'complex data sets', 'complex international supply chain', 'complex data structure', 'existing complex neural networks', 'complex data sources', 'complex feature combinations', 'complex multi-layered convolutional neural networks', 'complex environment’s increased simulation cost', 'complex real-world data distribution', 'complex data', 'complex numbers xi', 'complex model exhibits large variance', 'complex equations', 'complex individual-level time series dataset', 'complex inhand manipulation skill', 'complex representations', 'complex matrix', 'learn complex feature representations', 'complex design patterns found']),
    #     ReplacementConcept('modern data-centric life', 1, ['modern gender recognition systems', 'modern day businesses', 'modern deep neural networks', 'modern network function virtualization technologies', 'modern feedforward network', 'modern autoregressive density estimators', 'modern format', 'successful modern examples', 'causing modern web browsers', 'modern representation learning algorithms', 'modern web technologies', 'modern format era', 'modern machine learning approaches', 'modern machine learning classifiers', 'modern deep learning', 'modern over-parametrized learning', 'modern machine learning methods', 'modern deep learning frameworks', 'modern deep learning tools', 'modern machine learning practice', 'modern machine learning techniques', 'modern machine learning algorithms', 'modern trained machine learning models', 'modern machine learning tools', 'modern reinforcement learning methods', 'modern deep learning tool', 'modern machine learning', 'modern reinforcement learning', 'modern computer vision task', 'modern techniques', 'modern practical applications', 'leveraging modern features', 'modern computer vision research', 'modern scanning technology', 'modern convolutional architecture', 'modern containerization tools', 'current life savings', 'software engineering life cycle stages', 'machine learning life cycle', 'entire life cycle', 'system life cycle', 'specific life cycle stage', 'brilliant career life', 'quantum artificial life', 'artificial life', 'save human life', 'permeate daily life', 'large modern datasets', 'software engineering life cycle', 'civic life']),
    #     ReplacementConcept('security checking code', 1, ['security cases requires low probability', 'network security domain', 'security data', 'network security', 'network security applications', 'theoretically-grounded security guarantees', 'network security based', 'code size', 'compute security evaluation curves', 'core security requirement', 'source code portion', 'benchmarks security requires moving', 'major security issue', 'security evaluation curves', 'increase code coverage', 'empirical security evaluation', 'publish messy code', 'papers released code', 'code submission', 'existing scientific code', 'add security features', 'security contexts typical', 'code line replacement', 'static code features', 'cyber security', 'perform automated code reviews', 'code submission policy', 'machine code', 'error correcting codes', 'public code notebooks', 'hash codes', 'regulatory code', 'security evaluation', 'initial source code file', 'national security perspective', 'write high-level computer code', 'sparse code', 'single code representation', 'code base', 'program source code', 'sparse conjunctive codes', 'perfect code coverage', 'standard security directory', 'starter code base', 'solver modules represent application code', 'generate valid source code', 'machine learning security', 'source code files', 'data and/or code', 'built-in code editor']),
    #     ReplacementConcept('demonstrated comparable bandwidth', 1, ['comparable ethical standards', 'comparable qualities', 'hard cutoff yield comparable results', 'obtaining comparable qualities', 'demonstrate comparable accuracy', 'comparable software package', 'comparable computational budget', 'achieve comparable test accuracies', 'classification accuracy comparable', 'comparable robustness measure', 'comparable disentangled representation', 'good comparable performance', 'provide comparable results', 'show comparable performance', 'achieve comparable performance', 'achieves comparable results', 'achieve comparable results', 'aggregate error rates comparable', 'making training time comparable', 'easily comparable reports', 'achieve performance comparable', 'reach comparable results', 'obtain comparable performance', 'proposed approach comparable performance', 'comparable learning performance', 'evaluation results directly comparable', 'comparable numerical performance', 'comparable computational load', 'information entropy signatures presented', 'low bandwidth', 'communication bandwidth required', 'low bandwidth outputs', 'showed higher probability', 'benchmark data sets demonstrate', 'reduce bandwidth cost', 'part presents policies', 'phase space diagrams showing', 'two-dimensional feature space shown', 'language conscious demonstrated', 'random object presented', 'experiments show high accuracy', 'resume showing input patterns', 'data sets demonstrate', 'figures shown indicating rank correlation', 'test accuracies presented', 'user data presented', 'regression networks show significantly', 'findings show interesting combinations', 'sub-reward function shown', 'presented potential function helps']),
    #     ReplacementConcept('motivating multi-level main memory systems', 1, ['main memory stores 8', 'large-capacity main memory part', 'main memory plays', 'called main memory', 'entire main memory', 'shared memory system', 'good concept representation learning system', 'concept representation learning systems', 'accurate hidden state representations motivated', 'main data structure', 'main building block', 'main underlying idea', 'main practical issues', 'main issues discussed', 'main movie types comedy', 'main computational load', 'main notable innovation', 'main test bench', 'main research output', 'main quantity examined', 'single memory structure', 'abstract belief system', 'flat memory structure', 'dual memory structure', 'proposed dual memory structure designed', 'proposed dual memory structure', 'conventional single memory structure', 'successful belief systems', 'principal angle condition', 'bank’s image recognition system', 'document image understanding system', 'main model achieves low loss', 'principal component scores', 'principal label space transformation', 'drone’s image recognition system', 'art image recognition system', 'image retrieval systems', 'image analysis systems', 'main model process', 'main model’s error', 'sparse principal component analysis problem', 'proposed memory structure consists', 'principal research scientist', 'kth principal component ~u', 'principal components analysis', 'orthogonal principal components', 'weakly trained main model', 'multi-scale local principal component analysis', 'principal component analysis', 'top 5 principal components']),
    #     ReplacementConcept('data readily analyzable', 1, ['readily share data', 'readily teachable set', 'expected decomposable probability', 'implements decomposable scoring function', 'idea readily extends', 'decomposable attention model', 'readily perform direct sampling', 'readily transfer well-understood techniques', 'readily accommodate multiple simultaneous dancers', 'readily utilize algorithms', 'platform readily evaluated', 'decomposable probability-of-success metrics', 'raw cdr data', 'large redundant data sets', 'small computers recording data', 'unseen test data', 'training data xvn', 'structured data representations', 'preserving data privacy', 'data representation learning methods', 'data processing methods', 'analyze social data', 'reported demographic data', 'non-expert human demonstration data', 'unseen data distributions', 'creates noisy non-linearly separable data', 'underlying user data', 'specific data type', 'observation data trough', 'naive data augmentation techniques', 'data sets compared', 'full data set', 'well-studied real-world data', 'publicly release synthetic data', 'mixed-type tabular data', 'data assimilation algorithms', 'inspect historical training data', 'limited paired data context', 'single data point', 'detecting erroneous data', 'missing data range 90- 98%', 'acquired training data', 'labeling sequence data', 'data vectors', 'vertically partitioned data', 'training data selection', 'user action data', 'abstract raw sensor data', 'data augmentation techniques', 'large-scale high-dimensional data']),
    #     ReplacementConcept('considered forty years ago', 1, ['speculative twenty years ago', '000 years ago', 'fifty years ago', 'experiment ten years ago', 'recent years learning-to-learn', 'recent years', 'recent years deep neural networks', 'recent years achieved human-competitive', 'recent years proven', 'average schooling years', 'recent past years', 'recent years convolutional neural networks', 'key research elds', 'years advanced malware', 'considered gain levels range', 'considered classical deep', 'variational indexes considered', 'lecture videos viewed', 'jointly considered data universes', 'considered working modality', 'considered options discovery', 'hedge funds considered', 'considered substantial agreement', 'considered latent variables', 'considered hidden variables', 'analyze dropout learning regarded', 'time slice considered', 'considered methods', 'viewing angle result', 'ensemble learning regarded', 'samples considered correct', 'considered deterministic normalization techniques', 'training tasks considered', 'users’ viewing preferences', 'considered declarative specification', 'study adults 85+ years', 'interactive protocol considered', 'estimation setting considered', 'considered deep-learning-asa-service computation', 'transfer scenarios considered', 'decision features considered', 'past thirty years', 'protected attribute considered', 'considered predictions set', 'learning restrictions considered', 'considered multi-step models', 'features considered irrelevant', 'learning-to-learn considered optimizing parameters', 'test machines considered', 'financial instrument considered']),
    #     ReplacementConcept('complex security policies', 1, ['complex aggregation schemes', 'complex perception problem', 'complex road curvatures', 'complex prediction problems similar', 'exploring complex dependencies', 'gain profile complex optimization problem', 'complex real-world problems', 'overwhelmingly complex problem', 'solving complex problems specially', 'solving complex visual problems', 'complex optimization problem', 'complex decision-making problems', 'solving complex problems', 'complex regression problem', 'consecutive complex signal values', 'complex representations', 'learn complex feature representations', 'complex hypothesis spaces', 'learn complex representations', 'manipulating complex spaces', 'complex systems space', 'complex projective space', 'complex environment’s increased simulation cost', 'recent complex neutral network models', 'complex obfuscation methods', 'complex feature combinations', 'modeling complex environments', 'visually complex environment', 'complex environment dynamics', 'complex global operation', 'learn complex behaviour', 'complex locomotion environments', 'complex machine learning models', 'complex model exhibits large variance', 'training complex generative models', 'complex channel models', 'complex inhand manipulation skill', 'complex design patterns found', 'complex wavelet signals', 'complex pattern memorization', 'automatically recognize complex patterns', 'complex analytic subsets', 'complex real-world data distribution', 'complex multi-modal model', 'complex features combined', 'model complex systems consisting', 'constructing complex mathematical models', 'learn complex models', 'complex model architecture', 'simplicial complex models naturally define']),
    #     ReplacementConcept('customize control-plane operations', 1, ['small basic operations', 'load additional operations', 'arithmetic operations', 'involves costly convolution operations', 'stopping usual business operations', 'approximate arithmetic operations', 'general reduce operations', 'economical power system operations', 'fundamental arithmetic operations', 'pooling operations make outputs gain', 'basic arithmetic operations', 'facilitate basic operations', 'evolutionary operations proposed', 'performing matrix operations', 'basic set operations', 'real-time network operations', 'multiplication operations making', 'matrix operations requires', 'performing genetic operations', 'perform non-standard tensor operations', 'utilized arithmetic operations', 'fast bit-wise operations', 'simple vectorial operations', 'perform type-specific operations', 'sparse collective operations', 'efficient boolean vector operations', 'read operations precede', 'represent simple operations', 'defining quantum operations', 'customized model training approach', 'customized model training', 'pooling operations', 'weighting operations ⊗1', 'graph pooling operations', 'adding user-defined operations', 'user adds operations', 'runtime operations increase', 'numpy’s array operations', 'power system operations', 'customized data representations', 'data cleaning operations', 'global/local synchronization operations', 'customized machine learning architectures', 'customized model function', 'customized point mass', 'layer operations', '10k merge operations', 'perform edit operations', 'require 7 vector operations', 'chain augmentation operations']),
    #     ReplacementConcept('configuration tools today', 1, ['automatic configuration tools', 'so-called automatic configuration tools', 'automatic layout generation tool', 'layout generation tool', 'drives machine learning today', 'learning machines today', 'machine learning pipeline configurations', 'ground state configurations displays', 'today’s neural network architectures', 'sophisticated data visualization tool', 'data visualization tools', 'today’s massive academic output', 'machine learning tools', 'sophisticated test generation tool', 'subsequent learning tools', 'deep learning text categorization tool', 'deep learning tool', 'learning tools', 'popular neuropsychological screening tool', 'model-agnostic interpretation tools', 'chine learning tools', 'modern deep learning tools', 'state-of-the-art supervised dictionary learning tools', 'modern machine learning tools', 'supervised learning tools developed', 'modern deep learning tool', 'deep learning tools', 'geometric constellation shapes', 'environment configuration', 'learn geometric constellation shapes robust', 'geometric constellation shape', 'risk assessment tools', 'standard deep learning packages today', 'automatic differentiation tools', 'causal reasoning tools', 'visualization tools show', 'verification tool generates', 'primary article management tool', 'mixed-initiative design assistance tools', 'tools encourages discussions', 'predictive measurement tool', 'peer review tools', 'efficient problem configuration', '50- dimensional pose configurations', 'dnn hyper-parameter configuration problem', 'field configuration images', 'vision paper today', 'predictive modeling tool', 'today’s neural networks', 'superior tool users']),
    #     ReplacementConcept('storage class memory', 1, ['specific memory storage model', 'aggregate class representations', 'rich class representations', 'representation class consists', 'aggregated class representation', 'aggregated class representations', 'current data storage systems', 'memory impairment group', 'replay memory set', 'knowledge storage carrier', 'knowledge storage mechanism', 'probable image classes', 'entire 75 image classes', 'memory traffic', 'cache memory data', 'limited memory bundle method', 'controller’s experience memory set', 'short memory data', 'limited memory variety', 'user data memory', 'class imbalanced issue', 'class imbalance issue', 'ebm’s light memory usage', 'process’s memory footprint', 'long short term memory network', 'parametric concept class', 'finite concept class', 'memory network', 'privately learnable concept classes', 'original concept class', 'learner’s concept class', 'interesting infinite concept classes', 'long short term memory networks', 'concept class', 'concept class measures', 'concept classes included', 'infinite concept class', 'concept classes', 'general concept classes', 'definable concept classes', 'longshort term memory networks', 'restricted concept class', 'extended concept class', 'long short-term memory networks', 'class imbalanced training data', 'memory usage heavily depend', 'memory usage', 'memory usage compared', 'small memory usage', 'benchmark working memory tasks']),
    #     ReplacementConcept('social security numbers', 1, ['condition numbers 16', 'low condition numbers', 'social science problems', 'rapidly solve pressing social problems', 'unequal social groups', 'social media language', 'generic social network scenario', 'social network scenario', 'social network scenarios', 'social interaction mode', 'social graph', 'rich social graph', 'social network graphs', 'social network graph', 'social media information', 'social debates', 'reify racialized social inequality', 'social inequality achieved', 'internet social debate', 'analyze social data', 'social network company', 'popular social networks', 'great societal relevance', 'social welfare functions', 'popular social network', 'on-line social network', 'social network classification', 'social network disaster relevance', 'big social data', 'social media data', 'social data', 'social networks', 'social disparities', 'turn reinforce societal biases', 'societal concerns', 'promoting social integration based', 'social media resources', 'social image annotation', 'users social fabric', 'social impact', 'social interaction', 'encodes societal gender biases', 'social media experience', 'social scientists alike', 'social learning strategy', 'social theory helps', 'broader social impacts', 'social learning', 'social media companies', 'simulating social behavior']),
    #     ReplacementConcept('today’s file systems', 1, ['network file system', 'learning system’s behavior—to optimize', 'local file system', 'hadoop distributed file system', 'file system', 'storage file systems', 'device’s validation set', 'subject’s mobile device', 'system’s probability distribution', 'networked systems space', 'complex systems space', 'user’s machine learning script', 'output capsule’s pose', 'hinton’s capsule network', 'machine learning practitioner’s work', 'reward structure’s parameters', 'detector’s decision function', 'language processing system', 'natural language processing systems', 'drives machine learning today', 'learning machines today', 'previous section’s argument', 'machine log files', 'semi-structured machine log files', 'system life cycle', 'leveraging holder’s inequality', 'machine translation system', 'generator model’s output grows closer', 'final search result’s quality', 'agent’s camera orientation', 'generator’s parameters θ', 'robust aggregation system', 'adversary’s strategy space', 'power system', 'economical power system operations', 'power systems community', 'power system dataset', 'significantly en-hance power system flexibility', 'power system operations', 'power system framework', 'system complexity', 'power system testbed', 'accurately simulate power system dynamics', 'patient’s primary condition group', 'authentic power system dataset', 'power systems communities', 'today’s neural network architectures', 'water level control system', 'learner’s knowledge level', 'warning sign’s effects']),
    #     ReplacementConcept('cloud vendor’s offering', 1, ['cloud computing vendors provide', 'trader’s risk aversion', 'agent’s computed motion template', 'agent’s video clips', 'final search result’s quality', 'greatly increased user’s motivation', 'user’s knowledge', 'learner’s knowledge state', 'learner’s knowledge', 'learner’s knowledge level', 'paper’s reported results', 'cloud computing providers', 'cloud services providers', 'input point clouds', 'input point cloud', 'teacher’s hypothesis', 'teacher’s expected answer', 'answer network’s input vector xt', 'neural network’s explanation', 'applied scientist’s skill set', 'user’s machine learning script', 'learner’s policy', 'user’s underlying intent', 'user’s prior belief', 'user’s specific purpose', 'user’s base table', 'incremental learner’s performance', 'user’s gesture takes', 'user’s mental image', 'user’s ego network', 'improve single learner classifier’s performance', 'user’s mental map', 'patient’s primary condition group', 'agent’s discounted return', 'agent’s policy network', 'agent’s body parts', 'agent’s policy based', 'agent’s intrinsicallymotivated rewards', 'agent’s state', 'learning agent’s parameters', 'single agent’s data', 'agent’s expected return', 'target agent’s policy', 'agent’s camera orientation', 'agent’s policy pass', 'agent’s environment consists', 'mc rl’s trained agent', 'agent’s component', 'agent’s algorithm takes', 'target agent’s parameters']),
    #     ReplacementConcept('isolated system environment', 1, ['maze environment aim', 'unique systems challenges', 'systems challenges', 'drone’s image recognition system', 'bank’s image recognition system', 'art image recognition system', 'automated speech recognition systems', 'facial recognition systems', 'face recognition system', 'blocks world environment', 'train face recognition systems', 'handwriting recognition systems', 'disease recognition system', 'modern gender recognition systems', 'networked systems space', 'electronic safety related systems', 'system life cycle', 'safety critical systems', 'complex systems space', 'simulated object pushing environment', 'robot arm environment', 'robot arm environments', 'power system', 'open world production environment', 'economical power system operations', 'wireless environments', 'power systems community', 'introduced ranking system', 'environment outputs random state', 'power system dataset', 'significantly en-hance power system flexibility', 'power system operations', 'power system framework', 'system complexity', 'real world environment', 'power system testbed', 'intentionally exploit system vulnerabilities', 'accurately simulate power system dynamics', 'procedurally generated platform environments', 'commercial cyber security systems', 'authentic power system dataset', 'power systems communities', 'grid world environments', 'learning environment remains unchanged', 'million environment steps', 'water level control system', 'base execution environment', 'environment outputs', 'isolated optimization techniques result', 'inside isolated components']),
    #     ReplacementConcept('strong data provenance system', 1, ['strong data processing inequality', 'strong data extraction process', 'training data show strong clusters', 'data discovery system', 'current data storage systems', 'data discovery systems', 'administrative sources data', 'explain arbitrary data sources', 'source data longer', 'related data sources', 'untrusted data sources', 'geo-distributed data sources revolve', 'labeled source data', 'data source', 'test data fault source', 'source domain data set', 'data fault sources', 'additional data sources', 'paired speech-translation data source', 'multiple data sources', 'source data center', 'source data set', 'complex data sources', 'data fault source', 'original labeled source data', 'data sources', 'source domain data', 'open source big data technology', 'distributed data sources', 'source code data', 'isolated data sources', 'source code edit data', 'robust aggregation system', 'strong class imbalance', 'stronger machine learning models', 'set system', 'set system induced', 'abstract set system', 'fundamental set systems', 'set system underlying', 'efficient data container', 'device collects data', 'social media data', 'device’s local data', 'geometric set systems', 'set system consisting', 'device’s validation data', 'data efficient machine learning workshop', 'show strong clustering', 'strong patient-provider network based']),
    #     ReplacementConcept('kernel bypass subsystems', 1, ['regularization kernel network', 'kernel network', 'kernel neural network', 'deep kernel network', 'feedforward network kernel', 'large margin feed-forward network kernel', 'bypass networks', 'kernel class', 'kernel combination space', 'base kernel matrix', 'resulting kernel matrix', 'learn kernel matrices', 'final kernel matrix', 'positive definite kernel matrix', 'kernel space', 'kernel matrix computed', 'learned kernel matrix', 'kernel space defined', 'typical squared exponential kernel matrix', 'valid kernel matrix', 'kernel target alignment', 'kernel matrix', 'pre-given kernel matrix', 'maximizing kernel target alignment', 'empirical kernel matrix', 'kernel matrices', 'nl × nl kernel matrix', 'synthetic kernel matrices', 'kernel feature space', 'kernel alignment', 'weighted degree string kernel', 'single layer kernels', 'layer kernel machine', 'information geometric kernel density estimation', 'pre-defined kernel functions', 'reverse diffusion kernel', 'kernel functions', 'computationally expensive kernel function', 'radial basis kernel', 'kernel function selection', 'kernel distance function', 'pre-defined kernel function', 'input kernel function', 'gaussian kernel function', 'basis kernel', 'parametric kernel functions', 'kernel target alignment criterion', 'partially shared kernel function', 'kernel function κ', 'radial basis kernels']),
    #     ReplacementConcept('simple data model', 1, ['simple knowledge base embedding model', 'simple data noising strategy', 'simple data augmentation strategy', 'architecture models meta data', 'simple models detailed', 'simple models describing', 'simple models', 'simple model', 'distributed data processing frameworks', 'simple interpretable models', 'generate simple interpretable models', 'data quality models', 'entire model spectral data', 'data parallel framework', 'data stream computational model', 'model spectral data', 'flipped data model', 'target framework profile included data', 'data generating models', 'data generating model', 'data mining process model', 'data driven model training', 'noise model data', 'relational data model', 'existing educational data mining models', 'model highly heterogeneous data', 'model performance data', 'ensemble-based data assimilation framework', 'data driven models', 'data analysis framework', 'model aggregation', 'standardized metadata models', 'sophisticated base model classes', 'base model class', 'incremental batch learning framework', 'framework batch active learning', 'employ model combination', 'permutation-invariant set model', 'defined-to-be-interpretable model classes equally interpretable', 'shifting model choice sets', 'finite model set', 'spline regression model representing class', 'construct table-structured data representations', 'model combinations reported', 'core language model', 'humans design models', 'data type abstraction', 'model clusters appropriately', 'positive pair models', 'cluster computing frameworks']),
    #     ReplacementConcept('colocate communication functions', 1, ['action activation functions', 'action activation function', 'error functions', 'acquisition function utilized widely', 'temporal acquisition function', 'kernel function selection', 'gradient privacy protection function', 'training loss functions', 'entropy search acquisition function', 'training set error function', 'support mapping objects', 'expected loss function errors', 'work utilizing non-linear function approximation', 'network evaluation function', 'existing acquisition functions', 'acquisition function', 'acquisition functions', 'fixed aggregation function offers', 'iterative function evaluations', 'fetch data function', 'remaining acquisition functions', 'function evaluations', 'error function erf', 'loss function error', 'cost function supports', 'training loss function', 'true acquisition function', 'called approximation error function', 'reward function evaluation grows linearly', 'presented potential function helps', 'loss function errors', 'constraint propagation function', 'objective function evaluation', 'approximation error function', 'objective function evaluation requires evaluating', 'support mapping similar', 'purely uncertainty-based acquisition functions', 'error indicator function', 'simple fetch data function', 'pursue function evaluations', 'objective function evaluations', 'error function', 'strongly-performing acquisition functions', 'privacy protection function', 'temporal acquisition functions', 'loss function ` assigning', 'loss function error sequence', 'tracked acquisition function', 'decision functions', 'classification loss function']),
    #     ReplacementConcept('software-as-a-service products today', 1, ['large tensor product spaces', 'bring quality products', 'drives machine learning today', 'fashion product recognition dataset8', 'today’s neural network architectures', 'today’s massive academic output', 'learning machines today', 'tensor product operation', 'product similarity function', 'product nodes identify factorizations', 'vector dot product', 'product review domains', 'dot product', 'dot products', 'test sets comprise products', 'code products external', 'gradient dot products', 'weighted element-wise dot product', 'product w>i wj close', 'product data', 'published specific data products', 'gradient dot product', 'multiple product lines', 'outer product operator', 'commercial product descriptions', 'production ready product', 'product management software developed', 'discrete product distributions', 'binary product distributions', 'vision paper today', 'product give similar results', 'product form', 'machine learning products', 'dot product operations', 'today’s neural networks', 'deep neural networks today', 'implementation handles products', 'tensor product position', 'standard deep learning packages today', 'today’s electricity markets', 'learn product automata', 'remain valid today', 'initial prefix tree acceptor product', 'minimum viable product', 'product model', 'symmetric outer product decomposition', 'dot product zᵀj', 'outer product factorization', 'matrix product states', 'cross product kernel']),
    #     ReplacementConcept('storage-based communication system', 1, ['wireless communication system', 'future multi-band optical communication systems', 'normal system activity', 'data discovery system', 'highly functional production system', 'real production systems', 'data discovery systems', 'decision support systems provided', 'proposed training system', 'system make error', 'machine learning systems design process', 'protection systems vary', 'marker-based motion capture system', 'motion capture system', 'system generates artificial faults', 'system protection software', 'system development process', 'online education systems', 'clinical decision support system', 'personalized search systems', 'clinical decision support systems', 'search engine system', 'makings network intrusion detection systems', 'decision support systems', 'financial search engine system', 'improve clinical decision support systems', 'communication graph structure', 'system enabling valuable interactions', 'system identification', 'develop classification systems', 'communication rounds required', 'malware classification system', 'economical power system operations', 'incremental classification systems', 'existing motion planning systems', 'system identification techniques', 'computer applications and/or systems design', 'decoupled classification systems', 'communication rounds', 'single communication round', 'power system operations', 'credit scoring system', 'nonlinear system identification', 'classification systems', 'system identification approach', 'linear system identification', 'recommender system tasks', 'reinforcement learning system', 'build interpretable reinforcement learning systems', 'protein classification system']),
    #     ReplacementConcept('great deal faster', 1, ['leading faster discovery', 'faster convergence rate', 'networks yielded faster convergence', 'show great promise', 'yielded faster training processes', 'recently achieved great successes', 'reporting faster training times', 'optimal behavior faster', 'achieve faster convergence', 'faster convergence', 'achieve faster training', 'shown great promise', 'shown great success', 'holding great promise', 'faster learning process', 'shown faster training', 'enables faster convergence', 'achieving great success', 'achieved great success', 'performance drops significantly faster', 'faster run time', 'demonstrated great performance', 'yield faster learning', 'great performance boost', 'shown great performance', 'achieve great improvements', 'sparked great insights', 'autonomous algorithm initially converges faster', 'great societal relevance', 'presents great opportunities', 'methods learn significantly faster', 'faster active learning loops', 'separate network enables faster learning', 'simple feedforward network faster', 'caused great difficulties', 'proposed method converges faster', 'track termination condition faster', 'estimator achieves great learning efficiency', 'js 177 times faster', 'lose great amounts', 'faster learning progress', 'encounter great challenges', 'made great strides', 'achieve great results', 'policy faster', 'great opportunities facing researchers', 'learning preferences faster', 'find high-quality solutions faster', 'results show great potential', 'complete dialogs faster']),
    #     ReplacementConcept('requires interprocess protection', 1, ['providing meaningful end-to-end protection', 'intellectual property protection', 'protection systems vary', 'computational effort needed', 'work effort needed', 'require additional features construction/engineering process', 'measurements require identification', 'stronger privacy protection', 'required training subsets', 'computational process needed', 'required training time', 'training process requires hundreds', 'lab measurements needed', 'approaches require excessive training time', 'learning process requires', 'total computation needed', 'communication rounds required', 'required classification label', 'machine learning applications require', 'requiring task labels', 'requires considerable communication', 'two-way communication channel needed', 'automated grid protection', 'requires exhaustive tuning', 'proposed criterion requires computation', 'non-trivial task requiring', 'methods require hyperparameter tuning', 'tasks typically require', 'communication bandwidth required', 'task requires answering', 'assessor attacks generally require', 'estimated actions required', 'lowest magnitude adversarial attack required', 'requires special care', 'requires lower computation time', 'require graph-wide calculations', 'total communication required', 'communication costs required', 'required intermediate computations', 'requires linear time computations', 'scientific applications require', 'inventory planning require richer information', 'requires high computation', 'average interaction time needed', 'interaction primitives required', 'human interactions required', 'requires km performance evaluations', 'requires special services', 'results requires careful examination', 'conscious domain requires conceptualization']),
    #     ReplacementConcept('managing heterogeneous hardware', 1, ['heterogeneous multi-agent systems', 'heterogeneous distributed systems', 'heterogeneous or/and multiple network architectures', 'heterogeneous network architectures', 'heterogeneous relational kernel learning', 'heterogeneous users interact', 'handles heterogeneous resource requests', 'heterogeneous modeling', 'heterogeneous disease effect modeling approach', 'heterogeneous treatment effect', 'heterogeneous disease effect', 'heterogeneous search space', 'heterogeneous edge servers', 'heterogeneous interaction network based', 'heterogeneous information network', 'heterogeneous networks', 'heterogeneous network resources', 'heterogeneous data modalities', 'heterogeneous big data', 'heterogeneous nature', 'heterogeneous time series data', 'model highly heterogeneous data', 'single heterogeneous network', 'heterogeneous data', 'heterogeneous undirected network', 'heterogeneous network model', 'turns heterogeneous medical records', 'heterogeneous domain adaptation', 'heterogeneous time series', 'heterogeneous switching behavior', 'heterogeneous multi-task metric learning', 'heterogeneous transfer learning', 'heterogeneous transfer learning approaches', 'estimating heterogeneous treatment effects', 'heterogeneous multitask learning', 'multiple heterogeneous domains', 'heterogeneous domains', 'heterogeneous active learning tasks', 'heterogeneous multi-task learning', 'heterogeneous tasks', 'incorporate heterogeneous models', 'heterogeneous features', 'heterogeneous network-based model', 'efficient hardware implementation', 'efficient hardware realization', 'specialized machine learning hardware', 'massively parallel hardware', 'state-of-the-art hardware technology', 'heterogeneous tasks/domains', 'building specialized machine learning hardware']),
    #     ReplacementConcept('require custom built tools', 1, ['predictive measurement tool', 'evaluating custom machine learning pipelines', 'static analysis tools', 'primary article management tool', 'developing technology tools', 'large deviation tools', 'custom learning rate decay', 'sophisticated test generation tool', 'subsequent learning tools', 'deep learning text categorization tool', 'deep learning tool', 'sophisticated data visualization tool', 'mixed-initiative design assistance tools', 'popular neuropsychological screening tool', 'automatic layout generation tool', 'modern deep learning tools', 'modern machine learning tools', 'modern deep learning tool', 'deep learning tools', 'automatic differentiation tools', 'automatic configuration tools', 'so-called automatic configuration tools', 'superior tool users', 'current frameworks implements tools', 'automatic extraction tool', 'custom task interpreter based', 'predictive modeling tool', 'open source tools', 'distributed ml jobs built', 'building human-like intelligent systems requires', 'custom proof-search methods working directly', 'building energy system', 'systems built', 'suitable machine learning tool', 'traditional fuzzing tool', 'machine learning based fuzzing tools', 'traditional fuzzing tools', 'computational tools', 'effective online learning tool', 'custom designed optimization algorithms', 'custom categorical variational autoencoder', 'highly capable tool', 'quickly evolving tools', 'cost-effective computational tools', 'promising generic tool', 'increasingly popular tool', 'modern containerization tools', 'machine learning tool', 'sktime includes tools', 'visual analytics tool']),
    #     ReplacementConcept('complex overlapping code bases', 1, ['code base', 'starter code base', 'author code base', 'shared knowledge base', 'base neural network layers shared', 'shared latent bases', 'complex data structure', 'complex wavelet signals', 'consecutive complex signal values', 'complex systems space', 'literature presenting complex', 'inherently complex symbolic objects', 'building complex network architectures', 'existing complex neural networks', 'complex maze-like structure', 'complex structure', 'complex cell layer repeatedly', 'complex road curvatures', 'model complex systems consisting', 'complex neural network architectures', 'complex sensor data', 'complex sensory inputs', 'possibly complex learning system', 'complex deep learning architectures', 'complex system', 'complex software-intensive systems', 'complex systems bring', 'complex hypothesis spaces', 'manipulating complex spaces', 'complex robotic systems', 'complex analytic subsets', 'complex projective space', 'complex systems', 'complex aggregation schemes', 'complex enterprise system', 'complex learning machines', 'complex machine learning models', 'complex machine learning', 'complex data sources', 'gain profile complex optimization problem', 'eventually learn complex programming idioms', 'large complex world', 'complex model architecture', 'complex numbers xi', 'overlapping group structure', 'capture complex relations', 'complex item hierarchy', 'complex architectures', 'implement increasing complex convex functions', 'exploring complex dependencies']),
    #     ReplacementConcept('serverless runtime system', 1, ['unknown time evolving system', 'biological natural systems', 'system identification', 'water storage system', 'nonequilibrium many-body system', 'real robotic systems', 'drone’s image recognition system', 'crossed wires represent multiple systems', 'targeted system', 'decision support systems provided', 'develop classification systems', 'submit system description papers', 'underlying system infrastructure', 'good concept representation learning system', 'nonequilibrium many-body systems', 'standard recommender system metrics', 'set system', 'power system', 'sensor systems', 'human auditory system', 'general type-2 fuzzy systems', 'quantum linear system algorithm', 'system dynamics equations', 'efficient machine learning systems design', 'machine learning systems considers', 'auditory system', 'actual intelligent maritime monitoring systems', 'system input', 'submitted online learning systems', 'malware classification system', 'test systems produce', 'computational model system', 'trustworthy machine learning systems', 'proposed training system', 'health system', 'traditional system', 'system transition', 'model complex systems consisting', 'operationalized scoring systems', 'visual system', 'automatic shape control system', 'expect broadly applicable intelligent systems', 'automated feedback system based', 'expert system administrators', 'chaotic systems', 'economical power system operations', 'heterogeneous multi-agent systems', 'conscious systems', 'popular recommendation systems datasets', 'concept algebra system'])
    # ]

    # concepts = [ 
    #     ReplacementConcept('operating systems', 22.0, ['ll system', 'expert system', 'defensive system', 'larger system', 'operating point', 'embedding system', 'ensemble system', 'knowledge-based system', 'logging system', 'system operator', 'dem-ai system', 'operating machines', 'protein system', 'system outputs', 'linear system', 'online system', 'neural system', 'crm system', 'operating systems', 'recommender system', 'analysis system', 'solar system', 'low-dimensional system', 'attacking system', 'se system', 'system malfunction', 'system logs', 'predictive system', 'proof system', 'lorenz system', 'system user', 'pilot system', 'system specifications', 'system learns', 'fl system', 'system selects', 'articulatory system', 'advertising system', 'fingerprinting system', 'system design', 'system dynamics', 'system state', 'intelligent system', 'hybrid system', 'earth system', 'transmon system', 'database system', 'end-to-end system', 'autonomous system', 'system inputs']),
    #     ReplacementConcept('existing operating systems', 9.083333333333334, ['operating systems', 'existing scoring systems', 'existing embedding systems', 'autonomous systems', 'software systems', 'many-body systems', 'scoring systems', 'test systems', 'robotic systems', 'operating point', 'health systems', 'physical systems', 'operating machines', 'atomistic systems', 'existing surveys', 'nervous systems', 'networked systems', 'existing datasets', 'existing design', 'existing formalizations', 'linear systems', 'explanation systems', 'existing objects', 'economic systems', 'existing techniques', 'cognitive systems', 'linux systems', 'existing theorems', 'existing indices', 'existing law', 'predictive systems', 'ai-based systems', 'accurate systems', 'dl systems', 'endocrine systems', 'cad systems', 'knowledge-based systems', 'black systems', 'recommendation systems', 'interconnected systems', 'ofdm systems', 'small systems', 'existing works', 'inconsistent systems', 'smt systems', 'molecular systems', 'existing algorithms', 'existing research', 'systems heterogeneity', 'learned systems']),
    #     ReplacementConcept('forty years ago', 8.466666666666665, ['years', 'past years', 'weeks ago', '20 years', 'recent years', 'past 5 years', 'average schooling years', 'recent 20 years', 'revised uncertainty set ūo', '>ŷ − nbi', 'efficiently learn', 'ỹ = −1|x', 'batch size 200', 'easily adjusted', 'asymptotically biased', 'engineering research council', '• v∗', 'safety', 'neural combinatorial optimization', 'hilbert space dimension', 'h1 = h̄1', 'diagnostic risk groups', 'annex', 'pytorch library', 'multi-view approaches', 'jsa', 'intersection exists', 'z>j εj + ε >', 'zit+1', 'perform gpudirect peer-to-peer', '| ||s−1/2w||1 ≤', 'dataset tm =', 'θ ∼', 'computational chemistry', 'ordinary differential equation defined', 'pipeline’s topology', 'neural network design', 'ψ |', 'policy gradient update', 'r+ #x¥ 025a8', 'end objective', 'tibial acceleration', '+ k−1∑ i=1', '∑ a∈a ∫ f−1', 'active token units', 'θ = ∏ u∈a', 'maximum likelihood classifier', 'critical point θ ∈', 'connect multiple simple models', 'ambient brightness']),
    #     ReplacementConcept('provide unprecedented performance', 7.833333333333334, ['provide', 'performance', 'modelling performance', 'label-conditional performance', 'optimum performance', 'out-of-sample performance', 'clustering performance', 'splitting performance', 'stable performance', 'classification performance', 'performance guarantees', 'computing performance', 'prediction performance', 'previous performance', 'statistical performance', 'performance curves', 'poor performance', 'localization performance', 'impressive performance', 'major performance', 'human-like performance', 'minor performance', 'performance gaps', 'performance compared', 'performance score', 'performance specification', 'performance component', 'loss performance', 'asymptotic performance', 'peak performance', 'performance characteristics', 'performance improvement', 'personalized-data performance', 'performance improvements', 'held-out performance', 'human performance', 'improved performance', 'empirical performance', 'performance bounds', 'payload performance', 'performance amplification', 'performance guarantee', 'performance gap', 'performance modeling', 'performance mitigation', 'detection performance', 'art performance', 'compare performance', 'state-of-the-art performance', 'human-level performance']),
    #     ReplacementConcept('40 years ago', 5.466666666666667, ['years', 'past years', 'weeks ago', '40%', '20 years', 'recent years', 'stanford 40 actions', 'past 5 years', '40% instances', 'average schooling years', 'instance #40', '40 ≤ weight', '40% faster', 'recent 20 years', '40 training samples', '40% white males', 'ζ ′t = 40', 'revised uncertainty set ūo', '>ŷ − nbi', 'efficiently learn', 'ỹ = −1|x', 'batch size 200', 'easily adjusted', 'asymptotically biased', 'engineering research council', '• v∗', 'safety', 'neural combinatorial optimization', 'hilbert space dimension', 'h1 = h̄1', 'diagnostic risk groups', 'annex', 'pytorch library', 'multi-view approaches', 'jsa', 'intersection exists', 'z>j εj + ε >', 'zit+1', 'perform gpudirect peer-to-peer', '| ||s−1/2w||1 ≤', 'dataset tm =', 'θ ∼', 'computational chemistry', 'ordinary differential equation defined', 'pipeline’s topology', 'neural network design', 'ψ |', 'policy gradient update', 'r+ #x¥ 025a8', 'end objective']),
    #     ReplacementConcept('system software', 5.321428571428571, ['software system', 'software', 'll system', 'expert system', 'software systems', 'software technology', 'defensive system', 'larger system', 'embedding system', 'ensemble system', 'knowledge-based system', 'logging system', 'system operator', 'dem-ai system', 'protein system', 'system outputs', 'linear system', 'online system', 'neural system', 'crm system', 'recommender system', 'analysis system', 'software development', 'solar system', 'low-dimensional system', 'attacking system', 'se system', 'system malfunction', 'software projects', 'quantum software', 'system logs', 'predictive system', 'proof system', 'software crisis', 'lorenz system', 'system user', 'pilot system', 'software engineering', 'system specifications', 'system learns', 'software ecosystem', 'fl system', 'system selects', 'articulatory system', 'advertising system', 'fingerprinting system', 'system design', 'system dynamics', 'system state', 'intelligent system']),
    #     ReplacementConcept('os state', 5.166666666666666, ['state encoding', 'state distributions', 'state input', 'improvisation state', 'true state', 'state variables', 'state information', 'prior state', 'state |a〉', 'state dimension', 'state transition', 'state v2', 'preferred state', 'critical state', 'state si', 'state trajectory', 'local state', 'many-body state', 'world state', 'state |ϕ〉', 'state embeddings', 'state estimation', 'abstract state', 'state evolution', 'end state', 'trap state', 'specific state', 'kth state', 'final state', 'terminal state', 'state design', 'state |x〉', 'starting state', 'state |φ〉', 'steady state', 'product state', 'state variable', 'state vector', 'state machine', 'metastable state', 'initial state', 'physiology state', 'state block', 'system state', 'belief state', 'quantum state', 'state representations', 'state |ψy', 'knowledge state', 'white state']),
    #     ReplacementConcept('virtual memory', 5.0, ['memory', 'memory storage', 'semantic memory', 'additional memory', 'virtual point', 'memory management', 'memory utilization', 'memory complexities', 'memory cell', 'memory mapping', 'virtual counts', 'memory contents', 'memory footprint', 'virtual examples', 'memory locations', 'working memory', 'memory budgets', 'memory call', 'short-term memory', 'external memory', 'memory states', 'shared memory', 'memory operations', 'requested memory', 'memory matrix', 'virtual replica', 'virtual datasets', 'memory consumption', 'memory occupation', 'read/write memory', 'memory caching', 'memory component', 'memory buffer', 'memory bandwidth', 'long-term memory', 'cache memory', 'virtual property', 'memory exemplars', 'memory retrieval', 'memory complexity', 'assigned memory', 'memory budget', 'large memory', 'replay memory', 'memory bottleneck', 'recurrent memory', 'host memory', 'memory module', 'memory block', 'associative memory']),
    #     ReplacementConcept('data structures', 4.833333333333334, ['structures', 'gdsc data', 'field data', 'data si', 'stroke data', 'non-sensitive data', 'waveform data', 'train data', 'data needed', 'sensory data', 'data subjects', 'data adapter', 'sequential data', 'spectral data', 'model data', 'unlabelled data', 'data specific', 'aligned data', 'filtered data', 'nv data', 'data communication', 'data record', 'clickstream data', 'imaging data', 'biased data', 'unweighted data', 'local data', 'data pairs', 'ch data', 'multimedia data', 'data window', 'gps data', 'limited data', 'syntactic data', 'data types', 'observational data', 'sketch data', 'explainee data', 'data universe', 'observable data', 'data scientists', 'off-policy data', 'data assimilation', 'semi-unsupervised data', 'data scenario', 'sensing data', 'data pxtqt', 'data distributions', 'data stored', 'complete data']),
    #     ReplacementConcept('operating system', 4.75, ['ll system', 'expert system', 'defensive system', 'larger system', 'operating point', 'embedding system', 'ensemble system', 'knowledge-based system', 'logging system', 'system operator', 'dem-ai system', 'operating machines', 'protein system', 'system outputs', 'linear system', 'online system', 'neural system', 'crm system', 'operating systems', 'recommender system', 'analysis system', 'solar system', 'low-dimensional system', 'attacking system', 'se system', 'system malfunction', 'system logs', 'predictive system', 'proof system', 'lorenz system', 'system user', 'pilot system', 'system specifications', 'system learns', 'fl system', 'system selects', 'articulatory system', 'advertising system', 'fingerprinting system', 'system design', 'system dynamics', 'system state', 'intelligent system', 'hybrid system', 'earth system', 'transmon system', 'database system', 'end-to-end system', 'autonomous system', 'system inputs']),
    #     ReplacementConcept('heterogeneous hardware', 4.75, ['hardware', 'hardware impairments', 'hardware components', 'application-specific hardware', 'hardware footprint', 'hardware overhead', 'heterogeneous tasks', 'heterogeneous demonstration', 'heterogeneous model', 'hardware realization', 'heterogeneous scenario', 'heterogeneous population', 'trusted hardware', 'heterogeneous edges', 'hardware implementation', 'heterogeneous networks', 'heterogeneous effects', 'hardware resources', 'hardware cost', 'hardware accelerators', 'heterogeneous clusters', 'neuromorphic hardware', 'heterogeneous graphs', 'heterogeneous ensembles', 'heterogeneous graph', 'heterogeneous learning', 'specialized hardware', 'reconfigurable hardware', 'hardware architects', 'hardware utilization', 'hardware architectures', 'heterogeneous setting', 'quantum hardware', 'efficient hardware realization', 'trusted hardware enclaves', 'heterogeneous qos requirements', 'hardware design approaches', 'heterogeneous causal effects', 'heterogeneous data types', 'embedded hardware system', 'heterogeneous search space', 'irregular heterogeneous graphs', 'heterogeneous transfer learning', 'heterogeneous ehr data', 'heterogeneous mixed learning', 'multiple heterogeneous domains', 'heterogeneous information network', 'heterogeneous sensor networks', 'heterogeneous information networks', 'hardware trojan triggered']),
    #     ReplacementConcept('future systems', 4.606060606060606, ['future adaptable systems', 'future', 'autonomous systems', 'software systems', 'many-body systems', 'scoring systems', 'test systems', 'unobserved future', 'robotic systems', 'health systems', 'physical systems', 'future gradients', 'future rewards', 'atomistic systems', 'future studies', 'nervous systems', 'operating systems', 'networked systems', 'future works', 'future behaviour', 'future horizon', 'linear systems', 'explanation systems', 'future context', 'economic systems', 'cognitive systems', 'linux systems', 'future actions', 'predictive systems', 'ai-based systems', 'accurate systems', 'dl systems', 'endocrine systems', 'cad systems', 'future research', 'knowledge-based systems', 'black systems', 'recommendation systems', 'interconnected systems', 'ofdm systems', 'small systems', 'inconsistent systems', 'smt systems', 'molecular systems', 'future direction', 'systems heterogeneity', 'learned systems', 'expert systems', 'fl systems', 'dynamical systems']),
    #     ReplacementConcept('security models', 4.4, ['models', 'security', 'basic models', 'statistic models', 'security violation', 'binary-based models', 'bayesian models', 'models rely', 'gaifman models', 'parametric models', 'deterministic models', 'factored models', 'textual models', 'dcnn models', 'non-parametric models', 'describe models', 'one-step models', 'similar models', 'extracted models', 'arma models', 'forward models', 'lgmlvq models', 'good-enough models', 'mle models', 'algorithmic models', 'effective models', 'cnn-based models', 'iv models', 'ae models', 'joint models', 'semi-supervised models', 'final models', 'unnormalized models', 'unstable models', 'base-λ/α models', 'product models', 'rnn models', 'lifted models', 'edge-based models', 'gat models', 'standard models', 'cyber security', 'non-network models', 'measurement models', 'dl-based models', 'compensatory models', 'lstm-ad models', 'map-estimated models', 'trust models', 'probabilistic models']),
    #     ReplacementConcept('dynamic optimization', 4.333333333333334, ['dynamic portfolio optimization', 'optimization', 'dynamic', 'dynamic graphs', 'dynamic negatives', 'optimization budget', 'polynomial optimization', 'optimization procedure', 'constrained optimization', 'global optimization', 'perform optimization', 'gradient-based optimization', 'optimization formulation', 'dynamic data', 'black-box optimization', 'dynamic voltage', 'convex optimization', 'primal-dual optimization', 'dynamic programming', 'handover optimization', 'design optimization', 'adam optimization', 'alternating optimization', 'optimization layer', 'optimization error', 'dynamic instances', 'dynamic policies', 'dynamic learning', 'manycore optimization', 'dynamic instance', 'efficient optimization', 'min-max optimization', 'optimization kernel', 'dynamic parameters', 'nonconvex optimization', 'dynamic range', 'sum-of-nonconvex optimization', 'hyperparameter optimization', 'dynamic routing', 'optimization ran', 'optimization variables', 'optimization difficulty', 'bayesian optimization', 'optimization framework', 'optimization technique', 'dynamic transformation', 'multi-fidelity optimization', 'dynamic features', 'discrete optimization', 'classification-based optimization']),
    #     ReplacementConcept('database tables', 4.25, ['database', 'map database', 'cross tables', 'spatial database', 'real-time database', 'mimic-iii database', 'central database', 'lookup tables', 'training database', 'centralized database', 'database molecules', 'lincs database', 'database system', 'larger database', 'endgame database', 'classifying database', 'pubchem database', 'oeis database', 'tables 3–4', 'tables 2', 'tables 1–2', 'freebase database', 'decision tables', 'database table', 'explanation tables', 'probability tables', 'update database', 'tables iv', 'federated database', 'truth tables', 'parameter database', 'learning database', 'nosql database', 'osm database', 'mnist database', 'master database', 'input database', 'entire database', 'random database', 'fast database', 'database systems', 'experimental database', 'database top500', 'interpolating look-up tables', 'canonical database instance', 'master record database', 'ground truth database', 'weimar jazz database', 'rdf database system', 'toronto face database']),
    #     ReplacementConcept('process table', 4.25, ['process', 'table', 'review process', 'reference table', 'selection process', 'hiring process', 'automl process', 'table ii', 'forward process', 'bottom table', 'process calculi', 'recursive process', 'periodic table', 'hts process', 'cognitive process', 'look-up table', 'random process', 'measurement process', 'diffusion process', 'estimation process', 'fine-tuning process', 'gamma process', 'innovations process', 'n-times table', 'observation process', 'dp table', 'table s1', 'iterative process', 'optimisation process', 'boosting process', 'construction process', 'table 2a', 'test process', 'sampling process', 'classification process', 'ml process', 'table shows', 'reconstruction process', 'modeling process', 'forecasting process', 'continuous process', 'table 1a', 'observation table', 'teaching process', 'process noise', 'process data', 'table 3b', 'screening process', 'table understanding', 'output process']),
    #     ReplacementConcept('lambda model', 4.166666666666666, ['lambda', 'model', 'model inversion', 'gcn model', 'model hm', 'threat model', 'simulation model', 'art model', 'meta-learning model', 'ilp model', 'noisy model', 'model data', 'mle model', 'model knowledge', 'specific model', 'model sees', 'wren model', 'model hyperparameters', 'probabilistic model', 'small model', 'reward model', 'business model', 'model pre-training', 'model topology', 'backbone model', 'adaptive model', 'personal model', 'dl model', 'main-effects model', 'resnet model', 'model fits', 'structural model', 'dnn model', 'problem model', 'efge-bern model', 'rmdl model', 'bayesian model', 'calibration model', 'model architectures', 'recurrent model', 'mental model', 'model 2', 'bert model', 'fine-tuned model', 'model pθ', 'model perspective', 'model hypothesis', 'vector-space model', 'click model', 'nmt model']),
    #     ReplacementConcept('scheduling algorithm', 4.0, ['algorithm', 'k-means algorithm', 'ppo algorithm', 'quantum algorithm', 'popular algorithm', 'oversampling algorithm', 'demlearn algorithm', 'ilp algorithm', 'adasecant algorithm', 'algorithm configuration', 'notears algorithm', 'algorithm recommendation', 'accelerated algorithm', 'occam algorithm', 'ddac algorithm', 'k-mapper algorithm', 'adaboost algorithm', 'asynchronous scheduling', 'asynchronous algorithm', 'csi algorithm', 'omniscient algorithm', 'backpropagation algorithm', 'push-sum algorithm', 'algorithm approxmax', 'cd-1 algorithm', 'randomized algorithm', 'nvse algorithm', 'arbitrary algorithm', 'algorithm terminates', 'algorithm 1', 'algorithm key', 'd-glmnet algorithm', 'ecosvm algorithm', 'erm algorithm', 'flora algorithm', '-greedy algorithm', 'scg algorithm', 'baum-welch algorithm', 'ap algorithm', 'algorithm succeeds', 'ϕ-lcb algorithm', 'maxvol algorithm', 'sampling algorithm', 'mchl algorithm', 'gge algorithm', 'rl algorithm', 'algorithm listed', 'mm algorithm', 'mc2h algorithm', 'fci algorithm']),
    #     ReplacementConcept('improve performance', 4.0, ['improve generalization performance', 'improve clustering performance', 'performance', 'improve', 'modelling performance', 'label-conditional performance', 'optimum performance', 'out-of-sample performance', 'clustering performance', 'splitting performance', 'stable performance', 'classification performance', 'performance guarantees', 'computing performance', 'prediction performance', 'previous performance', 'statistical performance', 'performance curves', 'poor performance', 'localization performance', 'impressive performance', 'major performance', 'human-like performance', 'minor performance', 'performance gaps', 'performance compared', 'performance score', 'performance specification', 'performance component', 'loss performance', 'asymptotic performance', 'peak performance', 'performance characteristics', 'improve generalization', 'performance improvement', 'personalized-data performance', 'performance improvements', 'held-out performance', 'improve classification', 'human performance', 'improve fab', 'improved performance', 'empirical performance', 'improve accuracy', 'performance bounds', 'payload performance', 'performance amplification', 'performance guarantee', 'performance gap', 'performance modeling']),
    #     ReplacementConcept('time window', 4.0, ['τξ time window', 'pre-defined time window duration', 'time', 'window', 'generation time', 'continuous time', 'time evolution', 'computing time', 'merging time', 'time cost', 'data window', 'time polynomial', 'time series', 'survival time', 'real time', 'time consuming', 'time budget', 'lookback window', 'gpu time', 'physical time', 'time period', 'dwell time', 'estimated time', 'predictor window', 'time breakdown', 'mixing time', 'blocking time', 'discrete time', 'prediction time', 'time consumed', 'time tz', 'time frame', 'lead time', 'extrapolation window', 'time ranks', 'time slots', 'inter-arrival time', 'reference time', 'hiking time', 'testing time', 'meta-test time', 'expected time', 'time scales', 'time structure', 'hitting time', 'sub-bin time', 'time tk', 'wallclock time', 'unit time', 'communication time']),
    #     ReplacementConcept('permissions tables', 4.0, ['cross tables', 'lookup tables', 'tables 3–4', 'tables 2', 'tables 1–2', 'decision tables', 'explanation tables', 'probability tables', 'tables iv', 'truth tables', 'interpolating look-up tables', 'joining related tables', 'revised uncertainty set ūo', '>ŷ − nbi', 'efficiently learn', 'ỹ = −1|x', 'batch size 200', 'easily adjusted', 'asymptotically biased', 'engineering research council', '• v∗', 'safety', 'neural combinatorial optimization', 'hilbert space dimension', 'h1 = h̄1', 'diagnostic risk groups', 'annex', 'pytorch library', 'multi-view approaches', 'jsa', 'intersection exists', 'z>j εj + ε >', 'zit+1', 'perform gpudirect peer-to-peer', '| ||s−1/2w||1 ≤', 'dataset tm =', 'θ ∼', 'computational chemistry', 'ordinary differential equation defined', 'pipeline’s topology', 'neural network design', 'ψ |', 'policy gradient update', 'r+ #x¥ 025a8', 'end objective', 'tibial acceleration', '+ k−1∑ i=1', '∑ a∈a ∫ f−1', 'active token units', 'θ = ∏ u∈a']),
    #     ReplacementConcept('knob-free design', 4.0, ['design', 'pot design', 'design choices', 'drug design', 'design details', 'existing design', 'layout design', 'design pq-unbiased', 'feature design', 'design optimization', 'state design', 'design intent', 'design matrix', 'design requirements', 'polymer design', 'design phase', 'system design', 'design suggestions', 'inverse design', 'body design', 'design choice', 'design parameters', 'design transparent', 'design objectives', 'algorithm design', 'materials design', 'design combinations', 'candidate design', 'network design', 'design variables', 'original design', 'morphology design', 'curriculum design', 'design tasks', 'visual design', 'adversarial design', 'experiment design', 'design space', 'design features', 'design parameter', 'design consistency', 'design considerations', 'design action', 'design decisions', 'design procedure', 'design specification', 'manycore design', 'design process', 'initial design', 'computer-generated design']),
    #     ReplacementConcept('wide range', 4.0, ['range', 'range tested', 'wider range', 'training range', 'range test', 'broader range', 'scoring range', 'range estimation', 'wide array', 'broad range', 'wide resnet', 'wide variety', 'angular range', 'wide networks', 'dynamic range', 'wide spectrum', 'data range', '= range', 'time range', 'wide margin', 'range expects', 'range queries', 'range predictions', 'average range', 'energy range', 'ages range', 'feature range', 'wide diversity', 'date range', 'input range', 'temporal range', 'logarithmic range', 'true range', 'narrower range', 'feasible range', '95 range', 'wide residuals', 'parameter range', 'geographic range', 'gradient range', 'quantifiers range', 'small range', 'world wide web', 'sample size range', 'training size range', 'z2 ∈ range', 'found wide application', 'dropout nn-12-layer wide', 'finitely wide nns', 'dropout nn-4-layer wide']),
    #     ReplacementConcept('data-centric architecture', 4.0, ['architecture', 'convolutional architecture', 'dual architecture', 'nmt architecture', 'supervised architecture', 'basic architecture', 'final architecture', 'dcgan architecture', 'tfbt architecture', 'similar architecture', 'optimal architecture', 'transformer architecture', 'communication architecture', 'distributed architecture', 'ecd architecture', 'option-critic architecture', 'encoder-decoder architecture', 'dl architecture', 'full architecture', 'proposed architecture', 'block architecture', 'stam architecture', 'iprescribe architecture', 'multitask architecture', 'u-net architecture', 'hibert architecture', 'dcnn architecture', 'circuit architecture', 'vgg architecture', 'dnn architecture', 'node architecture', 'optioncritic architecture', 'specific architecture', 'base architecture', 'architecture search', 'reference architecture', 'hierarchical architecture', 'cnn architecture', 'network architecture', 'mtl architecture', 'pase architecture', 'capsnet architecture', 'architecture weights', 'siamese architecture', 'architecture optimization', 'architecture ba-0-50-50', 'resnet-18 architecture', 'architecture space', 'data-centric synchronization', 'stams architecture']),
    #     ReplacementConcept('large amount', 4.0, ['large', 'amount', 'reasonable amount', 'limited amount', 'large k̂', 'large errors', 'large capacity', 'small amount', 'large graph', 'large numbers', 'large model', 'unreasonable amount', 'large platform', 'large collections', 'large organizations', 'large collection', 'smaller amount', 'large portion', 'large variance', 'large amounts', 'large number', 'large instances', 'large weights', 'large space', 'large values', 'large datasets', 'update amount', 'large margins', 'large −kl', 'large samples', 'large nt', 'sufficient amount', 'large state', 'large models', 'large dataset', 'large memory', 'large coefficients', 'large windows', 'large body', 'large graphs', 'infinite amount', 'finite amount', 'large variety', 'large coresets', 'large images', 'total amount', 'large σ', 'extremely large', 'increasing amount', 'large corpus']),
    #     ReplacementConcept('polystore architecture', 4.0, ['architecture', 'convolutional architecture', 'dual architecture', 'nmt architecture', 'supervised architecture', 'basic architecture', 'final architecture', 'dcgan architecture', 'tfbt architecture', 'similar architecture', 'optimal architecture', 'transformer architecture', 'communication architecture', 'distributed architecture', 'ecd architecture', 'option-critic architecture', 'encoder-decoder architecture', 'dl architecture', 'full architecture', 'proposed architecture', 'block architecture', 'stam architecture', 'iprescribe architecture', 'multitask architecture', 'u-net architecture', 'hibert architecture', 'dcnn architecture', 'circuit architecture', 'vgg architecture', 'dnn architecture', 'node architecture', 'optioncritic architecture', 'specific architecture', 'base architecture', 'architecture search', 'reference architecture', 'hierarchical architecture', 'cnn architecture', 'network architecture', 'mtl architecture', 'pase architecture', 'capsnet architecture', 'architecture weights', 'siamese architecture', 'architecture optimization', 'architecture ba-0-50-50', 'resnet-18 architecture', 'architecture space', 'stams architecture', 'deep architecture']),
    #     ReplacementConcept('sender writing', 4.0, ['writing', 'sender', 'writing system', 'writing assessment', 'revised uncertainty set ūo', '>ŷ − nbi', 'efficiently learn', 'ỹ = −1|x', 'batch size 200', 'easily adjusted', 'asymptotically biased', 'engineering research council', '• v∗', 'safety', 'neural combinatorial optimization', 'hilbert space dimension', 'h1 = h̄1', 'diagnostic risk groups', 'annex', 'pytorch library', 'multi-view approaches', 'jsa', 'intersection exists', 'z>j εj + ε >', 'zit+1', 'perform gpudirect peer-to-peer', '| ||s−1/2w||1 ≤', 'dataset tm =', 'θ ∼', 'computational chemistry', 'ordinary differential equation defined', 'pipeline’s topology', 'neural network design', 'ψ |', 'policy gradient update', 'r+ #x¥ 025a8', 'end objective', 'tibial acceleration', '+ k−1∑ i=1', '∑ a∈a ∫ f−1', 'active token units', 'θ = ∏ u∈a', 'maximum likelihood classifier', 'critical point θ ∈', 'connect multiple simple models', 'ambient brightness', '+ knb2 −d + µ', '> c0 ·max', '1− η∗h', 'threads parallelly compute']),
    #     ReplacementConcept('machine learning', 4.0, ['learning machine', 'machine learning interpretability', 'machine learning models', 'machine learning tools', 'machine learning area', 'automatic machine learning', 'trustworthy machine learning', 'classical machine learning', 'amazon machine learning', 'machine learning baselines', 'machine learning scientists', 'exploiting machine learning', 'machine learning techniques', 'machine learning system', 'supervised machine learning', 'machine learning classifier', 'machine learning computations', 'machine learning projects', 'machine learning service', 'end-to-end machine learning', 'machine learning software', 'adversarial machine learning', 'machine learning technology', 'machine learning group', 'machine learning experts', 'machine learning predictions', 'machine learning research', 'lifelong machine learning', 'machine learning representation', 'machine learning methods', 'machine learning task', 'tn machine learning', 'distributed machine learning', 'machine learning paradigm', 'large-scale machine learning', 'machine learning method', 'machine learning classifiers', 'machine learning framework', 'automated machine learning', 'machine learning technique', 'persistent-homology-based machine learning', 'machine learning sort', 'ideal learning machine', 'machine learning characteristic', 'universal learning machine', 'machine learning estimators', 'machine learning tasks', 'private machine learning', 'machine learning wikipedia', 'informed machine learning']),
    #     ReplacementConcept('linux kernel', 3.866666666666667, ['kernel', 'universal kernel', 'kernel evaluations', 'kernel combinations', 'min-max kernel', 'mh kernel', 'intersection kernel', 'cartesian kernel', 'spectral kernel', 'kernel matrix', 'reduced kernel', 'kernel logistic', 'kernel values', 'stump kernel', 'se kernel', 'perceptron kernel', 'polynomial kernel', 'kernel approximation', 'kernel function', 'learned kernel', 'level-2 kernel', 'nonlinear kernel', 'tensor-product kernel', 'kernel inference', 'arc-cosine kernel', 'kernel smoothing', 'linux systems', 'kernel receives', 'smoothing kernel', 'sparse kernel', 'reproducing kernel', 'kernel mode', 'fleet kernel', 'markov kernel', 'kernel kg', 'kernel goodness', '2x2 kernel', 'rbf kernel', 'offline kernel', 'sigmoid kernel', 'scalar-valued kernel', 'optimization kernel', 'selected kernel', 'kernel pca', 'combination kernel', 'kernel kf', 'periodic kernel', 'average kernel', 'kernel γ', 'lsh kernel']),
    #     ReplacementConcept('application code', 3.833333333333333, ['code', 'application', 'ib-quantization code', 'typical application', 'code refactoring', 'lower-dimensional code', 'code optimisation', 'pseudo code', 'code dump', 'hidden code', 'smali code', 'programming code', 'manually code', 'zip code', 'hexadecimal code', 'application layer', 'malware code', 'healthcare application', 'code release', 'repeated application', 'code size', 'sparse code', 'application scenarios', 'sample code', 'source code', 'spherical code', 'seedot-generated code', 'distributed code', 'additional code', 'code edits', 'potential application', 'code representation', 'representing code', 'keras code', 'icd code', 'learned code', 'code space', 'code tetris', 'javascript code', 'code book', 'application scope', 'code fragments', 'canonical code', 'mapping code', 'code released', 'application dataset', 'library code', 'latent code', 'code inspection/analysis', 'model code']),
    #     ReplacementConcept('learned components', 3.8, ['learned', 'hardware components', 'learned regularizer', 'ml components ml', 'independent components', 'representations learned', 'learned resampler', 'policy learned', 'previously learned', 'features learned', 'important components', 'learned tasks', 'learned edges', 'representation learned', 'model learned', 'pca components', 'components drawn', 'rulesets learned', 'learned embedding', 'options learned', 'learned estimate', 'learned kernel', 'connected components', 'learned optimizer', 'filters learned', 'learned oracle', 'learned transitions', 'learned network', 'learned rewards', 'successfully learned', 'learned rules', 'learned algorithms', 'learned pθ', 'learned classifier', 'skill-dynamics learned', 'learned kernels', 'ml components', 'components learn', 'models learned', 'learned incrementally', 'learned rulesets', 'individual components', 'unwhitened components', 'learned weights', 'learned systems', 'easily learned', 'learned machine', 'model components', 'principal components', 'learned cspn']),
    #     ReplacementConcept('dbms transactions', 3.583333333333333, ['transactions', 'non-fraud transactions', 'ieee transactions', 'financial transactions', 'in-person transactions', 'ieee/acm transactions', 'acm transactions', 'normal transactions', 'transactions involved', 'fraud transactions', 'credit card transactions', 'credit cards’ fraud transactions', 'detect credit cards’ fraud transactions', 'revised uncertainty set ūo', '>ŷ − nbi', 'efficiently learn', 'ỹ = −1|x', 'batch size 200', 'easily adjusted', 'asymptotically biased', 'engineering research council', '• v∗', 'safety', 'neural combinatorial optimization', 'hilbert space dimension', 'h1 = h̄1', 'diagnostic risk groups', 'annex', 'pytorch library', 'multi-view approaches', 'jsa', 'intersection exists', 'z>j εj + ε >', 'zit+1', 'perform gpudirect peer-to-peer', '| ||s−1/2w||1 ≤', 'dataset tm =', 'θ ∼', 'computational chemistry', 'ordinary differential equation defined', 'pipeline’s topology', 'neural network design', 'ψ |', 'policy gradient update', 'r+ #x¥ 025a8', 'end objective', 'tibial acceleration', '+ k−1∑ i=1', '∑ a∈a ∫ f−1', 'active token units']),

    #     ]

    text = '''RISC-V makes use of a link register, like similar RISC architectures such as PowerPC, ARM, and SPARC. In RISC-V this is labeled the ra register. The purpose of this register is to optimize calls to leaf subroutines since the return address need not be pushed or popped on the stack. The implication of this is that in RISC ROP exploitation is mostly limited to non-leaf function epilogues, and RISC-V ROP is no exception.For our purposes, we define a chainable ROP gadget as follows: an instruction sequence that:1. Loads a value from a(sp) into ra where a is some positive immediate value divisible by 82. Adds an immediate value b to sp where b > a and b is divisible by 16 (due to stack-alignment requirements)3. Ends in a ret (equivalent to jr ra)In addition to the above steps needed to maintain the ROP chain, a good ROP gadget will contain a few extra instructions that perform useful work. Note that these requirements are fairly restrictive, and exclude gadgets that, for example, pop and jump to a register other than the ra register. For our purposes, we will focus on gadgets that fulfill these requirements (and thus look like function epilogues) but examining other classes of gadgets is a promising future research direction.
    As an example, below is a gadget that does no work except maintining the ROP chain. This is typically called a NOP gadget.0x0000000000097a68 : c.ldsp ra, 8(sp) c.addi sp, 0x10 c.jr raNote that in x86, the same three actions are performed by a single 1-byte instruction (ret). In SPARC, a similar gadget only requires a ret and restore to slide the register window. In ARM, a similar gadget looks like a LDMFD followed by a RET.The fact that the simplest ROP gadget in RISC-V requires more instructions than in other architectures has the following implications:1. When a chainable ROP gadget is found, it is very likely that the gadget formed part of a legitimate function epilogue. ROP gadgets that consist entirely of unintended instructions would be exceedingly rare.2. The three instructions may not always be contiguous; in other words, part of the work performed by the gadget may be located in between these three instructions.When this happens, the return-oriented programmer is unable to "trim" the work by jumping into the middle of the work like on other architectures. Even in ARM, the LDMFD and the RET are typically contiguous. Similarly, in SPARC, ret and restore are almost always contiguous. The implication of RISC-V’s departure from this norm is that RISC-V ROP chains sometimes must account for a larger number of undesirable gadget side effects.Take for example the following POP gadget:0x000000000006a5e8 : c.ldsp ra, 0x28(sp) c.ldsp s0, 0x20(sp) c.ldsp a0, 0(sp) c.ldsp a1, 8(sp) c.ldsp s1, 0x18(sp) c.ldsp s2, 0x10(sp) c.addi16sp sp, 0x30 c.jr raIf the Return-Oriented Programmer would like to use this gadget to pop only s2 (maybe a0 contains a runtime-calculated value she would not like to overwrite), she is unable to do so because jumping directly to the c.ldsp s2, 0x10(sp) instruction would skip the load into ra, breaking the ROP chain and causing an infinite loop.A similar issue presents itself with ARM through LDMFD instructions that pop a large number of registers, and with SPARC through the restore instruction. Note however, that in RISC-V, the instructions sandwiched between c.ldsp ra, 0x28(sp) and c.addi16sp, sp, 0x30 are often not only pop instructions and thus can cause traps, undefined behavior, and undesirable memory corruption.
    The ideal way to avoid undesirable side effects is to entirely avoid using gadgets that cause them. However this is not always feasible, and sometimes more careful and deliberate treatment of side effects is needed.Take for example the following readMEM gadget:0x00000000000d3230 : c.ld a0, 8(a0) c.add a0, a5 c.ldsp a4, 0x28(sp) c.ld a5, 0(s0) bne a4, a5, 0x1e c.ldsp ra, 0x38(sp) c.ldsp s0, 0x30(sp) c.addi16sp sp, 0x40 c.jr raThis gadget is extremely valuable because it is a very rare readMEM gadget that reads memory pointed at by a registerthat is easily popped, incremented, and decremented through other gadgets, and does not perform a conditional branch depending on the read value. However, it is prone to the following side effects:1. The initial value of a5 is added to the read value of a0.2. The value of a5 is read from (s0).3. The value of a4 is popped and if the popped a4 is not equal to the read a5 then a branch occurs.Ideally, we want the initial value of a5 to be 0 so that the first side effect is avoided entirely, and we want (s0) to not trap and contain some constant known value so that we can make the popped a4 equal to the value, avoiding the branch. If we maintain these preconditions prior to invoking this gadget (for example, if we found and used a pop gadget for s0, a4, and a5), then we can prevent or account for these side effects. It turns out that these specific preconditions can be achieved using two other gadgets.In terms of crafting ROP chains, we can combine the gadgets used to fulfill preconditions and the gadget requiring the preconditions into a single logical unit to make programming large ROP chains easier.'''

    # concepts = [
    #     ReplacementConcept('ldsp ra', 0, ['ldsp radium', 'ldsp atomic number 88', 'ldsp Re', 'ldsp right ascension', 'ldsp Ra', 'ldsp celestial longitude', 'ldsp angular distance', 'ldsp Egyptian deity', 'ldsp metal', 'ldsp metallic element']),
    #     ReplacementConcept('brainfuck programs', 0, ['brainfuck plan', 'brainfuck programme', 'brainfuck broadcast', 'brainfuck platform', 'brainfuck political platform', 'brainfuck political program', 'brainfuck course of study', 'brainfuck curriculum', 'brainfuck syllabus', 'brainfuck computer program', 'brainfuck computer programme', 'brainfuck announcement', 'brainfuck computer software', 'brainfuck document', 'brainfuck idea', 'brainfuck info', 'brainfuck information', 'brainfuck package', 'brainfuck papers', 'brainfuck performance', 'brainfuck promulgation', 'brainfuck show', 'brainfuck software', 'brainfuck software package', 'brainfuck software program', 'brainfuck software system', 'brainfuck system', 'brainfuck system of rules', 'brainfuck thought', 'brainfuck written document', 'brainfuck create by mental act', 'brainfuck create mentally', 'brainfuck schedule']),
    #     ReplacementConcept('register', 0, ['registry', 'cash register', 'air duct', 'air passage', 'airway', 'cashbox', 'memory device', 'money box', 'quality', 'record', 'regulator', 'storage device', 'till', 'timber', 'timbre', 'tone', 'written account', 'written record', 'register', 'file', 'record', 'read', 'show', 'cross-file', 'affect', 'campaign', 'enrol', 'enroll', 'enter', 'indicate', 'inscribe', 'mail', 'play', 'post', 'put down', 'recruit', 'run', 'send', 'show up']),
    #     ReplacementConcept('extension', 0, ['propagation', 'extension service', 'university extension', 'filename extension', 'file name extension', 'reference', 'denotation', 'lengthiness', 'prolongation', 'telephone extension', 'extension phone', 'elongation', 'annex', 'annexe', 'wing', 'add-on', 'addition', 'airing', 'dance', 'delay', 'didactics', 'dissemination', 'education', 'educational activity', 'enlargement', 'expansion', 'hold', 'improver', 'instruction', 'longness', 'meaning', 'pedagogy', 'phone', 'postponement', 'property', 'public exposure', 'spreading', 'stretching', 'string', 'substance', 'teaching', 'telephone', 'telephone set', 'time lag', 'wait']),
    #     ReplacementConcept('purposes', 0, ['intent', 'intention', 'aim', 'design', 'function', 'role', 'use', 'determination', 'end', 'firmness', 'firmness of purpose', 'goal', 'resoluteness', 'resolution', 'resolve', 'usefulness', 'utility', 'purport', 'propose', 'decide', 'determine', 'intend', " make up one's mind ", 'mean', 'think']),
    #     ReplacementConcept('gadget', 0, ['appliance', 'contraption', 'contrivance', 'convenience', 'gizmo', 'gismo', 'widget', 'device']),
    #     ReplacementConcept('write', 0, ['compose', 'pen', 'indite', 'publish', 'drop a line', 'spell', 'communicate', 'correspond', 'create', 'create by mental act', 'create mentally', 'create verbally', 'delineate', 'describe', 'draw', 'intercommunicate', 'line', 'make', 'record', 'tape', 'trace']),
    #     ReplacementConcept('instructions', 0, ['instruction manual', 'book of instructions', 'operating instructions', 'manual']),
    #     ReplacementConcept('original address stored', 0, ['master address stored', 'master copy address stored', 'archetype address stored', 'pilot address stored', 'creation address stored', 'example address stored', 'model address stored', 'original computer address stored', 'original speech stored', 'original destination stored', 'original name and address stored', 'original savoir-faire stored', 'original code stored', 'original computer code stored', 'original delivery stored', 'original direction stored', 'original geographic point stored', 'original geographical point stored', 'original instruction stored', 'original manner of speaking stored', 'original speech act stored', 'original stance stored', 'original street sign stored', 'original tact stored', 'original tactfulness stored', 'original address stored', 'original turn to stored', 'original speak stored', 'original direct stored', 'original call stored', 'original cover stored', 'original treat stored', 'original handle stored', 'original plow stored', 'original deal stored', 'original accost stored', 'original come up to stored', 'original access stored', 'original adjust stored', 'original aim stored', 'original align stored', 'original aline stored', 'original apply stored', 'original broach stored', 'original come stored', 'original come up stored', 'original communicate stored', 'original employ stored', 'original initiate stored', 'original intercommunicate stored', 'original label stored', 'original line up stored', 'original place stored', 'original point stored', 'original target stored', 'original use stored', 'original utilise stored', 'original utilize stored']),
    #     ReplacementConcept('memory', 0, ['remembering', 'retention', 'retentiveness', 'retentivity', 'computer memory', 'storage', 'computer storage', 'store', 'memory board', 'basic cognitive process', 'cognitive psychology', 'computer hardware', 'faculty', 'hardware', 'internal representation', 'memory device', 'mental faculty', 'mental representation', 'module', 'representation', 'storage device']),
    #     ReplacementConcept('link', 0, ['nexus', 'linkup', 'tie', 'tie-in', 'connection', 'connectedness', 'connexion', 'liaison', 'contact', 'inter-group communication', 'radio link', 'data link', 'channel', 'circuit', 'command', 'communication channel', 'communication system', 'electric circuit', 'electrical circuit', 'fastener', 'fastening', 'fixing', 'form', 'holdfast', 'instruction', 'line', 'linear unit', 'linkage', 'program line', 'shape', 'statement', 'unification', 'union', 'associate', 'tie in', 'relate', 'colligate', 'link up', 'connect', 'tie', 'join', 'unite', 'yoke', 'attach', 'cerebrate', 'cogitate', 'think']),
    #     ReplacementConcept('show', 0, ['display', 'appearance', 'amusement', 'demo', 'demonstration', 'entertainment', 'feigning', 'pretence', 'pretending', 'pretense', 'simulation', 'social event', 'show', 'demo', 'exhibit', 'present', 'demonstrate', 'prove', 'establish', 'shew', 'testify', 'bear witness', 'evidence', 'picture', 'depict', 'render', 'express', 'evince', 'indicate', 'point', 'show up', 'read', 'register', 'record', 'usher', 'affirm', 'appear', 'communicate', 'conduct', 'confirm', 'convey', 'corroborate', 'direct', 'display', 'guide', 'impart', 'inform', 'interpret', 'lead', 'pass', 'pass along', 'pass on', 'put across', 'race', 'represent', 'reveal', 'run', 'substantiate', 'support', 'sustain', 'take']),
    #     ReplacementConcept('https', 0, ['hypertext transfer protocol', 'HTTP', 'communications protocol', 'protocol']),
    #     ReplacementConcept('gadgets', 0, ['appliance', 'contraption', 'contrivance', 'convenience', 'gizmo', 'gismo', 'widget', 'device']),
    #     ReplacementConcept('similar gadget', 0, ['similar appliance', 'similar contraption', 'similar contrivance', 'similar convenience', 'similar gizmo', 'similar gismo', 'similar widget', 'similar device']),
    #     ReplacementConcept('make', 0, ['brand', 'shuffle', 'shuffling', 'form', 'kind', 'reordering', 'sort', 'variety', 'make', 'do', 'get', 'create', 'induce', 'stimulate', 'cause', 'have', 'produce', 'draw', 'gain', 'take in', 'clear', 'earn', 'realize', 'realise', 'pull in', 'bring in', 'form', 'constitute', 'reach', 'get to', 'progress to', 'construct', 'build', 'name', 'nominate', 'attain', 'hit', 'arrive at', 'lay down', 'establish', 'hold', 'throw', 'give', 'make up', 'take', 'stool', 'defecate', 'work', 'cook', 'fix', 'ready', 'prepare', 'seduce', 'score', 'pretend', 'make believe', 'urinate', 'piddle', 'puddle', 'micturate', 'piss', 'pee', 'pee-pee', 'make water', 'relieve oneself', 'take a leak', 'spend a penny', 'wee', 'wee-wee', 'pass water', 'accomplish', 'achieve', 'acquire', 'act', 'add up', 'alter', 'amount', 'appear', 'appoint', 'approximate', 'assemble', 'assure', 'be', 'become', 'behave', 'change', 'charge', 'clean up', 'come', 'commit', 'comprise', 'consider', 'create by mental act', 'create from raw material', 'create from raw stuff', 'create mentally', 'develop', 'direct', 'egest', 'eliminate', 'ensure', 'estimate', 'excrete', 'execute', 'gather', 'gauge', 'get together', 'go across', 'go through', 'grow', 'guarantee', 'guess', 'head', 'insure', 'judge', 'look', 'modify', 'neaten', 'number', 'pass', 'perform', 'perpetrate', 'persuade', 'play', 'pull', 'rack up', 'reckon', 'regard', 'represent', 'secure', 'see', 'seem', 'square away', 'straighten', 'straighten out', 'tally', 'tidy', 'tidy up', 'total', 'view']),
    #     ReplacementConcept('future self-modified gadgets', 0, ['hereafter self-modified gadgets', 'futurity self-modified gadgets', 'time to come self-modified gadgets', 'future tense self-modified gadgets', 'commodity self-modified gadgets', 'good self-modified gadgets', 'tense self-modified gadgets', 'time self-modified gadgets', 'trade good self-modified gadgets', 'future self-modified appliance', 'future self-modified contraption', 'future self-modified contrivance', 'future self-modified convenience', 'future self-modified gizmo', 'future self-modified gismo', 'future self-modified widget', 'future self-modified device']),
    #     ReplacementConcept('scratch space', 0, ['abrasion space', 'scrape space', 'excoriation space', 'incision space', 'prick space', 'slit space', 'dent space', 'boodle space', 'bread space', 'cabbage space', 'clams space', 'dinero space', 'dough space', 'gelt space', 'kale space', 'lettuce space', 'lolly space', 'lucre space', 'loot space', 'moolah space', 'pelf space', 'shekels space', 'simoleons space', 'sugar space', 'wampum space', 'chicken feed space', 'scraping space', 'scratching space', 'scribble space', 'scrawl space', 'cacography space', 'scar space', 'mark space', 'blemish space', 'defect space', 'depression space', 'hand space', 'handwriting space', 'impression space', 'imprint space', 'lesion space', 'mar space', 'mash space', 'money space', 'noise space', 'script space', 'wound space', 'rub space', 'fray space', 'fret space', 'chafe space', 'scrape space', 'scratch up space', 'itch space', 'cancel space', 'call off space', 'scrub space', 'strike space', 'expunge space', 'excise space', 'scrape up space', 'come up space', 'engrave space', 'grave space', 'inscribe space', 'accumulate space', 'adjoin space', 'amass space', 'carve space', 'chip at space', 'collect space', 'compile space', 'contact space', 'delete space', 'hoard space', 'incise space', 'irritate space', 'meet space', 'pile up space', 'roll up space', 'touch space', 'scratch infinite', 'scratch blank', 'scratch distance', 'scratch blank space', 'scratch place', 'scratch quad', 'scratch amorphous shape', 'scratch area', 'scratch attribute', 'scratch character', 'scratch country', 'scratch expanse', 'scratch grapheme', 'scratch graphic symbol', 'scratch interval', 'scratch location', 'scratch surface area', 'scratch time interval', 'scratch type', 'scratch lay', 'scratch place', 'scratch pose', 'scratch position', 'scratch put', 'scratch set']),
    #     ReplacementConcept('temporary registers', 0, ['temp registers', 'temporary worker registers', 'worker registers', 'temporary registry', 'temporary cash register', 'temporary air duct', 'temporary air passage', 'temporary airway', 'temporary cashbox', 'temporary memory device', 'temporary money box', 'temporary quality', 'temporary record', 'temporary regulator', 'temporary storage device', 'temporary till', 'temporary timber', 'temporary timbre', 'temporary tone', 'temporary written account', 'temporary written record', 'temporary register', 'temporary file', 'temporary read', 'temporary show', 'temporary cross-file', 'temporary affect', 'temporary campaign', 'temporary enrol', 'temporary enroll', 'temporary enter', 'temporary indicate', 'temporary inscribe', 'temporary mail', 'temporary play', 'temporary post', 'temporary put down', 'temporary recruit', 'temporary run', 'temporary send', 'temporary show up']),
    #     ReplacementConcept('modify', 0, ['qualify', 'change', 'alter', 'add']),
    #     ReplacementConcept('side effects', 0, ['face effects', 'side of meat effects', 'position effects', 'slope effects', 'incline effects', 'English effects', 'ancestry effects', 'area effects', 'aspect effects', 'blood effects', 'blood line effects', 'bloodline effects', 'cut effects', 'cut of meat effects', 'descent effects', 'facet effects', 'formation effects', 'geological formation effects', 'line effects', 'line of descent effects', 'lineage effects', 'opinion effects', 'origin effects', 'parentage effects', 'part effects', 'pedigree effects', 'region effects', 'social unit effects', 'spin effects', 'stemma effects', 'stock effects', 'surface effects', 'unit effects', 'view effects', 'back effects', 'choose effects', 'endorse effects', 'go with effects', 'indorse effects', 'pick out effects', 'plump for effects', 'plunk for effects', 'pull effects', 'root effects', 'select effects', 'support effects', 'take effects', 'side personal effects', 'side personal estate', 'side personal property', 'side personalty', 'side private property']),
    #     ReplacementConcept('libc function', 0, ['libc mathematical function', 'libc purpose', 'libc role', 'libc use', 'libc office', 'libc part', 'libc affair', 'libc occasion', 'libc social occasion', 'libc social function', 'libc routine', 'libc subroutine', 'libc subprogram', 'libc procedure', 'libc computer software', 'libc duty', 'libc mathematical relation', 'libc package', 'libc relation', 'libc social affair', 'libc social event', 'libc social gathering', 'libc software', 'libc software package', 'libc software program', 'libc software system', 'libc usefulness', 'libc utility', 'libc work', 'libc operate', 'libc go', 'libc run', 'libc serve', 'libc officiate', 'libc answer', 'libc do', 'libc suffice']),
    #     ReplacementConcept('unintended instructions', 0, ['unintended instruction manual', 'unintended book of instructions', 'unintended operating instructions', 'unintended manual']),
    #     ReplacementConcept('rop gadgets', 0, ['rop appliance', 'rop contraption', 'rop contrivance', 'rop convenience', 'rop gizmo', 'rop gismo', 'rop widget', 'rop device']),
    #     ReplacementConcept('found', 0, ['earnings', 'pay', 'remuneration', 'salary', 'wage', 'establish', 'set up', 'launch', 'plant', 'constitute', 'institute', 'base', 'ground', 'initiate', 'open', 'open up', 'pioneer']),
    #     ReplacementConcept('perform', 0, ['execute', 'do', 'accomplish', 'act', 'action', 'carry out', 'carry through', 'fulfil', 'fulfill', 'move', 're-create']),
    #     ReplacementConcept('stack pointer', 0, ['batch pointer', 'deal pointer', 'flock pointer', 'good deal pointer', 'great deal pointer', 'hatful pointer', 'heap pointer', 'lot pointer', 'mass pointer', 'mess pointer', 'mickle pointer', 'mint pointer', 'muckle pointer', 'peck pointer', 'pile pointer', 'plenty pointer', 'pot pointer', 'quite a little pointer', 'raft pointer', 'sight pointer', 'slew pointer', 'spate pointer', 'tidy sum pointer', 'wad pointer', 'push-down list pointer', 'push-down stack pointer', 'smokestack pointer', 'push-down storage pointer', 'push-down store pointer', 'agglomerate pointer', 'chimney pointer', 'cumulation pointer', 'cumulus pointer', 'large indefinite amount pointer', 'large indefinite quantity pointer', 'list pointer', 'listing pointer', 'memory device pointer', 'mound pointer', 'storage device pointer', 'whole lot pointer', 'whole slew pointer', 'pile pointer', 'heap pointer', 'arrange pointer', 'lade pointer', 'laden pointer', 'load pointer', 'load up pointer', 'set up pointer', 'stack arrow', 'stack cursor', 'stack Spanish pointer', 'stack gun dog', 'stack indicator', 'stack mark', 'stack sporting dog']),
    #     ReplacementConcept('initial', 0, ['alphabetic character', 'letter', 'letter of the alphabet', 'sign']),
    #     ReplacementConcept('registers', 0, ['registry', 'cash register', 'air duct', 'air passage', 'airway', 'cashbox', 'memory device', 'money box', 'quality', 'record', 'regulator', 'storage device', 'till', 'timber', 'timbre', 'tone', 'written account', 'written record', 'register', 'file', 'read', 'show', 'cross-file', 'affect', 'campaign', 'enrol', 'enroll', 'enter', 'indicate', 'inscribe', 'mail', 'play', 'post', 'put down', 'recruit', 'run', 'send', 'show up']),
    #     ReplacementConcept('function', 0, ['mathematical function', 'purpose', 'role', 'use', 'office', 'part', 'affair', 'occasion', 'social occasion', 'social function', 'routine', 'subroutine', 'subprogram', 'procedure', 'computer software', 'duty', 'mathematical relation', 'package', 'relation', 'social affair', 'social event', 'social gathering', 'software', 'software package', 'software program', 'software system', 'usefulness', 'utility', 'work', 'operate', 'go', 'run', 'serve', 'officiate', 'answer', 'do', 'suffice']),
    #     ReplacementConcept('ret', 0, ['douse', 'dowse', 'drench', 'soak', 'sop', 'souse']),
    #     ReplacementConcept('unconditional branch', 0, ['unconditional subdivision', 'unconditional arm', 'unconditional leg', 'unconditional ramification', 'unconditional outgrowth', 'unconditional offshoot', 'unconditional offset', 'unconditional limb', 'unconditional consequence', 'unconditional division', 'unconditional effect', 'unconditional event', 'unconditional issue', 'unconditional outcome', 'unconditional projection', 'unconditional result', 'unconditional stalk', 'unconditional stem', 'unconditional stream', 'unconditional subfigure', 'unconditional upshot', 'unconditional watercourse', 'unconditional ramify', 'unconditional fork', 'unconditional furcate', 'unconditional separate', 'unconditional diverge', 'unconditional grow']),
    #     ReplacementConcept('safe', 0, ['condom', 'rubber', 'safety', 'prophylactic', 'birth control device', 'closet', 'contraceptive', 'contraceptive device', 'cupboard', 'deedbox', 'preventative', 'preventive', 'prophylactic device', 'strongbox']),
    #     ReplacementConcept('turing completeness', 0, ['Turing completeness', 'Alan Turing completeness', 'Alan Mathison Turing completeness', 'mathematician completeness', 'turing integrity', 'turing logicality', 'turing logicalness', 'turing unity', 'turing wholeness']),
    #     ReplacementConcept('pop', 0, ['dad', 'dada', 'daddy', 'pa', 'papa', 'pappa', 'soda', 'soda pop', 'soda water', 'tonic', 'popping', 'pop music', 'begetter', 'father', 'male parent', 'popular music', 'popular music genre', 'soft drink', 'sound', 'start', 'protrude', 'pop out', 'bulge', 'bulge out', 'bug out', 'come out', 'crop up', 'pop up', 'toss off', 'bolt down', 'belt down', 'pour down', 'down', 'drink down', 'kill', 'appear', 'break open', 'burst', 'change form', 'change shape', 'collapse', 'deform', 'discharge', 'drink', 'fire', 'go', 'hit', 'imbibe', 'inject', 'let go', 'let go of', 'release', 'relinquish', 'sound', 'split', 'throw', 'thrust']),
    #     ReplacementConcept('write a0', 0, ['compose a0', 'pen a0', 'indite a0', 'publish a0', 'drop a line a0', 'spell a0', 'communicate a0', 'correspond a0', 'create a0', 'create by mental act a0', 'create mentally a0', 'create verbally a0', 'delineate a0', 'describe a0', 'draw a0', 'intercommunicate a0', 'line a0', 'make a0', 'record a0', 'tape a0', 'trace a0']),
    #     ReplacementConcept('instruction', 0, ['direction', 'education', 'teaching', 'pedagogy', 'didactics', 'educational activity', 'command', 'statement', 'program line', 'activity', 'code', 'computer code', 'content', 'message', 'subject matter', 'substance']),
    #     ReplacementConcept('jalr a5 gadget', 0, ['jalr a5 appliance', 'jalr a5 contraption', 'jalr a5 contrivance', 'jalr a5 convenience', 'jalr a5 gizmo', 'jalr a5 gismo', 'jalr a5 widget', 'jalr a5 device']),
    #     ReplacementConcept('read', 0, ['publication', 'say', 'scan', 'take', 'learn', 'study', 'register', 'show', 'record', 'understand', 'interpret', 'translate', 'anticipate', 'audition', 'call', 'construe', 'feature', 'forebode', 'foretell', 'have', 'indicate', 'mouth', 'predict', 'prognosticate', 'promise', 'see', 'speak', 'talk', 'try out', 'utter', 'verbalise', 'verbalize']),
    #     ReplacementConcept('function call', 0, ['mathematical function call', 'purpose call', 'role call', 'use call', 'office call', 'part call', 'affair call', 'occasion call', 'social occasion call', 'social function call', 'routine call', 'subroutine call', 'subprogram call', 'procedure call', 'computer software call', 'duty call', 'mathematical relation call', 'package call', 'relation call', 'social affair call', 'social event call', 'social gathering call', 'software call', 'software package call', 'software program call', 'software system call', 'usefulness call', 'utility call', 'work call', 'operate call', 'go call', 'run call', 'serve call', 'officiate call', 'answer call', 'do call', 'suffice call', 'function phone call', 'function telephone call', 'function Call', 'function cry', 'function outcry', 'function yell', 'function shout', 'function vociferation', 'function claim', 'function birdcall', 'function birdsong', 'function song', 'function margin call', 'function call option', 'function animal communication', 'function asking', 'function command', 'function conclusion', 'function decision', 'function demand', 'function determination', 'function disposition', 'function inclination', 'function instruction', 'function option', 'function program line', 'function request', 'function statement', 'function telephone', 'function telephony', 'function tendency', 'function utterance', 'function visit', 'function vocalization', 'function name', 'function telephone', 'function call up', 'function phone', 'function ring', 'function shout', 'function shout out', 'function cry', 'function yell', 'function scream', 'function holler', 'function hollo', 'function squall', 'function send for', 'function visit', 'function call in', 'function address', 'function bid', 'function call off', 'function predict', 'function foretell', 'function prognosticate', 'function forebode', 'function anticipate', 'function promise', 'function adjudge', 'function arouse', 'function ask', 'function awaken', 'function bespeak', 'function call for', 'function challenge', 'function consider', 'function declare', 'function defer', 'function demand', 'function dispute', 'function emit', 'function enjoin', 'function entice', 'function exact', 'function expect', 'function gainsay', 'function get together', 'function guess', 'function hazard', 'function hold', 'function hold over', 'function indicate', 'function label', 'function let loose', 'function let out', 'function lure', 'function meet', 'function order', 'function play', 'function postpone', 'function pretend', 'function prorogue', 'function put off', 'function put over', 'function quest', 'function read', 'function reckon', 'function regard', 'function remit', 'function request', 'function require', 'function rouse', 'function say', 'function see', 'function set back', 'function shelve', 'function stop', 'function stop over', 'function table', 'function telecommunicate', 'function tell', 'function tempt', 'function turn to', 'function utter', 'function venture', 'function view', 'function wake', 'function wake up', 'function waken']),
    #     ReplacementConcept('requirements', 0, ['demand', 'necessity', 'essential', 'requisite', 'necessary', 'prerequisite', 'duty', 'obligation', 'responsibility', 'thing', 'inessential (ant.)']),
    #     ReplacementConcept('work', 0, ['piece of work', 'employment', 'study', 'workplace', 'oeuvre', 'body of work', 'acquisition', 'activity', 'business', 'end product', 'energy', 'geographic point', 'geographical point', 'job', 'learning', 'line', 'line of work', 'occupation', 'output', 'product', 'production', 'work', 'do work', 'act', 'function', 'operate', 'go', 'run', 'work on', 'process', 'exercise', 'work out', 'make', 'bring', 'play', 'wreak', 'make for', 'put to work', 'cultivate', 'crop', 'influence', 'act upon', 'shape', 'form', 'mold', 'mould', 'forge', 'knead', 'exploit', 'solve', 'figure out', 'puzzle out', 'lick', 'ferment', 'sour', 'turn', 'affect', 'apply', 'be', 'bear on', 'bear upon', 'becharm', 'become', 'beguile', 'bewitch', 'bring home the bacon', 'captivate', 'capture', 'care', 'catch', 'change state', 'charm', 'come through', 'convert', 'create', 'create from raw material', 'create from raw stuff', 'deal', 'deliver the goods', 'displace', 'employ', 'enamor', 'enamour', 'enchant', 'entrance', 'excite', 'fascinate', 'fix', 'gear up', 'get', 'go across', 'go through', 'handle', 'impact', 'manage', 'manipulate', 'move', 'pass', 'prepare', 'proceed', 'ready', 'set', 'set up', 'stimulate', 'stir', 'succeed', 'touch', 'touch on', 'trance', 'transform', 'transmute', 'transubstantiate', 'understand', 'use', 'utilise', 'utilize', 'win']),
    #     ReplacementConcept('architectures', 0, ['computer architecture', 'bailiwick', 'beaux arts', 'branch of knowledge', 'building', 'discipline', 'edifice', 'field', 'field of study', 'fine arts', 'profession', 'structure', 'study', 'subject', 'subject area', 'subject field']),
    #     ReplacementConcept('parameter', 0, ['parametric quantity', 'constant', 'constant quantity', 'factor', 'invariable', 'quantity']),
    #     ReplacementConcept('solve', 0, ['work out', 'figure out', 'puzzle out', 'lick', 'work', 'resolve', 'clear', 'calculate', 'cipher', 'compute', 'cypher', 'determine', 'figure', 'reckon', 'settle', 'square off', 'square up', 'understand']),
    #     ReplacementConcept('return-oriented programmer', 0, ['return-oriented computer programmer', 'return-oriented coder', 'return-oriented software engineer', 'return-oriented applied scientist', 'return-oriented computer user', 'return-oriented engineer', 'return-oriented technologist']),
    #     ReplacementConcept('original', 0, ['master', 'master copy', 'archetype', 'pilot', 'creation', 'example', 'model']),
    #     ReplacementConcept('rop chain', 0, ['rop concatenation', 'rop chemical chain', 'rop Chain', 'rop Ernst Boris Chain', 'rop Sir Ernst Boris Chain', 'rop range', 'rop mountain range', 'rop range of mountains', 'rop mountain chain', 'rop chain of mountains', 'rop string', 'rop strand', 'rop biochemist', 'rop building block', 'rop business', 'rop business concern', 'rop business organisation', 'rop business organization', 'rop concern', 'rop constraint', 'rop formation', 'rop geological formation', 'rop ligament', 'rop linear unit', 'rop necklace', 'rop restraint', 'rop series', 'rop unit', 'rop arrange', 'rop fasten', 'rop fix', 'rop secure', 'rop set up']),
    #     ReplacementConcept('problem', 0, ['job', 'trouble', 'difficulty', 'head', 'question']),
    #     ReplacementConcept('arm', 0, ['branch', 'limb', 'weapon', 'weapon system', 'subdivision', 'sleeve', 'armrest', 'cloth covering', 'division', 'instrument', 'projection', 'build up', 'fortify', 'gird', 'furnish', 'provide', 'render', 'supply']),
    #     ReplacementConcept('program', 0, ['plan', 'programme', 'broadcast', 'platform', 'political platform', 'political program', 'course of study', 'curriculum', 'syllabus', 'computer program', 'computer programme', 'announcement', 'computer software', 'document', 'idea', 'info', 'information', 'package', 'papers', 'performance', 'promulgation', 'show', 'software', 'software package', 'software program', 'software system', 'system', 'system of rules', 'thought', 'written document', 'programme', 'create by mental act', 'create mentally', 'schedule']),
    #     ReplacementConcept('ra register', 0, ['radium register', 'atomic number 88 register', 'Re register', 'right ascension register', 'Ra register', 'celestial longitude register', 'angular distance register', 'Egyptian deity register', 'metal register', 'metallic element register', 'ra registry', 'ra cash register', 'ra air duct', 'ra air passage', 'ra airway', 'ra cashbox', 'ra memory device', 'ra money box', 'ra quality', 'ra record', 'ra regulator', 'ra storage device', 'ra till', 'ra timber', 'ra timbre', 'ra tone', 'ra written account', 'ra written record', 'ra register', 'ra file', 'ra record', 'ra read', 'ra show', 'ra cross-file', 'ra affect', 'ra campaign', 'ra enrol', 'ra enroll', 'ra enter', 'ra indicate', 'ra inscribe', 'ra mail', 'ra play', 'ra post', 'ra put down', 'ra recruit', 'ra run', 'ra send', 'ra show up']),
    #     ReplacementConcept('output', 0, ['end product', 'yield', 'output signal', 'production', 'outturn', 'turnout', 'indefinite quantity', 'product', 'sign', 'signal', 'signaling', 'create', 'make', 'produce']),
    #     ReplacementConcept('compressed instructions', 0, ['compressed instruction manual', 'compressed book of instructions', 'compressed operating instructions', 'compressed manual']),
    #     ReplacementConcept('restore', 0, ['reconstruct', 'regenerate', 'rejuvenate', 'restitute', 'repair', 'mend', 'fix', 'bushel', 'doctor', 'furbish up', 'touch on', 'reinstate', 'reestablish', 'alter', 'ameliorate', 'amend', 'better', 'change', 'give back', 'improve', 'meliorate', 'modify', 'refund', 'renew', 'repay', 'return']),
    #     ReplacementConcept('approach', 0, ['attack', 'plan of attack', 'approaching', 'coming', 'access', 'approach path', 'glide path', 'glide slope', 'overture', 'advance', 'feeler', 'approach shot', 'air lane', 'airway', 'conceptualisation', 'conceptualization', 'flight path', 'formulation', 'golf shot', 'golf stroke', 'motion', 'move', 'movement', 'proffer', 'proposition', 'similarity', 'skyway', 'suggestion', 'swing', 'timing', 'way', 'near', 'come on', 'go up', 'draw near', 'draw close', 'come near', 'border on', 'set about', 'go about', 'accost', 'act', 'address', 'approximate', 'come', 'come close', 'come up', 'come up to', 'move']),
    #     ReplacementConcept('issue', 0, ['number', 'topic', 'subject', 'matter', 'issuing', 'issuance', 'military issue', 'government issue', 'return', 'take', 'takings', 'proceeds', 'yield', 'payoff', 'consequence', 'effect', 'outcome', 'result', 'event', 'upshot', 'offspring', 'progeny', 'emergence', 'egress', 'exit', 'outlet', 'way out', 'publication', 'beginning', 'cognitive content', 'content', 'fund', 'income', 'mental object', 'opening', 'periodical', 'phenomenon', 'printing', 'provision', 'relation', 'relative', 'stock', 'store', 'supply', 'supplying', 'publish', 'bring out', 'put out', 'release', 'supply', 'emerge', 'come out', 'come forth', 'go forth', 'egress', 'write out', 'make out', 'cut', 'air', 'bare', 'communicate', 'distribute', 'intercommunicate', 'publicise', 'publicize', 'write']),
    # ]

    text = '''DGAs are one of the main pillars of the success of botnets. They were first devised more than ten years ago, and they have been steadily refined over the years by successive generations of malware developers. These algorithms generate a set of AGDs to communicate with C&C servers, thus eliminating the risks associated with using static IP addresses [7, 33]. In [35], the authors generalise the notion of DGAs by extending them to other protocols beyond DNS, and they propose the term Resource Identifier Generation Algorithms (RIGAs). The authors show how decentralised permanent storage (DPS) has some potential drawbacks and exploitable characteristics for armouring a botnet, a fact that has already been exploited in the real world [6] due to the immutability property of DPS. Figure 2 depicts the hierarchy of RIGAs.
    In its most basic form, DGAs create a set of domain names by using a deterministic pseudo-random generator (PRNG) [43, 37]. Therefore, (infected) devices belonging to a botnet query a set of domains generated by the DGA until they are correctly resolved to a valid IP, corresponding to the C&C server. Since the location of the C&C server dynamically changes, blacklisting domains is a very inefficient protection technique. Additionally, this makes seizing the botnet much more difficult, since we would
    need to take (register) all domain names generated by the DGA (with a given seed) for disrupting the botmaster only for a short amount of time. This process will generally be very costly. Hence, the botmaster benefits from the high ratio between the number of generated domains and registered ones, which makes her operation cheap as compared to the cost defending against it, which involves registering all possible domains.
    According to the literature, there are two main DGA families: (i) Random-based DGA methods, which use a PRNG to generate a set of characters that form a domain name, and (ii) Dictionary/Wordlistbased DGA methods, which use a dictionary to produce domains. Nevertheless, we may also consider other types of DGA families, which use more subtle approaches, i.e. valid domains that were previously hacked to hide their C&C servers (i.e. domain shadowing) [28] as well as DGAs that generate domains that are very similar to existing valid domains [9], further hindering the detection task. Considering the dependency of the pre-shared secret (or seed) on time, Plohmann et al. [38] further categorise DGAs into: (i) time-independent and deterministic, (ii) time-dependent and deterministic, and (iii) time-dependent and non-deterministic.
    A random forest classifier (RNDF) based on a set of features such as word correlations, frequency, and part-of-speech tags is proposed in [52]. Berman [11] proposed a methodology based on Capsule Networks (CapsNet) to detect AGDs; the author compared his method with well-known approaches such as RNNs and CNNs, and the outcomes showed similar accuracy yet better performance. Xu et al. [49] proposed the combination of n-gram and a deep CNNs to create an n-gram combined with character-based domain classification (n-CBDC) model. Their model runs in an end-to-end fashion and does not require domain feature extraction. Vinayakumar et al. [47] implemented a set of deep learning architectures with Keras embedding and classical machine learning algorithms to classify DGA families. Their best-reported configuration is obtained when using RNNs and SVM with a radial basis function (SVM-RBF). Yang et al. [51] propose a heterogeneous deep neural network framework, which extracts the local features of a domain name as well as a self-attention based Bi-LSTM to extract further global features. Their outcomes showed higher accuracy than traditional DGA classifiers. Adversarial and Anti-Forensic Techniques to DGAs. Recently, an exciting trend of deploying anti-forensic techniques in DGA has become popular, aiming to create hard-to-detect DGA families and to test the performance of classifiers. Anderson et al. [5] proposed a generative adversarial network (GAN), which can learn and bypass classical detectors. Afterwards, they improved the performance of used AGD detectors with the training data generated by the GAN. Alaeiyan et al. [2] proposed a DGA family created with a genetic algorithm considering lexical features such as pronounceability. Their experiments showed that such a DGA family was hard to detect by classical approaches. In a similar vein, Yun et al. [55] used n-gram distribution and the pronounceability/readability of domains as a basis to create a novel DGA based on neural language models and the Wasserstein GAN (WGAN), which caused low detection rates for traditional DGA detection techniques. Spooren et al. [44] showed that their deep learning RNN performs significantly better than classical machine learning approaches. Besides, the authors stressed that one of the issues of manual feature engineering is that an adversary may adapt her strategy if she knows which features are used in the detection. Fu et al. [20] proposed two DGAs that use hidden Markov models (HMMs) and probabilistic context-free grammars, which were tested on state-of-the-art detection systems. Their results revealed that these DGAs hindered the detection rate of used approaches. Patsakis and Casino [34] proposed a probabilistic method to detect wordlist-based DGAs, which exploited the fact that some DGAs use a relatively limited dictionary, often resulting in word repetitions and the “birthday problem”. Their method is capable of detecting both real-world and custom DGAs created to fool traditional detectors. Finally, due to the widespread use of covert/encrypted communication channels for DNS (e.g. DNSCurve, DNS over HTTPS and DNS over TLS) or C&C connections in general [58, 21], malware creators have an additional layer to hide their activity, rendering traditional DGA detection useless. Nevertheless, as shown by Patsakis et al. [36], NXDomain detection can still be performed in such a scenario as well as feature extraction, so that DGA families can still be classified with high performance. In this section, we introduce the HYDRAS dataset, which consists of a collection of benign and AGD domains, both real-world as well as adversarial. The name of the dataset originates from the insightful parallelism of Nadji et al. [32] of DGA-powered botnets with the mythical ancient Greek monster Hydra. Benign domains are sampled from the Alexa 1M dataset. Since the Alexa dataset contains sites and not domains, we had to preprocess it as follows. First, we removed all top-level domain names (e.g. .com, .org) from each entry and kept only the SLD. Then, we pruned the duplicates since some web pages have multiple entries in the dataset due to localisation (e.g. google.com and google.co.in) or been subdomains of identical services (e.g. various blogs of blogspot.com) . Finally, we removed all internationalised domain names, since they are encoded using Punycode1 representation. After preprocessing the Alexa dataset, we ended up with 915,994 unique domains. In the case of AGDs, the use of a single dataset, unfortunately very frequent in the literature, leads to several issues and biases that can easily drive towards wrong analysis and misleading conclusions. For instance, the public feed of DGAs provided by the Network Security Research Lab at 3602 as well as the DGArchive [38] provide real-world datasets with millions of samples from many DGA families. Nonetheless, despite the numerous samples in both these datasets, many malware families are significantly underrepresented. A demonstrative example is the xshellghost family in the 360 dataset, which contains only a single sample at the time of writing. Thankfully, the researchers at 360 have reversed the code of this DGA3. Since the provision of many samples is required to perform a decent evaluation of any detection technique, we utilised the available code of DGAs that contained only a few samples, to populate our dataset further. Our dataset was initialised with several public DGA repositories, e.g., J. Bader’s [10], A. Abakumov’s [1], and P. Chaignon’s [16]. As explained above, we additionally used DGA code available at these repositories to generate enough samples for underrepresented DGA families; we used a few random seeds and/or the extended date range to obtain new samples. Since we used the original code of the DGAs, the appended domains have identical characteristics to the original ones and might occur in the real-world as well. Thus, these AGDs could have been collected in the real world. Moreover, we added the SLDs of three adversarial DGAs, namely deception, deception2 [44] and khaos [55]. In summary, our dataset consists of 95,325,598 AGDs belonging to a total of 109 families, from which 105 are unique.4 The families included, along with their corresponding number of collected samples, are reported in Table 1. The dataset is available for download at https://zenodo.org/record/3965397 [15]. 1https://tools.ietf.org/html/rfc3492 2https://data.netlab.360.com/dga/ 3https://github.com/360netlab/DGA/blob/master/code/xshellghost/dga.py 4A few DGAs are used by multiple families. We thoroughly analysed the AGDs in our dataset as well as the ideas behind existing AGD detection approaches in the literature. We found out that the basic strategy for detecting non-wordlist-based DGAs is to take advantage of the fact that they, in general, make little effort to be human-memorable, as they are randomly generated. Moreover, even if they show a high correlation with readable words in terms of vowel/consonant usage, etc., the generated domains are expected to contain from zero to only a few words having a short length. A general description of our approach is as follows: On receiving a domain name for analysis, we first cache it to see correlations with previous ones. Then, we try to determine whether the SLD matches some specific patterns, e.g. whether it is a hex value, the combination of vowels/consonants. Later, after removing all digits, we try to break the remaining characters into words. Within these words, we prune the short ones (e.g. stop words, articles) and study the remaining to determine whether they are real or just gibberish. Moreover, we compute the entropy of the domain and a subset of the patterns created during the correlation process. All the above provide us with several features that can be efficiently used to determine whether a domain name is benign or not, without the need for external information (e.g. WHOIS) or waiting for the domain name resolution revealing whether it is an NXDomain. In this way, we may prune a significant amount of requests, regardless of their outcome. The features used in our method are defined in Table 2. The first set of parameters is computed when trying to identify valid n-grams and words. For the former, we train our n-gram model with Alexa n-grams with lengths three, four and five. For the latter, we use the wordninja5 word splitter, which probabilistically splits its input using NLP based on the unigram frequencies of the English Wikipedia. Hence, we split the domain into meaningful words, according to a minimum word-length w. Therefore, only terms which contain at least w characters are considered as significant. Then, we compute what percentage of the domain characters are meaningful, by calculating the ratio γ between characters belonging to words and the domain’s total length. Next, we compute two more sets of features according to statistical attributes as well as ratios using the previously calculated features. In addition, we use a Gibberish detection layer, which consists of two methods. The first one is a 2-character Markov chain Gibberish detector6, which is trained with English text to determine how often characters appear next to each other. Therefore, a text string is valid if it obtains a value above the probability threshold for each pair of characters. The second is a Gibberish classifier.7 In this case, the method checks mainly three features of the text: (i) whether the amount of unique chars is within a typical range, (ii) whether the amount of vowels is within a standard range and (iii), whether the word to char ratio is in a healthy range. Finally, we compute the entropy of a subset of the alphanumeric sequences to enrich the feature set. Due to space constraints, we have included the average weight for each classification task, which we further detail in Section 5.
    '''

    concepts = [
        ReplacementConcept('machine learning', 5 ,['simple machine learning', 'political machine learning', 'car learning', 'auto learning', 'automobile learning', 'motorcar learning', 'automotive vehicle learning', 'device learning', 'individual learning', 'mechanical device learning', 'mortal learning', 'motor vehicle learning', 'organisation learning', 'organization learning', 'person learning', 'somebody learning', 'someone learning', 'soul learning', 'create learning', 'forge learning', 'form learning', 'make learning', 'mold learning', 'mould learning', 'produce learning', 'shape learning', 'work learning', 'machine acquisition', 'machine eruditeness', 'machine erudition', 'machine learnedness', 'machine scholarship', 'machine encyclopedism', 'machine encyclopaedism', 'machine basic cognitive process', 'machine education']),
        ReplacementConcept('fair comparison', 5 ,['carnival comparison', 'funfair comparison', 'bazaar comparison', 'assemblage comparison', 'cut-rate sale comparison', 'exhibition comparison', 'expo comparison', 'exposition comparison', 'gathering comparison', 'sale comparison', 'sales event comparison', 'show comparison', 'bring together comparison', 'join comparison', 'fair comparing', 'fair compare', 'fair equivalence', 'fair comparability', 'fair alikeness', 'fair examination', 'fair likeness', 'fair relation', 'fair scrutiny', 'fair similitude']),
        ReplacementConcept('malicious domains', 5 ,['malicious sphere', 'malicious area', 'malicious orbit', 'malicious field', 'malicious arena', 'malicious demesne', 'malicious land', 'malicious world', 'malicious knowledge domain', 'malicious knowledge base', 'malicious class', 'malicious environment', 'malicious realm', 'malicious region', 'malicious set', 'malicious social class', 'malicious socio-economic class']),
        ReplacementConcept('real scenarios', 5 ,['real number scenarios', 'coin scenarios', 'complex number scenarios', 'complex quantity scenarios', 'imaginary scenarios', 'imaginary number scenarios', 'real assumption', 'real book', 'real playscript', 'real premise', 'real premiss', 'real scene', 'real script', 'real setting']),
        ReplacementConcept('detection method', 5 ,['sensing method', 'catching method', 'espial method', 'spying method', 'spotting method', 'signal detection method', 'detecting method', 'detective work method', 'sleuthing method', 'discovery method', 'find method', 'perception method', 'police investigation method', 'police work method', 'reception method', 'uncovering method', 'detection method acting', 'detection acting', 'detection know-how', 'detection performing', 'detection playacting', 'detection playing']),
        ReplacementConcept('classification time', 5 ,['categorization time', 'categorisation time', 'compartmentalization time', 'compartmentalisation time', 'assortment time', 'sorting time', 'arrangement time', 'basic cognitive process time', 'grouping time', 'restriction time', 'classification clip', 'classification clock time', 'classification fourth dimension', 'classification meter', 'classification metre', 'classification prison term', 'classification sentence', 'classification attribute', 'classification case', 'classification dimension', 'classification example', 'classification experience', 'classification indication', 'classification instance', 'classification instant', 'classification meter reading', 'classification minute', 'classification moment', 'classification period', 'classification period of time', 'classification reading', 'classification rhythmicity', 'classification second', 'classification term', 'classification time period', 'classification clock', 'classification adjust', 'classification correct', 'classification determine', 'classification influence', 'classification measure', 'classification mold', 'classification quantify', 'classification regulate', 'classification schedule', 'classification set', 'classification shape']),
        ReplacementConcept('classification performance', 5 ,['categorization performance', 'categorisation performance', 'compartmentalization performance', 'compartmentalisation performance', 'assortment performance', 'sorting performance', 'arrangement performance', 'basic cognitive process performance', 'grouping performance', 'restriction performance', 'classification public presentation', 'classification execution', 'classification carrying out', 'classification carrying into action', 'classification operation', 'classification functioning', 'classification accomplishment', 'classification achievement', 'classification action', 'classification demonstration', 'classification physical process', 'classification presentation', 'classification presentment', 'classification process', 'classification show']),
        ReplacementConcept('multiclass classification', 5 ,['multiclass categorization', 'multiclass categorisation', 'multiclass compartmentalization', 'multiclass compartmentalisation', 'multiclass assortment', 'multiclass sorting', 'multiclass arrangement', 'multiclass basic cognitive process', 'multiclass grouping', 'multiclass restriction']),
        ReplacementConcept('standard deviation', 5 ,['criterion deviation', 'measure deviation', 'touchstone deviation', 'monetary standard deviation', 'capacity measure deviation', 'capacity unit deviation', 'cubage unit deviation', 'cubature unit deviation', 'cubic content unit deviation', 'cubic measure deviation', 'displacement unit deviation', 'flag deviation', 'ideal deviation', 'point of reference deviation', 'post deviation', 'reference deviation', 'reference point deviation', 'value deviation', 'volume unit deviation', 'standard divergence', 'standard departure', 'standard difference', 'standard deviance', 'standard diversion', 'standard digression', 'standard deflection', 'standard deflexion', 'standard divagation', 'standard abnormality', 'standard erroneousness', 'standard error', 'standard fluctuation', 'standard irregularity', 'standard statistic', 'standard turn', 'standard turning', 'standard variation']),
        ReplacementConcept('unlimited depth', 5 ,['unlimited deepness', 'unlimited astuteness', 'unlimited profundity', 'unlimited profoundness', 'unlimited abasement', 'unlimited abjection', 'unlimited degradation', 'unlimited degree', 'unlimited extent', 'unlimited grade', 'unlimited level', 'unlimited part', 'unlimited region', 'unlimited sapience', 'unlimited wisdom']),
        ReplacementConcept('sound evaluation methodology', 5 ,['auditory sensation evaluation methodology', 'audio evaluation methodology', 'phone evaluation methodology', 'speech sound evaluation methodology', 'strait evaluation methodology', 'aesthesis evaluation methodology', 'auditory communication evaluation methodology', 'body of water evaluation methodology', 'channel evaluation methodology', 'esthesis evaluation methodology', 'happening evaluation methodology', 'language unit evaluation methodology', 'linguistic unit evaluation methodology', 'mechanical phenomenon evaluation methodology', 'natural event evaluation methodology', 'occurrence evaluation methodology', 'occurrent evaluation methodology', 'sensation evaluation methodology', 'sense datum evaluation methodology', 'sense experience evaluation methodology', 'sense impression evaluation methodology', 'sound property evaluation methodology', 'water evaluation methodology', 'go evaluation methodology', 'voice evaluation methodology', 'vocalize evaluation methodology', 'vocalise evaluation methodology', 'fathom evaluation methodology', 'announce evaluation methodology', 'appear evaluation methodology', 'articulate evaluation methodology', 'cause to be perceived evaluation methodology', 'denote evaluation methodology', 'enounce evaluation methodology', 'enunciate evaluation methodology', 'look evaluation methodology', 'measure evaluation methodology', 'pronounce evaluation methodology', 'quantify evaluation methodology', 'say evaluation methodology', 'seem evaluation methodology', 'sound out evaluation methodology', 'sound rating methodology', 'sound valuation methodology', 'sound appraisal methodology', 'sound assessment methodology', 'sound judgement methodology', 'sound judgment methodology', 'sound evaluation methodological analysis', 'sound evaluation epistemology', 'sound evaluation method']),
        ReplacementConcept('malicious family', 5 ,['malicious household', 'malicious house', 'malicious home', 'malicious menage', 'malicious family unit', 'malicious class', 'malicious category', 'malicious family line', 'malicious folk', 'malicious kinfolk', 'malicious kinsfolk', 'malicious sept', 'malicious phratry', 'malicious kin', 'malicious kinsperson', 'malicious syndicate', 'malicious crime syndicate', 'malicious mob', 'malicious fellowship', 'malicious accumulation', 'malicious aggregation', 'malicious ancestry', 'malicious assemblage', 'malicious association', 'malicious blood', 'malicious blood line', 'malicious bloodline', 'malicious clan', 'malicious collection', 'malicious descent', 'malicious gangdom', 'malicious gangland', 'malicious kin group', 'malicious kindred', 'malicious kinship group', 'malicious line', 'malicious line of descent', 'malicious lineage', 'malicious organized crime', 'malicious origin', 'malicious parentage', 'malicious pedigree', 'malicious relation', 'malicious relative', 'malicious social unit', 'malicious stemma', 'malicious stock', 'malicious taxon', 'malicious taxonomic category', 'malicious taxonomic group', 'malicious tribe', 'malicious unit']),
        ReplacementConcept('vast amount', 5 ,['vast sum', 'vast sum of money', 'vast amount of money', 'vast measure', 'vast quantity', 'vast total', 'vast abstraction', 'vast assets', 'vast magnitude', 'vast total', 'vast number', 'vast add up', 'vast come', 'vast be', 'vast become', 'vast turn']),
        ReplacementConcept('f1 score', 5 ,['f1 mark', 'f1 grade', 'f1 musical score', 'f1 account', 'f1 scotch', 'f1 grudge', 'f1 grievance', 'f1 sexual conquest', 'f1 bitterness', 'f1 conquest', 'f1 debt', 'f1 dent', 'f1 evaluation', 'f1 fact', 'f1 gall', 'f1 ground', 'f1 incision', 'f1 number', 'f1 prick', 'f1 rancor', 'f1 rancour', 'f1 rating', 'f1 reason', 'f1 resentment', 'f1 scratch', 'f1 seduction', 'f1 set', 'f1 sheet music', 'f1 slit', 'f1 success', 'f1 valuation', 'f1 hit', 'f1 tally', 'f1 rack up', 'f1 nock', 'f1 mark', 'f1 seduce', 'f1 make', 'f1 grade', 'f1 accomplish', 'f1 achieve', 'f1 advance', 'f1 appraise', 'f1 assess', 'f1 attain', 'f1 compose', 'f1 enter', 'f1 evaluate', 'f1 gain', 'f1 gain ground', 'f1 get ahead', 'f1 make headway', 'f1 measure', 'f1 notch', 'f1 persuade', 'f1 pull ahead', 'f1 put down', 'f1 reach', 'f1 record', 'f1 valuate', 'f1 value', 'f1 win', 'f1 write']),
        ReplacementConcept('current state', 5 ,['electric current state', 'stream state', 'flow state', 'course state', 'electrical phenomenon state', 'flowing state', 'line state', 'current province', 'current nation', 'current country', 'current land', 'current commonwealth', 'current res publica', 'current body politic', 'current state of matter', 'current Department of State', 'current United States Department of State', 'current State Department', 'current State', 'current DoS', 'current administrative district', 'current administrative division', 'current attribute', 'current authorities', 'current chemical phenomenon', 'current emotional state', 'current executive department', 'current government', 'current political entity', 'current political unit', 'current regime', 'current spirit', 'current territorial division', 'current say', 'current tell', 'current submit', 'current put forward', 'current posit', 'current express', 'current advise', 'current denote', 'current give tongue to', 'current propose', 'current refer', 'current suggest', 'current utter', 'current verbalise', 'current verbalize']),
        ReplacementConcept('create agds', 5 ,['make agds', 'create agds', 'produce agds', 'act agds', 'appoint agds', 'charge agds', 'move agds']),
        ReplacementConcept('features computation', 5 ,['characteristic computation', 'lineament computation', 'feature film computation', 'feature article computation', 'article computation', 'attribute computation', 'body part computation', 'dimension computation', 'film computation', 'flick computation', 'merchandise computation', 'motion picture computation', 'motion-picture show computation', 'movie computation', 'moving picture computation', 'moving-picture show computation', 'pic computation', 'picture computation', 'picture show computation', 'product computation', 'property computation', 'ware computation', 'have computation', 'feature computation', 'sport computation', 'boast computation', 'lack (ant.) computation', 'features calculation', 'features computing', 'features figuring', 'features reckoning', 'features problem solving', 'features procedure', 'features process']),
        ReplacementConcept('accuracy', 5 ,['truth', 'quality']),
        ReplacementConcept('feature', 5 ,['characteristic', 'lineament', 'feature film', 'feature article', 'article', 'attribute', 'body part', 'dimension', 'film', 'flick', 'merchandise', 'motion picture', 'motion-picture show', 'movie', 'moving picture', 'moving-picture show', 'pic', 'picture', 'picture show', 'product', 'property', 'ware', 'have', 'feature', 'sport', 'boast']),
        ReplacementConcept('prediction times', 5 ,['anticipation times', 'prevision times', 'foretelling times', 'forecasting times', 'prognostication times', 'abstract thought times', 'logical thinking times', 'reasoning times', 'statement times', 'prediction multiplication', 'prediction arithmetic operation', 'prediction period', 'prediction period of time', 'prediction time period']),
        ReplacementConcept('benign domains', 5 ,['benign sphere', 'benign area', 'benign orbit', 'benign field', 'benign arena', 'benign demesne', 'benign land', 'benign world', 'benign knowledge domain', 'benign knowledge base', 'benign class', 'benign environment', 'benign realm', 'benign region', 'benign set', 'benign social class', 'benign socio-economic class']),
        ReplacementConcept('current state-of-the-art', 5 ,['electric current state-of-the-art', 'stream state-of-the-art', 'flow state-of-the-art', 'course state-of-the-art', 'electrical phenomenon state-of-the-art', 'flowing state-of-the-art', 'line state-of-the-art']),
        ReplacementConcept('grant agreement', 5 ,['subsidization agreement', 'subsidisation agreement', 'assignment agreement', 'Grant agreement', 'Duncan Grant agreement', 'Duncan James Corrow Grant agreement', 'Cary Grant agreement', 'Ulysses Grant agreement', 'Ulysses S. Grant agreement', 'Ulysses Simpson Grant agreement', 'Hiram Ulysses Grant agreement', 'President Grant agreement', 'concession agreement', 'actor agreement', 'aid agreement', 'allocation agreement', 'allotment agreement', 'apportioning agreement', 'apportionment agreement', 'assignation agreement', 'Chief Executive agreement', 'contract agreement', 'economic aid agreement', 'full general agreement', 'general agreement', 'histrion agreement', 'painter agreement', 'parceling agreement', 'parcelling agreement', 'player agreement', 'President agreement', 'President of the United States agreement', 'right agreement', 'role player agreement', 'thespian agreement', 'transferred possession agreement', 'transferred property agreement', 'United States President agreement', 'allow agreement', 'award agreement', 'concede agreement', 'yield agreement', 'accord agreement', 'allot agreement', 'give agreement', 'cede agreement', 'deed over agreement', 'agree agreement', 'concord agreement', 'concur agreement', 'gift agreement', 'hold agreement', 'present agreement', 'grant understanding', 'grant correspondence', 'grant accord', 'grant arrangement', 'grant concord', 'grant compatibility', 'grant concordance', 'grant grammatical relation', 'grant harmony', 'grant planning', 'grant preparation', 'grant provision', 'grant speech act', 'grant statement']),
        ReplacementConcept('specific length', 5 ,['particular length', 'fact length', 'medicament length', 'medication length', 'medicinal drug length', 'medicine length', 'specific duration', 'specific distance', 'specific dimension', 'specific extent', 'specific fundamental measure', 'specific fundamental quantity', 'specific physical property', 'specific section', 'specific segment', 'specific size', 'specific temporal property']),
        ReplacementConcept('related work', 5 ,['related piece of work', 'related employment', 'related study', 'related workplace', 'related oeuvre', 'related body of work', 'related acquisition', 'related activity', 'related business', 'related end product', 'related energy', 'related geographic point', 'related geographical point', 'related job', 'related learning', 'related line', 'related line of work', 'related occupation', 'related output', 'related product', 'related production', 'related work', 'related do work', 'related act', 'related function', 'related operate', 'related go', 'related run', 'related work on', 'related process', 'related exercise', 'related work out', 'related make', 'related bring', 'related play', 'related wreak', 'related make for', 'related put to work', 'related cultivate', 'related crop', 'related influence', 'related act upon', 'related shape', 'related form', 'related mold', 'related mould', 'related forge', 'related knead', 'related exploit', 'related solve', 'related figure out', 'related puzzle out', 'related lick', 'related ferment', 'related sour', 'related turn', 'related affect', 'related apply', 'related be', 'related bear on', 'related bear upon', 'related becharm', 'related become', 'related beguile', 'related bewitch', 'related bring home the bacon', 'related captivate', 'related capture', 'related care', 'related catch', 'related change state', 'related charm', 'related come through', 'related convert', 'related create', 'related create from raw material', 'related create from raw stuff', 'related deal', 'related deliver the goods', 'related displace', 'related employ', 'related enamor', 'related enamour', 'related enchant', 'related entrance', 'related excite', 'related fascinate', 'related fix', 'related gear up', 'related get', 'related go across', 'related go through', 'related handle', 'related impact', 'related manage', 'related manipulate', 'related move', 'related pass', 'related prepare', 'related proceed', 'related ready', 'related set', 'related set up', 'related stimulate', 'related stir', 'related succeed', 'related touch', 'related touch on', 'related trance', 'related transform', 'related transmute', 'related transubstantiate', 'related understand', 'related use', 'related utilise', 'related utilize', 'related win']),
        ReplacementConcept('binary classification', 5 ,['binary star classification', 'double star classification', 'star classification', 'binary categorization', 'binary categorisation', 'binary compartmentalization', 'binary compartmentalisation', 'binary assortment', 'binary sorting', 'binary arrangement', 'binary basic cognitive process', 'binary grouping', 'binary restriction']),
        ReplacementConcept('describe', 5 ,['depict', 'draw', 'report', 'account', 'trace', 'line', 'delineate', 'identify', 'discover', 'key', 'key out', 'distinguish', 'name', 'exposit', 'expound', 'inform', 'mark', 'set forth']),
        ReplacementConcept('classifier', 5 ,['morpheme', 'thinker', 'word']),
        ReplacementConcept('reported results', 5 ,['reported consequence', 'reported effect', 'reported outcome', 'reported event', 'reported issue', 'reported upshot', 'reported solution', 'reported answer', 'reported resolution', 'reported solvent', 'reported resultant', 'reported final result', 'reported termination', 'reported resultant role', 'reported conclusion', 'reported ending', 'reported finish', 'reported participant role', 'reported phenomenon', 'reported semantic role', 'reported statement', 'reported ensue', 'reported leave', 'reported lead', 'reported bring about', 'reported give rise', 'reported produce', 'reported prove', 'reported turn out', 'reported turn up']),
        ReplacementConcept('adversarial dgas', 5 ,["adversarial domain propagation algorithms"]),
        # ReplacementConcept('dga families', 5 ,["domain propagation algorithm families"]),
        # ReplacementConcept('benign', 5 ,["benign"]),
        # ReplacementConcept('alexa dataset', 5 ,["alexa dataset"]),
        # ReplacementConcept('10-fold cross-validation', 5 ,["10-fold cross-validation"]),
        # ReplacementConcept('dga', 5 ,["domain propagation algorithm"]),
    ]

    

    print(ranker.genSubstitutions(text,concepts))
    # print(ranker.genFakeText(text,concepts))



if __name__ == "__main__":
    import timeit

    print(timeit.Timer(lambda: main()).repeat(1, 1))